{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "223px",
        "width": "193px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Notebook contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "226px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "movie_lens_fair_svae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqrrncx06Ejf",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Variational Autoencoders for Collaborative Filtering\n",
        "\n",
        "\n",
        "\n",
        "The notebook provides PyTorch code for the proposed model, \"SVAE\" along with the data preprocessing for the Movielens-20M dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX-W-jWh6Ejg",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "A7dHsN8C6Ejh",
        "colab_type": "code",
        "outputId": "1062b5fb-759c-4fe5-db1b-6fcb53853ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from random import randint\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbLuo7K_6Ejk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KsmhEHs6Ejm",
        "colab_type": "text"
      },
      "source": [
        "# Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knf3mAvX6Ejn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### change `DATA_DIR` to the location where the dataset sits\n",
        "### compatible datasets: ML-1M, Netflix-full\n",
        "\n",
        "hyper_params = {\n",
        "    'data_base': '/content/drive/My Drive/thesis/Sequential_Vae/ml-20m/', # Don't remove the '/' at the end please :)\n",
        "    'project_name': 'svae_ml20m',\n",
        "    # 'data_base': 'saved_data/netflix-full/',\n",
        "    # 'project_name': 'svae_netflix_full',\n",
        "    'model_file_name': '',\n",
        "    'log_file': '',\n",
        "    'history_split_test': [0.8, 0.2], # Part of test history to train on : Part of test history to test\n",
        "\n",
        "    'learning_rate': 0.01, # learning rate is required only if optimizer is adagrad\n",
        "    'optimizer': 'adam',\n",
        "    'weight_decay': float(5e-3),\n",
        "\n",
        "    'epochs': 15,\n",
        "    'batch_size': 1, # Needs to be 1, because we don't pack multiple sequences in the same batch\n",
        "    \n",
        "    'item_embed_size': 256,\n",
        "    'rnn_size': 200,\n",
        "    'hidden_size': 150,\n",
        "    'latent_size': 64,\n",
        "    'loss_type': 'next_k', # [predict_next, same, prefix, postfix, exp_decay, next_k]\n",
        "    'next_k': 4,\n",
        "    'noise': 0,\n",
        "\n",
        "    'number_users_to_keep': 1000000000,\n",
        "    'batch_log_interval': 10000,\n",
        "    'train_cp_users': 200,\n",
        "    'exploding_clip': 0.25,\n",
        "}\n",
        "\n",
        "file_name = '_optimizer_' + str(hyper_params['optimizer'])\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    file_name += '_lr_' + str(hyper_params['learning_rate'])\n",
        "file_name += '_weight_decay_' + str(hyper_params['weight_decay'])\n",
        "file_name += '_loss_type_' + str(hyper_params['loss_type'])\n",
        "file_name += '_item_embed_size_' + str(hyper_params['item_embed_size'])\n",
        "file_name += '_rnn_size_' + str(hyper_params['rnn_size'])\n",
        "file_name += '_latent_size_' + str(hyper_params['latent_size'])\n",
        "\n",
        "log_file_root = \"/content/drive/My Drive/thesis/Sequential_Vae/ml-20m/saved_logs_fin/\" # Don't remove the '/' at the end please :)\n",
        "model_file_root = \"/content/drive/My Drive/thesis/Sequential_Vae/ml-20m/saved_models_fin/\" # Don't remove the '/' at the end please :)\n",
        "\n",
        "if not os.path.isdir(log_file_root): os.mkdir(log_file_root)\n",
        "if not os.path.isdir(model_file_root): os.mkdir(model_file_root)\n",
        "hyper_params['log_file'] = log_file_root + hyper_params['project_name'] + '_log' + file_name + '.txt'\n",
        "hyper_params['model_file_name'] = model_file_root + hyper_params['project_name'] + '_model' + file_name + '.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mDyPrrx6Ejq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = hyper_params['data_base']\n",
        "pro_dir = os.path.join(DATA_DIR, 'pro_sg') # Path where preprocessed data will be saved\n",
        "hyper_params['data_base'] += 'pro_sg/'\n",
        "\n",
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "    cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "    dtypes = {'userId': 'int', 'movieId': 'int', 'timestamp': 'int', 'rating': 'int'}\n",
        "    #raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), sep='::', names=cols, parse_dates=['timestamp'])\n",
        "    raw_data =pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)\n",
        "    print (raw_data)\n",
        "    max_seq_len = 1000\n",
        "    n_heldout_users = 10000 # If total users = N; train_users = N - 2*heldout; test_users & val_users = heldout\n",
        "\n",
        "    # binarize the data (only keep ratings >= 4)\n",
        "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
        "\n",
        "    # Remove users with greater than $max_seq_len number of watched movies\n",
        "    raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
        "\n",
        "    # Sort data values with the timestamp\n",
        "    raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
        "\n",
        "    print(raw_data.head(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQyfGRRYOtLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data =pd.read_csv('/content/drive/My Drive/thesis/Sequential_Vae/ml-20m/ratings.csv',header=0)\n",
        "# # binarize the data (only keep ratings >= 4)\n",
        "# max_seq_len = 1000\n",
        "# raw_data = raw_data[raw_data['rating'] > 3.5]\n",
        "\n",
        "#     # Remove users with greater than $max_seq_len number of watched movies\n",
        "# raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
        "\n",
        "#     # Sort data values with the timestamp\n",
        "# raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
        "\n",
        "   \n",
        "\n",
        "#raw_data.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJ-yIYobCWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data.to_numeric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-um7SOIlZ9Ts",
        "colab_type": "code",
        "outputId": "bd59a834-f197-4b75-8a83-abeea502091e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "raw_data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7a57e84b5e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebK8dFIra-zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data['userId'].nunique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2PUZPgvtfBW",
        "colab_type": "code",
        "outputId": "cbdaa1c1-8f1f-405a-d78e-cb429debb3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "raw_data['movieId'].nunique"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-919e6dca20cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDAXdQodqMQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data =pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)\n",
        "#   #  print (raw_data)\n",
        "# max_seq_len = 10000\n",
        "# n_heldout_users = 10000 # If total users = N; train_users = N - 2*heldout; test_users & val_users = heldout\n",
        "\n",
        "#     # binarize the data (only keep ratings >= 4)\n",
        "# raw_data = raw_data[raw_data['rating'] > 3.5]\n",
        "\n",
        "#     # Remove users with greater than $max_seq_len number of watched movies\n",
        "# raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
        "\n",
        "#     # Sort data values with the timestamp\n",
        "# raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
        "# raw_data.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8IxF4GfTLHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr54rCXQr0dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data['userId'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ4LsvQzVYSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_data['movieId'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGgWrPJ7oIdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_count(tp, id):\n",
        "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
        "    count = playcount_groupbyid.size()\n",
        "    print (count)\n",
        "    return count\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSs052v_oZpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
        "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
        "    if min_sc > 0:\n",
        "        itemcount = get_count(tp, 'movieId')\n",
        "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
        "        print(itemcount)\n",
        "    \n",
        "    # Only keep the triplets for users who clicked on at least min_uc items\n",
        "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
        "    if min_uc > 0:\n",
        "        usercount = get_count(tp, 'userId')\n",
        "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
        "        print(usercount)\n",
        "    # Update both usercount and itemcount after filtering\n",
        "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
        "    print (usercount)\n",
        "    return tp, usercount, itemcount\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7HhXyiU6Ejs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test_proportion(data, test_prop=0.2):\n",
        "    data_grouped_by_user = data.groupby('userId')\n",
        "    tr_list, te_list = list(), list()\n",
        "\n",
        "    np.random.seed(98765)\n",
        "\n",
        "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
        "        n_items_u = len(group)\n",
        "\n",
        "        if n_items_u >= 5:\n",
        "            idx = np.zeros(n_items_u, dtype='bool')\n",
        "            # idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
        "            idx[int((1.0 - test_prop) * n_items_u):] = True\n",
        "            # print(idx)\n",
        "            \n",
        "            tr_list.append(group[np.logical_not(idx)])\n",
        "            te_list.append(group[idx])\n",
        "        else:\n",
        "            tr_list.append(group)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(\"%d users sampled\" % i)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    data_tr = pd.concat(tr_list)\n",
        "    data_te = pd.concat(te_list)\n",
        "    \n",
        "    return data_tr, data_te\n",
        "\n",
        "def numerize(tp):\n",
        "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
        "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
        "    ra = list(map(lambda x: x, tp['rating']))\n",
        "    ret =  pd.DataFrame(data={'uid': uid, 'sid': sid, 'rating': ra}, columns=['uid', 'sid', 'rating'])\n",
        "    ret['rating'] = ret['rating'].apply(pd.to_numeric)\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl2FyQ176Eju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
        "\n",
        "    raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
        "\n",
        "    sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
        "\n",
        "    print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "          (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
        "\n",
        "    unique_uid = user_activity.index\n",
        "\n",
        "    np.random.seed(98765)\n",
        "    idx_perm = np.random.permutation(unique_uid.size)\n",
        "    unique_uid = unique_uid[idx_perm]\n",
        "\n",
        "    # create train/validation/test users\n",
        "    n_users = unique_uid.size\n",
        "\n",
        "    tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
        "    vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
        "    te_users = unique_uid[(n_users - n_heldout_users):]\n",
        "\n",
        "    train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
        "\n",
        "    unique_sid = pd.unique(train_plays['movieId'])\n",
        "\n",
        "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
        "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
        "\n",
        "    if not os.path.exists(pro_dir):\n",
        "        os.makedirs(pro_dir)\n",
        "\n",
        "    with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
        "        for sid in unique_sid:\n",
        "            f.write('%s\\n' % sid)\n",
        "\n",
        "    vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
        "    vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
        "\n",
        "    test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
        "    test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]\n",
        "\n",
        "    test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
        "\n",
        "    train_data = numerize(train_plays)\n",
        "    train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
        "\n",
        "    vad_data_tr = numerize(vad_plays_tr)\n",
        "    vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
        "\n",
        "    vad_data_te = numerize(vad_plays_te)\n",
        "    vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
        "\n",
        "    test_data_tr = numerize(test_plays_tr)\n",
        "    test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
        "\n",
        "    test_data_te = numerize(test_plays_te)\n",
        "    test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q63-THuRYgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data.head(n=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxF_irwhz4H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_histogram(data):\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, ax = plt.subplots()\n",
        "    print(max(data))\n",
        "    plt.hist(data,(max(data)))\n",
        "    #plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EldnVtz6Ejw",
        "colab_type": "text"
      },
      "source": [
        "# Utlity functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvLKq4Btz6Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot_histogram(raw_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4iURa1I-6Ejw",
        "colab_type": "code",
        "outputId": "2147aa20-94d6-4766-acb7-aa3e6021f3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "LongTensor = torch.LongTensor\n",
        "FloatTensor = torch.FloatTensor\n",
        "\n",
        "is_cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda_available: \n",
        "    print(\"Using CUDA...\\n\")\n",
        "    LongTensor = torch.cuda.LongTensor\n",
        "    FloatTensor = torch.cuda.FloatTensor\n",
        "    \n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def save_obj_json(obj, name):\n",
        "    with open(name + '.json', 'w') as f:\n",
        "        json.dump(obj, f)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def load_obj_json(name):\n",
        "    with open(name + '.json', 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def file_write(log_file, s):\n",
        "    print(s)\n",
        "    f = open(log_file, 'a')\n",
        "    f.write(s+'\\n')\n",
        "    f.close()\n",
        "\n",
        "def clear_log_file(log_file):\n",
        "    f = open(log_file, 'w')\n",
        "    f.write('')\n",
        "    f.close()\n",
        "\n",
        "def pretty_print(h):\n",
        "    print(\"{\")\n",
        "    for key in h:\n",
        "        print(' ' * 4 + str(key) + ': ' + h[key])\n",
        "    print('}\\n')\n",
        "    \n",
        "def plot_len_vs_ndcg(len_to_ndcg_at_100_map):\n",
        "    \n",
        "    lens = list(len_to_ndcg_at_100_map.keys())\n",
        "    lens.sort()\n",
        "    X, Y = [], []\n",
        "    \n",
        "    for le in lens:\n",
        "        X.append(le)\n",
        "        ans = 0.0\n",
        "        for i in len_to_ndcg_at_100_map[le]: ans += float(i)\n",
        "        ans = ans / float(len(len_to_ndcg_at_100_map[le]))\n",
        "        Y.append(ans * 100.0)\n",
        "    \n",
        "    # Smoothening\n",
        "    Y_mine = []\n",
        "    prev_5 = []\n",
        "    for i in Y:\n",
        "        prev_5.append(i)\n",
        "        if len(prev_5) > 5: del prev_5[0]\n",
        "\n",
        "        temp = 0.0\n",
        "        for j in prev_5: temp += float(j)\n",
        "        temp = float(temp) / float(len(prev_5))\n",
        "        Y_mine.append(temp)\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(X, Y_mine, label='SVAE')\n",
        "    plt.xlabel(\"Number of items in the fold-out set\")\n",
        "    plt.ylabel(\"Average NDCG@100\")\n",
        "    plt.title(hyper_params['project_name'])\n",
        "    if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "    plt.savefig(\"saved_plots/seq_len_vs_ndcg_\" + hyper_params['project_name'] + \".pdf\")\n",
        "\n",
        "    leg = plt.legend(loc='best', ncol=2)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogv3LSUm6Ejy",
        "colab_type": "text"
      },
      "source": [
        "# Data Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FA1mzNPj6Ejz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(hyper_params):\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'train.csv')\n",
        "    lines_train = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_tr.csv')\n",
        "    lines_val_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'validation_te.csv')\n",
        "    lines_val_te = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
        "    lines_test_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
        "    lines_test_te = f.readlines()[1:]\n",
        "    \n",
        "    unique_sid = list()\n",
        "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
        "        for line in f:\n",
        "            unique_sid.append(line.strip())\n",
        "    num_items = len(unique_sid)\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
        "\n",
        "    train_reader = DataReader(hyper_params, lines_train, None, num_items, True)\n",
        "    val_reader = DataReader(hyper_params, lines_val_tr, lines_val_te, num_items, False)\n",
        "    test_reader = DataReader(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
        "\n",
        "    return train_reader, val_reader, test_reader, num_items\n",
        "\n",
        "class DataReader:\n",
        "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
        "        self.hyper_params = hyper_params\n",
        "        self.batch_size = hyper_params['batch_size']\n",
        "        \n",
        "        num_users = 0\n",
        "        min_user = 1000000000000000000000000 # Infinity\n",
        "        for line in a:\n",
        "            line = line.strip().split(\",\")\n",
        "            num_users = max(num_users, int(line[0]))\n",
        "            min_user = min(min_user, int(line[0]))\n",
        "        num_users = num_users - min_user + 1\n",
        "        \n",
        "        self.num_users = num_users\n",
        "        self.min_user = min_user\n",
        "        self.num_items = num_items\n",
        "        \n",
        "        self.data_train = a\n",
        "        self.data_test = b\n",
        "        self.is_training = is_training\n",
        "        self.all_users = []\n",
        "        \n",
        "        self.prep()\n",
        "        self.number()\n",
        "\n",
        "    def prep(self):\n",
        "        self.data = []\n",
        "        for i in range(self.num_users): self.data.append([])\n",
        "            \n",
        "        for i in tqdm(range(len(self.data_train))):\n",
        "            line = self.data_train[i]\n",
        "            line = line.strip().split(\",\")\n",
        "            self.data[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "        \n",
        "        if self.is_training == False:\n",
        "            self.data_te = []\n",
        "            for i in range(self.num_users): self.data_te.append([])\n",
        "                \n",
        "            for i in tqdm(range(len(self.data_test))):\n",
        "                line = self.data_test[i]\n",
        "                line = line.strip().split(\",\")\n",
        "                self.data_te[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "                \n",
        "        \n",
        "    def number(self):\n",
        "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
        "    \n",
        "    def iter(self):\n",
        "        users_done = 0\n",
        "\n",
        "        x_batch = []\n",
        "        \n",
        "        user_iterate_order = list(range(len(self.data)))\n",
        "        \n",
        "        # Randomly shuffle the training order\n",
        "        np.random.shuffle(user_iterate_order)\n",
        "        \n",
        "        for user in user_iterate_order:\n",
        "\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            users_done += 1\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(self.data[user]) - 1, self.num_items)\n",
        "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "            \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
        "                x_batch = []\n",
        "\n",
        "    def iter_eval(self):\n",
        "\n",
        "        x_batch = []\n",
        "        test_movies, test_movies_r = [], []\n",
        "        \n",
        "        users_done = 0\n",
        "        \n",
        "        for user in range(len(self.data)):\n",
        "            \n",
        "            users_done += 1\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            \n",
        "            if self.is_training == True: \n",
        "                split = float(self.hyper_params['history_split_test'][0])\n",
        "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
        "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
        "            else:\n",
        "                base_predictions_on = self.data[user]\n",
        "                heldout_movies = self.data_te[user]\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on) - 1, self.num_items).cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            test_movies.append([ i[0] for i in heldout_movies ])\n",
        "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
        "            x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "                \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), test_movies, test_movies_r\n",
        "                x_batch = []\n",
        "                test_movies, test_movies_r = [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnh1jY9De10L",
        "colab_type": "text"
      },
      "source": [
        "# Data Load 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4BsH4k-e1F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data2(hyper_params):\n",
        "      \n",
        "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
        "    lines_test_tr = f.readlines()[1:]\n",
        "    \n",
        "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
        "    lines_test_te = f.readlines()[1:]\n",
        "    \n",
        "    unique_sid = list()\n",
        "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
        "        for line in f:\n",
        "            unique_sid.append(line.strip())\n",
        "    num_items = len(unique_sid)\n",
        "    \n",
        "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
        "\n",
        "    test_reader = DataReader2(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
        "\n",
        "    return test_reader, num_items\n",
        "    \n",
        "class DataReader2:\n",
        "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
        "        self.hyper_params = hyper_params\n",
        "        self.batch_size = hyper_params['batch_size']\n",
        "        \n",
        "        num_users = 0\n",
        "        min_user = 1000000000000000000000000 # Infinity\n",
        "        for line in a:\n",
        "            line = line.strip().split(\",\")\n",
        "            num_users = max(num_users, int(line[0]))\n",
        "            min_user = min(min_user, int(line[0]))\n",
        "        num_users = num_users - min_user + 1\n",
        "        \n",
        "        self.num_users = num_users\n",
        "        self.min_user = min_user\n",
        "        self.num_items = num_items\n",
        "        \n",
        "        self.data_train = a\n",
        "        self.data_test = b\n",
        "        self.is_training = is_training\n",
        "        self.all_users = []\n",
        "        \n",
        "        self.prep()\n",
        "        self.number()\n",
        "\n",
        "    def prep(self):\n",
        "        self.data = []\n",
        "        for i in range(self.num_users): self.data.append([])\n",
        "            \n",
        "        for i in tqdm(range(len(self.data_train))):\n",
        "            line = self.data_train[i]\n",
        "            line = line.strip().split(\",\")\n",
        "            self.data[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "        \n",
        "        if self.is_training == False:\n",
        "            self.data_te = []\n",
        "            for i in range(self.num_users): self.data_te.append([])\n",
        "                \n",
        "            for i in tqdm(range(len(self.data_test))):\n",
        "                line = self.data_test[i]\n",
        "                line = line.strip().split(\",\")\n",
        "                self.data_te[int(line[0]) - self.min_user].append([ int(line[1]), 1 ])\n",
        "                \n",
        "        \n",
        "    def number(self):\n",
        "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
        "    \n",
        "    def iter(self):\n",
        "        users_done = 0\n",
        "\n",
        "        x_batch = []\n",
        "        \n",
        "        user_iterate_order = list(range(len(self.data)))\n",
        "        \n",
        "        # Randomly shuffle the training order\n",
        "        np.random.shuffle(user_iterate_order)\n",
        "        \n",
        "        for user in user_iterate_order:\n",
        "\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            users_done += 1\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(self.data[user]) - 1, self.num_items)\n",
        "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(self.data[user]) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "            \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
        "                x_batch = []\n",
        "\n",
        "    def iter_eval(self):\n",
        "\n",
        "        x_batch = []\n",
        "        test_movies, test_movies_r = [], []\n",
        "        \n",
        "        users_done = 0\n",
        "        \n",
        "        for user in range(len(self.data)):\n",
        "            \n",
        "            users_done += 1\n",
        "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
        "            \n",
        "            if self.is_training == True: \n",
        "                split = float(self.hyper_params['history_split_test'][0])\n",
        "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
        "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
        "            else:\n",
        "                base_predictions_on = self.data[user]\n",
        "                heldout_movies = self.data_te[user]\n",
        "            \n",
        "            y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on) - 1, self.num_items).cuda()\n",
        "            \n",
        "            if self.hyper_params['loss_type'] == 'predict_next':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'next_k':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
        "                    )\n",
        "                \n",
        "            elif self.hyper_params['loss_type'] == 'postfix':\n",
        "                for timestep in range(len(base_predictions_on) - 1):\n",
        "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
        "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:] ]), 1.0\n",
        "                    )\n",
        "            \n",
        "            test_movies.append([ i[0] for i in heldout_movies ])\n",
        "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
        "            x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
        "            \n",
        "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
        "                \n",
        "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), test_movies, test_movies_r\n",
        "                x_batch = []\n",
        "                test_movies, test_movies_r = [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbwU0mfu6Ej2",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CB0s1ZSD6Ej2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0.0\n",
        "    total_users = 0.0\n",
        "    #print (total_users)\n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "\n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "        #print(x, y_s, test_movies, test_movies_r)\n",
        "        batch += 1\n",
        "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "        #if is_train_set == False:\n",
        "          #hyper_params['noise']= noise\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        #print('output decoder')\n",
        "        #print(decoder_output.shape)\n",
        "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "        \n",
        "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "        decoder_output = decoder_output.data\n",
        "        #print('after decoder after criterian')\n",
        "        #print(decoder_output.shape)\n",
        "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        #print('x_scattered')\n",
        "        #print(x_scattered.shape)\n",
        "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "        #print('x scattered after ')\n",
        "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "\n",
        "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "        #print('last pred')\n",
        "        #print(last_predictions.shape)\n",
        "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "            predicted_scores = last_predictions[batch_num]\n",
        "            #print('score')\n",
        "            #print(predicted_scores.shape)\n",
        "\n",
        "            actual_movies_watched = test_movies[batch_num]\n",
        "            actual_movies_ratings = test_movies_r[batch_num]\n",
        "                    \n",
        "            # Calculate NDCG\n",
        "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "            for k in Ks:\n",
        "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                \n",
        "                rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                for m in range(len(actual_movies_watched)):\n",
        "                    movie = actual_movies_watched[m]\n",
        "                    now_at += 1.0\n",
        "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                    \n",
        "                    if movie not in rec_list: continue\n",
        "                    hits += 1.0\n",
        "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                \n",
        "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                \n",
        "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                if k == 100:\n",
        "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                \n",
        "            total_users += 1.0\n",
        "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "    for k in Ks:\n",
        "        metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "        metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "        \n",
        "    return metrics, len_to_ndcg_at_100_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzpbIMYCK65D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8gmmoxbNotf",
        "colab_type": "text"
      },
      "source": [
        "# DCG FOR CORRECT USERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZwpxb1v34t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate1(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0\n",
        "    total_users = 0.0\n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "    #for rounds in num_rounds:\n",
        "    decoder_output_arr = []\n",
        "    decoder_output_arr2 = np.empty((0,20108) ,float)\n",
        "    # print(decoder_output_arr) \n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "\n",
        "        \n",
        "        \n",
        "        #print(x, y_s, test_movies, test_movies_r)\n",
        "        \n",
        "        #print('batch')\n",
        "        #print(batch)\n",
        "        if batch == 1000:\n",
        "          break \n",
        "\n",
        "        else:          \n",
        "          batch += 1\n",
        "\n",
        "        # print('batch')\n",
        "        # print (batch)\n",
        "        # for batch in numpy.arange(2):\n",
        "        #     print(batch)\n",
        "        #     if batch == 2:\n",
        "        #         print('break it')\n",
        "        #         break\n",
        "          if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "\n",
        "          #if is_train_set == False:\n",
        "            #hyper_params['noise']= noise\n",
        "          #print('x')\n",
        "          #print(x)\n",
        "          #print(x.shape)\n",
        "          decoder_output, z_mean, z_log_sigma = model(x)\n",
        "          \n",
        "          # print(decoder_output.shape)\n",
        "          # print(decoder_output)\n",
        "\n",
        "        \n",
        "          metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "          \n",
        "          # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "          decoder_output = decoder_output.data\n",
        "          # test = decoder_output[:, -1, :]\n",
        "          # print('test')\n",
        "          # print(test.shape)\n",
        "          \n",
        "          # print(test)\n",
        "      \n",
        "          \n",
        "          #print('after decoder after criterian')\n",
        "          #print(decoder_output.shape)\n",
        "          x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "          #print('x_scattered')\n",
        "        # print(x_scattered.shape)\n",
        "        # print(x_scattered)\n",
        "          if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "          #print('x scattered after ')\n",
        "          #print(x_scattered)\n",
        "          x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "\n",
        "          last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "          #preds = list(argsorted[:k].cpu().numpy())\n",
        "          # preds = []\n",
        "          # preds = np.array(last_predictions.cpu().numpy())\n",
        "          # print('preds')\n",
        "          # print(preds)\n",
        "          # print(preds.shape)\n",
        "          # decoder_output_arr = np.concatenate((decoder_output_arr,preds))\n",
        "          # print('last_predictions')\n",
        "          # print(last_predictions)\n",
        "          decoder_output_arr.append(last_predictions.cpu().numpy())\n",
        "          decoder_output_arr2 = np.vstack((decoder_output_arr2, last_predictions.cpu().numpy()))\n",
        "          # print('ddddd')\n",
        "          # print(decoder_output_arr)\n",
        "\n",
        "\n",
        "          # print('decoder_output_arr')\n",
        "          # #print(decoder_output_arr.shape)\n",
        "          # print((decoder_output_arr))\n",
        "          #print('last_predictions1')\n",
        "          #last_predictions1 = torch.zeros( ,last_predictions.shape[0], last_predictions.shape[1])\n",
        "          \n",
        "          # print('last_predictions1')\n",
        "          # print(last_predictions1)\n",
        "          # print('decoder_output_arr')\n",
        "          #print(decoder_output_arr.shape)\n",
        "          #print((decoder_output_arr))\n",
        "          \n",
        "          \n",
        "          # print('last pred')\n",
        "          # print(last_predictions.shape)\n",
        "          # print(last_predictions)\n",
        "          # print(last_predictions.shape)\n",
        "          for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "              predicted_scores = last_predictions[batch_num]\n",
        "              # print('batch_num')\n",
        "              # print(batch_num)\n",
        "              # print('predicted score')\n",
        "              # print(predicted_scores.shape)\n",
        "              # print(predicted_scores)\n",
        "\n",
        "              actual_movies_watched = test_movies[batch_num]\n",
        "              actual_movies_ratings = [batch_num]\n",
        "        \n",
        "              # Calculate NDCGtest_movies_r\n",
        "              _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "              # print('arg')\n",
        "              # print(argsorted)\n",
        "              # print(argsorted.shape)\n",
        "              for k in Ks:\n",
        "                  best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                  \n",
        "                  rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                  for m in range(len(actual_movies_watched)):\n",
        "                      movie = actual_movies_watched[m]\n",
        "                      now_at += 1.0\n",
        "                      if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                      \n",
        "                      if movie not in rec_list: continue\n",
        "                      hits += 1.0\n",
        "                      dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                  \n",
        "                  metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                  metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                  metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                  \n",
        "                  # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                  if k == 100:\n",
        "                      seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                      if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                      len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                  \n",
        "              total_users += 1.0\n",
        "            # print('users')\n",
        "            # print(total_users)\n",
        "            # for total_users in numpy.arange(2.0):\n",
        "            #   print('okkkkkkkkkkkkkkkkkkkkk')\n",
        "            #   if total_users == 2.0:\n",
        "\n",
        "            #     break \n",
        "\n",
        "    # print('batchwdqdw')\n",
        "    #print(batch)\n",
        "   \n",
        "    #print(decoder_output_arr)\n",
        "   \n",
        "   \n",
        "    # print(len(batch))\n",
        "    # print('score')\n",
        "    # print(predicted_scores.shape)\n",
        "    # print(predicted_scores) \n",
        "    # print ('total users')        \n",
        "    # print(total_users)\n",
        "    # print ('seq_len')\n",
        "    # print(seq_len)\n",
        "    # print('rec list')\n",
        "    # print(len(rec_list)) \n",
        "\n",
        "    # print(rec_list) \n",
        "     \n",
        "    # print('argsorted')\n",
        "    # print(len(argsorted)) \n",
        "    # print(argsorted)\n",
        "\n",
        "    # print('len_to_ndcg_at_100_map')\n",
        "    # print(len(len_to_ndcg_at_100_map)) \n",
        "    # print(len_to_ndcg_at_100_map)\n",
        "\n",
        "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "    # for k in Ks:\n",
        "\n",
        "    #     print (k)\n",
        "    #     metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "      \n",
        "    #     metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "    #     metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "    # # print ('total users')\n",
        "    # print (total_users)\n",
        "    # print('..............qq..........')\n",
        "    # print('matrics')  \n",
        "    # print (len(metrics)) \n",
        "    # print(metrics)\n",
        "    # print('len_to_ndcg_at_100_map') \n",
        "    # print (len(len_to_ndcg_at_100_map)) \n",
        "    # print('..............22..........')\n",
        "    # print(len_to_ndcg_at_100_map)\n",
        "    return metrics, len_to_ndcg_at_100_map,decoder_output_arr,decoder_output_arr2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GZkdP_oNMny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYeXLAYhNe9d",
        "colab_type": "text"
      },
      "source": [
        "# Fairness_Evaluation_Correct_users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEHMLz9ZcvTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate2(model, criterion, reader, hyper_params, is_train_set, num_rounds):\n",
        "    model.eval()\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    \n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    \n",
        "\n",
        "    decoder_output_list = []\n",
        "    for rounds in range(0,num_rounds):\n",
        "      len_to_ndcg_at_100_map = {}\n",
        "      total_users = 0.0\n",
        "      decoder_output_arr = []\n",
        "      batch = 0\n",
        "      decoder_output_arr2 = np.empty((0,20108) ,float)\n",
        "      for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "          if batch == 1000:\n",
        "            break \n",
        "\n",
        "          else:          \n",
        "            batch += 1\n",
        "\n",
        "            if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "            decoder_output, z_mean, z_log_sigma = model(x)\n",
        "            \n",
        "          \n",
        "            metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "            \n",
        "            # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "            decoder_output = decoder_output.data\n",
        "            \n",
        "            x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "            \n",
        "            if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "            \n",
        "            x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "\n",
        "            last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "            \n",
        "            decoder_output_arr.append(last_predictions.cpu().numpy())\n",
        "            decoder_output_arr2 = np.vstack((decoder_output_arr2, last_predictions.cpu().numpy()))            \n",
        "         \n",
        "            for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "                predicted_scores = last_predictions[batch_num]\n",
        "\n",
        "                actual_movies_watched = test_movies[batch_num]\n",
        "                actual_movies_ratings = [batch_num]\n",
        "          \n",
        "                # Calculate NDCGtest_movies_r\n",
        "                _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "\n",
        "                for k in Ks:\n",
        "                    best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                    \n",
        "                    rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                    for m in range(len(actual_movies_watched)):\n",
        "                        movie = actual_movies_watched[m]\n",
        "                        now_at += 1.0\n",
        "                        if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                        \n",
        "                        if movie not in rec_list: continue\n",
        "                        hits += 1.0\n",
        "                        dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                    \n",
        "                    metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                    metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                    metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                    \n",
        "                    # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                    if k == 100:\n",
        "                        seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                        if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                        len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                    \n",
        "                total_users += 1.0\n",
        "                \n",
        "      decoder_output_list.append(decoder_output_arr2)\n",
        "\n",
        "\n",
        "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "  \n",
        "    return metrics, len_to_ndcg_at_100_map,decoder_output_arr,decoder_output_arr2,decoder_output_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwvKz_l4GssZ",
        "colab_type": "text"
      },
      "source": [
        "# Fairness Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWX5Y5w7Gry-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fairness_evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0\n",
        "    total_users = 0.0\n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "  \n",
        "    decoder_output_arr = []\n",
        "    dcg_arr = []\n",
        "    \n",
        "    inc = 0\n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "        if inc == 10:\n",
        "          break\n",
        "        else:\n",
        "          inc = inc + 1\n",
        "        batch += 1\n",
        "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "        #if is_train_set == False:\n",
        "          #hyper_params['noise']= noise\n",
        "        #print('x')\n",
        "        #print(x)\n",
        "        #print('y_s')\n",
        "        #print(y_s) \n",
        "\n",
        "        # x = x[0:1, 0:5]\n",
        "        # y_s = y_s[0:1, 0:5]\n",
        "\n",
        "\n",
        "        # print(\"=========================\")\n",
        "        # print(x.shape)\n",
        "        # print(x)\n",
        "        # print(\"-------------------------\")\n",
        "        # print(y_s.shape)\n",
        "        # print(y_s)\n",
        "        # print(\"=========================\")\n",
        "        # print(\"\\n\")\n",
        "\n",
        "        \n",
        "\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        # print(\"=========================\")\n",
        "        # x = x[0:1, 0:5]\n",
        "        #print(decoder_output.shape)\n",
        "        # decoder_output = decoder_output[0:1, 0:5]\n",
        "        # y_s = y_s[0:1, 0:5]\n",
        "        # print(decoder_output.shape)\n",
        "        # print(decoder_output)\n",
        "        # print(\"=========================\")\n",
        "        test = decoder_output[:, -1, :]\n",
        "        print(test.shape)\n",
        "        decoder_output_arr.append(test) \n",
        "        print(decoder_output_arr)\n",
        "\n",
        "        #print(decoder_output_arr.size)\n",
        "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "        \n",
        "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "        decoder_output = decoder_output.data\n",
        "        #print('decoder')\n",
        "        #print(decoder_output.shape)\n",
        "       # dec_out = torch.tensor(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        #print ('dec_out.shape')\n",
        "        #print (dec_out.shape)\n",
        "       # print (dec_out)\n",
        "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "        #print('last_predictions')\n",
        "        #last_predictions.shape\n",
        "        #last_predictions\n",
        "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "            predicted_scores = last_predictions[batch_num]\n",
        "            actual_movies_watched = test_movies[batch_num]\n",
        "            actual_movies_ratings = test_movies_r[batch_num]\n",
        "                    \n",
        "            # Calculate NDCG\n",
        "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "            for k in Ks:\n",
        "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                \n",
        "                rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                for m in range(len(actual_movies_watched)):\n",
        "                    movie = actual_movies_watched[m]\n",
        "                    now_at += 1.0\n",
        "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                    \n",
        "                    if movie not in rec_list: continue\n",
        "                    hits += 1.0\n",
        "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "\n",
        "                # metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                # metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                # metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                \n",
        "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                if k == 100:\n",
        "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "            dcg_arr.append(dcg)    \n",
        "            total_users += 1.0\n",
        "    # metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    # metrics['loss'] = round(metrics['loss'], 4)\n",
        "    \n",
        "    # for k in Ks:\n",
        "    #     metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "    #     metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "    #     metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "        \n",
        "    return metrics, len_to_ndcg_at_100_map, decoder_output_arr, dcg_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylgrqwL7s0K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = torch.tensor([1, 2, 3, 4])\n",
        "# y = x.view(1,-1)\n",
        "# print(y[0:1, 0:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMwMOXEv-K0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = torch.tensor([[[ 3.6174,  6.2539,  4.9995, -1.0357, -1.0357, -1.0357],\n",
        "#          [ 3.1265,  6.7381,  4.6916, -1.0037, -1.0037, -1.0037],\n",
        "#          [ 1.7155,  7.0997,  3.6410, -0.8106, -0.8106, -0.8106],\n",
        "#          [ 3.1876,  6.3943,  4.0834, -0.8931, -0.8931, -0.8931],\n",
        "#          [ 3.9237,  6.7369,  4.4088, -0.9200, -0.9200, -0.9200]]])\n",
        "# # print(x)\n",
        "# print(x.shape)\n",
        "# y = x[0:1, 0:3, 0:6]\n",
        "# print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuDa4ipAMHBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z = [x.cpu().numpy(),y.cpu().numpy()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1IiY6WR6Ej5",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDr7l0KUmbV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_noise = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc8rY65yXmOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e0c8Mym6xWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTA-9-Gr8BOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#torch.from_numpy(np.random.uniform(-1, 1, size=100)).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yzBSqNQ96Ej6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(\n",
        "            hyper_params['rnn_size'], hyper_params['hidden_size']\n",
        "        )\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(hyper_params['latent_size'], hyper_params['hidden_size'])\n",
        "        self.linear2 = nn.Linear(hyper_params['hidden_size'], hyper_params['total_items'])\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        nn.init.xavier_normal(self.linear2.weight)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(Model, self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "        # self.noise = hyper_params['noise'] \n",
        "        self.encoder = Encoder(hyper_params)\n",
        "        self.decoder = Decoder(hyper_params)\n",
        "        \n",
        "        # Since we don't need padding, our vocabulary size = \"hyper_params['total_items']\" and not \"hyper_params['total_items'] + 1\"\n",
        "        self.item_embed = nn.Embedding(hyper_params['total_items'], hyper_params['item_embed_size'])\n",
        "        \n",
        "        self.gru = nn.GRU(\n",
        "            hyper_params['item_embed_size'], hyper_params['rnn_size'], \n",
        "            batch_first = True, num_layers = 1\n",
        "        )\n",
        "        \n",
        "        self.linear1 = nn.Linear(hyper_params['hidden_size'], 2 * hyper_params['latent_size'])\n",
        "        nn.init.xavier_normal(self.linear1.weight)\n",
        "        \n",
        "        self.tanh = nn.Tanh()\n",
        "    \n",
        "    def add_noise(self, noise, sigma):\n",
        "        # print(\"Input Noise: \", noise)\n",
        "        return {\n",
        "           1: torch.from_numpy(np.random.normal(0, 0.5, size=sigma.size())).float(),\n",
        "           2: torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float(),\n",
        "           3: torch.from_numpy(np.random.normal(0, 2, size=sigma.size())).float(),\n",
        "           4: torch.from_numpy(np.random.uniform(-1, 1, size=sigma.size())).float(),\n",
        "        }.get(noise, torch.zeros(1))\n",
        "          \n",
        "    def sample_latent(self, h_enc):\n",
        "        \"\"\"\n",
        "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
        "        \"\"\"\n",
        "        temp_out = self.linear1(h_enc)\n",
        "        \n",
        "        mu = temp_out[:, :self.hyper_params['latent_size']]\n",
        "        log_sigma = temp_out[:, self.hyper_params['latent_size']:]\n",
        "        \n",
        "        sigma = torch.exp(log_sigma)\n",
        "#         std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
        "#         if is_cuda_available: std_z = std_z.cuda()\n",
        "\n",
        "        self.z_mean = mu\n",
        "        self.z_log_sigma = log_sigma\n",
        "        \n",
        "        #noise = self.add_noise(2, sigma)\n",
        "        #if is_cuda_available: noise = noise.cuda()  \n",
        "        std_z = self.add_noise(s_noise, sigma)  \n",
        "        # std_z = self.add_noise(self.noise, sigma)        \n",
        "        # std_z = self.add_noise(self.hyper_params['noise'], sigma)\n",
        "        if is_cuda_available: std_z = std_z.cuda()\n",
        "        return mu + sigma * Variable(std_z, requires_grad=False)\n",
        "        #return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
        "#         return mu + noise * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
        "#         return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_shape = x.shape                                      # [bsz x seq_len] = [1 x seq_len]\n",
        "        x = x.view(-1)                                          # [seq_len]\n",
        "        \n",
        "        x = self.item_embed(x)                                  # [seq_len x embed_size]\n",
        "        x = x.view(in_shape[0], in_shape[1], -1)                # [1 x seq_len x embed_size]\n",
        "        \n",
        "        rnn_out, _ = self.gru(x)                                # [1 x seq_len x rnn_size]\n",
        "        rnn_out = rnn_out.view(in_shape[0] * in_shape[1], -1)   # [seq_len x rnn_size]\n",
        "        \n",
        "        enc_out = self.encoder(rnn_out)                         # [seq_len x hidden_size]\n",
        "        sampled_z = self.sample_latent(enc_out)                 # [seq_len x latent_size]\n",
        "        \n",
        "        dec_out = self.decoder(sampled_z)                       # [seq_len x total_items]\n",
        "        dec_out = dec_out.view(in_shape[0], in_shape[1], -1)    # [1 x seq_len x total_items]\n",
        "                              \n",
        "        return dec_out, self.z_mean, self.z_log_sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tmTDgAo6Ej8",
        "colab_type": "text"
      },
      "source": [
        "# Custom loss\n",
        "\n",
        "$$ Loss \\; = \\; \\sum_{u \\in U} Loss_u $$ <br>\n",
        "$$ Loss_u \\; = \\; \\beta * KL( \\, \\phi(z \\vert x) \\, \\Vert \\, {\\rm I\\!N(0, I)} \\, ) \\; - \\; log( \\, P_{\\phi}(g_{\\theta}(x)) \\, ) $$ <br>\n",
        "$ g_{\\theta}(.)$ is the encoder ; $P_{\\phi}(.)$ is the decoded distribution; $ \\beta $ is the anneal factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jH_iYZJ36Ej9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAELoss(torch.nn.Module):\n",
        "    def __init__(self, hyper_params):\n",
        "        super(VAELoss,self).__init__()\n",
        "        self.hyper_params = hyper_params\n",
        "\n",
        "    def forward(self, decoder_output, mu_q, logvar_q, y_true_s, anneal):\n",
        "        # Calculate KL Divergence loss\n",
        "        kld = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1), -1))\n",
        "    \n",
        "        # Calculate Likelihood\n",
        "        dec_shape = decoder_output.shape # [batch_size x seq_len x total_items] = [1 x seq_len x total_items]\n",
        "\n",
        "        decoder_output = F.log_softmax(decoder_output, -1)\n",
        "        num_ones = float(torch.sum(y_true_s[0, 0]))\n",
        "        \n",
        "        likelihood = torch.sum(\n",
        "            -1.0 * y_true_s.view(dec_shape[0] * dec_shape[1], -1) * \\\n",
        "            decoder_output.view(dec_shape[0] * dec_shape[1], -1)\n",
        "        ) / (float(self.hyper_params['batch_size']) * num_ones)\n",
        "        \n",
        "        final = (anneal * kld) + (likelihood)\n",
        "        \n",
        "        return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAct2_kz6Ej_",
        "colab_type": "text"
      },
      "source": [
        "# Test Fairness Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H6UGt-T7zqB",
        "colab_type": "code",
        "outputId": "37269e20-890b-414e-fe02-167ef7521126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "\n",
        "ufairs_arr = []\n",
        "ndcgs_arr = []\n",
        "num_users = 1000\n",
        "num_items = 100\n",
        "num_rounds = 2\n",
        "#batch_to_pick = 0 #randint(0, len(decoder_output_arr)-1) #pickes random batch\n",
        "\n",
        "test_reader, total_items = load_data2(hyper_params)\n",
        "final_dcg = None\n",
        "# for s_noise in range(0, 5):\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "criterion = VAELoss(hyper_params)\n",
        "#metrics, len_to_ndcg_at_100_map, decoder_output_arr, dcg_arr = fairness_evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "    #print(decoder_output_arr.shape)\n",
        "\n",
        "metrics, len_to_ndcg_at_100_map,decoder_output_arr,decoder_output_arr2 = evaluate1(model, criterion, test_reader, hyper_params, False)\n",
        "#print(decoder_output_arr2.shape)\n",
        "# print('evaluate1') \n",
        "\n",
        "# num_rounds = 10\n",
        "topkItens = np.argsort(decoder_output_arr2)[:,-num_items:]\n",
        "predsn = []\n",
        "for user in range(topkItens.shape[0]):\n",
        "\n",
        "   predsn.append(decoder_output_arr2[user,sorted(topkItens[user,:])])\n",
        "predsn = np.array(predsn)\n",
        "#print(predsn)\n",
        "\n",
        "dcg_gt = dcg_k_users(predsn)\n",
        "\n",
        "print('evaluate2') \n",
        "#print(decoder_output_list)\n",
        "#print((np.array(decoder_output_list).shape))\n",
        "\n",
        "# for s_noise in range(0, 5):\n",
        "\n",
        "#   metrics, len_to_ndcg_at_100_map,decoder_output_arr,decoder_output_arr2,decoder_output_list  = evaluate2(model, criterion, test_reader, hyper_params, False, num_rounds)\n",
        "#       preds_k_rounds_filter = np.zeros((num_rounds,num_users,num_items))\n",
        "#     for user in range(num_users):\n",
        "#         preds_k_rounds_filter[:,user,:] = preds_k_rounds[:,user,sorted(topkItens[user,:])]\n",
        "    \n",
        "#     #preds_k_rounds = preds_k_rounds[:,:,sorted(topkItens)]\n",
        "#     preds_k_rounds_filter = np.array(preds_k_rounds_filter)\n",
        "#     print(preds_k_rounds_filter.shape)\n",
        "    \n",
        "#     ufairs, ndcgs = Fairness_at_k_rounds(decoder_output_list, dcg_gt)\n",
        "\n",
        "\n",
        "\n",
        "# print(decoder_output_arr2.shape)\n",
        "# print(np.array([decoder_output_arr2, decoder_output_arr2]).shape)\n",
        "\n",
        "\n",
        "# decoder_output_arr = np.array(decoder_output_arr) \n",
        "# print(decoder_output_arr)\n",
        "# print(decoder_output_arr.shape)\n",
        "#print()\n",
        "# print('preds')\n",
        "# print(preds)\n",
        "# preds.shape\n",
        "    #final_pred = Batch_selection_fairness(decoder_output_arr)\n",
        "    #if final_dcg == None:\n",
        "\n",
        "     #final_dcg = calcualte_final_dcg(decoder_output_arr)\n",
        "   # print(\"Final DCG: \",final_dcg)\n",
        "#ufairs, ndcgs = Fairness_at_k_rounds(decoder_output_list, dcg_gt)\n",
        "#   print(\"For Noise = \"+ str(s_noise))\n",
        "#   #print(\"Final NDCGs: \",ndcgs)\n",
        "#   print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#   #plot_comparison([ufairs],[1-ndcgs],['original'],'dataset','test_file')\n",
        "#   ufairs_arr.append(ufairs)\n",
        "#   ndcgs_arr.append(ndcgs)\n",
        "#   print(\"\\n\\n\")\n",
        "# #print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "# # plot_comparison([ufairs_arr[0]],[1-ndcgs_arr[0]],['original'],'dataset','test_file')\n",
        "    \n",
        "\n",
        "\n",
        "# # plot_comparison([ufairs_arr[1]],[1-ndcgs_arr[1]],['N(std=0.5)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "# # plot_comparison([ufairs_arr[2]],[1-ndcgs_arr[2]],['N(std=1)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "# # plot_comparison([ufairs_arr[3]],[1-ndcgs_arr[3]],['N(std=2)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "# # plot_comparison([ufairs_arr[4]],[1-ndcgs_arr[4]],['uniform'],'dataset','test_file')  \n",
        "\n",
        "# # plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3]],['N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "# plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3], ufairs_arr[4]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3],1-ndcgs_arr[4]],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "\n",
        "# # Plot sequence length vs NDCG@100 graph\n",
        "# # plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "# # string = \"\"\n",
        "# # for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "# # ss  = '=' * 89\n",
        "# # ss += '\\n| End of training'\n",
        "# # ss += string + \" (TEST)\"\n",
        "# # ss += '\\n'\n",
        "# # ss += '=' * 89\n",
        "# # file_write(hyper_params['log_file'], ss)\n",
        "# # print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")\n",
        "\n",
        "# # plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3]],['N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "# #plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3], ufairs_arr[4]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3],1-ndcgs_arr[4]],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "\n",
        "# # Plot sequence length vs NDCG@100 graph\n",
        "# # plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "# # string = \"\"\n",
        "# # for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "# # ss  = '=' * 89\n",
        "# # ss += '\\n| End of training'\n",
        "# # ss += string + \" (TEST)\"\n",
        "# # ss += '\\n'\n",
        "# # ss += '=' * 89\n",
        "# # file_write(hyper_params['log_file'], ss)\n",
        "# # print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 571057/571057 [00:00<00:00, 592282.89it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 799849.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluate2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ8VJT_Pwl3o",
        "colab_type": "code",
        "outputId": "cb739121-68ca-41ca-db66-8ded236425e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "decoder_output_arr2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.84242916e+00,  5.43675375e+00,  5.71865129e+00, ...,\n",
              "        -8.97110999e-01, -8.96381676e-01, -9.05451059e-01],\n",
              "       [ 2.77869630e+00,  4.69403887e+00,  3.99798846e+00, ...,\n",
              "        -1.00980031e+00, -1.00913858e+00, -1.00606370e+00],\n",
              "       [ 3.58510351e+00,  7.58163595e+00,  4.96862841e+00, ...,\n",
              "        -1.04517829e+00, -1.04415154e+00, -1.04947221e+00],\n",
              "       ...,\n",
              "       [ 3.77632761e+00,  1.61237574e+00,  2.33274055e+00, ...,\n",
              "        -8.77100646e-01, -8.76438141e-01, -8.75629425e-01],\n",
              "       [ 4.00387573e+00, -6.59056896e+08,  4.08010244e+00, ...,\n",
              "        -8.61356795e-01, -8.63690913e-01, -8.59815359e-01],\n",
              "       [-7.63807360e+08,  1.02963018e+00,  2.73184443e+00, ...,\n",
              "        -7.90739000e-01, -7.89567649e-01, -7.85310388e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqsVc2Cxj7Zt",
        "colab_type": "code",
        "outputId": "e5a97857-243e-4921-a4fe-7f9ede24b848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "\n",
        "ufairs_arr = []\n",
        "ndcgs_arr = []\n",
        "num_users = 1000\n",
        "num_items = 100\n",
        "num_rounds = 2\n",
        "\n",
        "test_reader, total_items = load_data2(hyper_params)\n",
        "\n",
        "for s_noise in range(0, 5):\n",
        "\n",
        "  hyper_params['total_items'] = total_items\n",
        "  hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "  criterion = VAELoss(hyper_params)\n",
        "  metrics, len_to_ndcg_at_100_map,decoder_output_arr,decoder_output_arr2,decoder_output_list  = evaluate2(model, criterion, test_reader, hyper_params, False, num_rounds)\n",
        "  final_pred = decoder_output_list\n",
        "  #print(final_pred.shape)\n",
        "  final_pred = np.array(final_pred)\n",
        "  print(final_pred.shape)\n",
        "  preds_k_rounds_filter = np.zeros((num_rounds,num_users,num_items))\n",
        "  for user in range(num_users):\n",
        "\n",
        "    preds_k_rounds_filter[:,user,:] = final_pred[:,user,sorted(topkItens[user,:])]\n",
        "  preds_k_rounds_filter = np.array(preds_k_rounds_filter)\n",
        "  print(preds_k_rounds_filter.shape) \n",
        "  ufairs, ndcgs = Fairness_at_k_rounds(preds_k_rounds_filter, dcg_gt)\n",
        "  print(\"For Noise = \"+ str(s_noise))\n",
        "  #print(\"Final NDCGs: \",ndcgs)\n",
        "  print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "  #plot_comparison([ufairs],[1-ndcgs],['original'],'dataset','test_file')\n",
        "  ufairs_arr.append(ufairs)\n",
        "  ndcgs_arr.append(ndcgs) \n",
        "\n",
        "plot_comparison([ufairs_arr[0]],[1-ndcgs_arr[0]],['original'],'dataset','test_file')\n",
        "    \n",
        "\n",
        "\n",
        "plot_comparison([ufairs_arr[1]],[1-ndcgs_arr[1]],['N(std=0.5)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "plot_comparison([ufairs_arr[2]],[1-ndcgs_arr[2]],['N(std=1)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "plot_comparison([ufairs_arr[3]],[1-ndcgs_arr[3]],['N(std=2)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n",
        "plot_comparison([ufairs_arr[4]],[1-ndcgs_arr[4]],['uniform'],'dataset','test_file')  \n",
        "\n",
        "plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3], ufairs_arr[4]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3],1-ndcgs_arr[4]],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "\n",
        "  #round_batch = final_pred[0:num_rounds, 0:num_users, 0:num_items]\n",
        "  #.cpu().numpy()[0]\n",
        "  #topkItens = np.argsort(decoder_output_arr2)[:,-num_items:]\n",
        "  # print(final_pred.shape)\n",
        "  # rounds = np.zeros((num_rounds,num_users,num_items))\n",
        "  # for user in range(num_users):\n",
        "  #   final_pred[:,user,:] = final_pred[:,user,sorted(topkItens[user,:])]\n",
        "\n",
        "  # ufairs, ndcgs = Fairness_at_k_rounds(decoder_output_list, dcg_gt)  \n",
        "  #   #preds_k_rounds = preds_k_rounds[:,:,sorted(topkItens)]\n",
        "  #   #final_pred = np.array(final_pred)\n",
        "  #   #print(preds_k_rounds_filter.shape)\n",
        "  # print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "\n",
        "  # # print(\"Final DCG: \",final_dcg)\n",
        "  #   #ufairs, ndcgs = Fairness_at_k_rounds(final_pred, dcg_gt)\n",
        "    #print(\"For Noise = \"+ str(s_noise))\n",
        "  #print(\"Final NDCGs: \",ndcgs)\n",
        "    #print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "    #plot_comparison([ufairs],[1-ndcgs],['original'],'dataset','test_file')\n",
        "    #ufairs_arr.append(ufairs)\n",
        "    #ndcgs_arr.append(ndcgs)\n",
        "    #print(\"\\n\\n\")\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "\n",
        "# plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3]],['N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "#plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3], ufairs_arr[4]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3],1-ndcgs_arr[4]],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "# plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "# string = \"\"\n",
        "# for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "# ss  = '=' * 89\n",
        "# ss += '\\n| End of training'\n",
        "# ss += string + \" (TEST)\"\n",
        "# ss += '\\n'\n",
        "# ss += '=' * 89\n",
        "# file_write(hyper_params['log_file'], ss)\n",
        "# print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")\n",
        "\n",
        "# plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3]],['N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "#plot_comparison([ufairs_arr[0],ufairs_arr[1], ufairs_arr[2], ufairs_arr[3], ufairs_arr[4]],[1-ndcgs_arr[0],1-ndcgs_arr[1], 1-ndcgs_arr[2],1-ndcgs_arr[3],1-ndcgs_arr[4]],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], 'dataset', 'test_file')\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "# plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "# string = \"\"\n",
        "# for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "# ss  = '=' * 89\n",
        "# ss += '\\n| End of training'\n",
        "# ss += string + \" (TEST)\"\n",
        "# ss += '\\n'\n",
        "# ss += '=' * 89\n",
        "# file_write(hyper_params['log_file'], ss)\n",
        "# print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 571057/571057 [00:01<00:00, 454378.31it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 782086.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(2, 1000, 20108)\n",
            "(2, 1000, 100)\n",
            "----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\n",
            "[[[6.12918329 6.45644569 6.50950289 ... 5.24839592 3.17606497 5.04203129]\n",
            "  [3.92926741 4.63713551 2.87619543 ... 4.67377853 4.23945618 4.43255711]\n",
            "  [9.14099312 6.8958807  5.73198462 ... 4.33368206 7.54876137 5.80649424]\n",
            "  ...\n",
            "  [6.03949642 5.94505119 6.70614719 ... 6.65471935 7.58527279 7.89289331]\n",
            "  [6.72234726 7.42150879 7.75378752 ... 5.56758261 5.88057804 3.68379664]\n",
            "  [6.51830053 5.90593719 5.08265734 ... 6.85422325 5.87170315 5.2691288 ]]\n",
            "\n",
            " [[6.12918329 6.45644569 6.50950289 ... 5.24839592 3.17606497 5.04203129]\n",
            "  [3.92926741 4.63713551 2.87619543 ... 4.67377853 4.23945618 4.43255711]\n",
            "  [9.14099312 6.8958807  5.73198462 ... 4.33368206 7.54876137 5.80649424]\n",
            "  ...\n",
            "  [6.03949642 5.94505119 6.70614719 ... 6.65471935 7.58527279 7.89289331]\n",
            "  [6.72234726 7.42150879 7.75378752 ... 5.56758261 5.88057804 3.68379664]\n",
            "  [6.51830053 5.90593719 5.08265734 ... 6.85422325 5.87170315 5.2691288 ]]]\n",
            "-----------------------------------------------------------------------------------\n",
            "For Noise = 0\n",
            "0.09318456229233091 0.02662984117376765 0.9784975131545597 0.11519797010960672\n",
            "(2, 1000, 20108)\n",
            "(2, 1000, 100)\n",
            "----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\n",
            "[[[5.71228981 5.4404459  4.46227217 ... 4.94734955 4.09164524 5.2776022 ]\n",
            "  [4.11329603 3.87420392 1.00611806 ... 3.71494889 3.29266691 3.01246905]\n",
            "  [9.3302536  5.90401268 5.18083    ... 3.75032926 7.46551895 4.8146348 ]\n",
            "  ...\n",
            "  [8.38646221 7.48955917 9.59365273 ... 6.64587212 6.73144817 7.96450758]\n",
            "  [6.1024003  7.65481615 7.11660957 ... 6.41962814 5.27815533 3.30656433]\n",
            "  [4.98705578 6.18538618 5.0256381  ... 7.21399736 6.3860321  5.32957029]]\n",
            "\n",
            " [[4.67090416 4.15487528 3.90821505 ... 4.03506899 3.84639454 4.8539629 ]\n",
            "  [2.8148365  3.3005867  1.53613448 ... 4.01878166 3.57463765 2.84662795]\n",
            "  [8.09812164 2.91396761 3.96380448 ... 2.02233171 7.87857437 2.97974038]\n",
            "  ...\n",
            "  [5.55947256 5.24438047 4.55377865 ... 5.90842342 7.66129112 7.98367643]\n",
            "  [3.87737846 5.93138313 5.98318958 ... 5.49983263 5.64816046 3.64743114]\n",
            "  [5.45996904 5.89576149 3.91714334 ... 5.24445105 4.58828688 3.65262008]]]\n",
            "-----------------------------------------------------------------------------------\n",
            "For Noise = 1\n",
            "0.07815341933246074 0.019836604256193626 0.8869788824887629 0.12778665991180474\n",
            "(2, 1000, 20108)\n",
            "(2, 1000, 100)\n",
            "----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\n",
            "[[[ 2.41215181  0.89203238  0.42634878 ...  1.67053068  1.25107586\n",
            "    2.90097642]\n",
            "  [ 6.56238699  3.68640423  1.6549108  ...  5.00244093  4.94534445\n",
            "    4.21930695]\n",
            "  [ 5.88045263  4.67556095  4.35082531 ...  2.2191124   3.29619884\n",
            "    6.05259466]\n",
            "  ...\n",
            "  [ 3.65563869  2.82516646  5.63586807 ...  4.0428772   6.59858131\n",
            "    6.53796148]\n",
            "  [ 5.95195293  1.01753688  8.05820465 ...  6.64472008  2.26011205\n",
            "    0.12625095]\n",
            "  [ 2.18961382  9.85210896  2.68301606 ...  3.52248168  2.87518072\n",
            "    3.87203503]]\n",
            "\n",
            " [[ 6.397861    6.81335258  6.64715719 ...  2.0424633   2.06473923\n",
            "    3.50581717]\n",
            "  [ 0.66757596  2.2119391   1.20742285 ...  4.14753246  3.69982982\n",
            "    3.01675248]\n",
            "  [ 4.51322412  1.53620303 -0.26882899 ...  3.96120167  4.53149843\n",
            "    6.29802895]\n",
            "  ...\n",
            "  [ 4.80284834  5.64305544  6.11731148 ...  3.68193364  4.14382935\n",
            "    5.75249386]\n",
            "  [ 3.14790797  2.51844692  1.8239274  ...  2.0108974   3.51861882\n",
            "    5.494102  ]\n",
            "  [ 6.61384869  6.25702715  6.65409422 ...  6.13113117  4.40525913\n",
            "    4.29283381]]]\n",
            "-----------------------------------------------------------------------------------\n",
            "For Noise = 2\n",
            "0.07269752672691601 0.018291313314404666 0.7182502324635166 0.15344922082103352\n",
            "(2, 1000, 20108)\n",
            "(2, 1000, 100)\n",
            "----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\n",
            "[[[ 7.789361    1.08076119  2.0246551  ...  2.77838087  2.1804862\n",
            "    1.85128486]\n",
            "  [ 0.80976009  3.26289797  2.58089161 ...  3.91247749  0.89736617\n",
            "    1.52214956]\n",
            "  [ 6.97015905  7.1526494   7.24912357 ...  2.38617277  5.36904621\n",
            "    1.8872112 ]\n",
            "  ...\n",
            "  [ 1.77482641  3.3888576   3.18171287 ...  3.97244525  3.86449862\n",
            "    5.25538874]\n",
            "  [ 5.68615532  3.81646967  5.38504982 ... -3.27063751  0.21078396\n",
            "    4.05069876]\n",
            "  [ 1.87960863  2.29246497  0.80283648 ...  5.54888868  2.53550029\n",
            "    3.48811197]]\n",
            "\n",
            " [[ 4.33444357  3.81948328  4.49849463 ...  3.34580946  1.49679005\n",
            "    4.3983345 ]\n",
            "  [ 5.62769651  5.76397848  3.91521239 ...  2.31133509  4.13724518\n",
            "    2.98427939]\n",
            "  [ 5.62070227  5.24997425  3.94526339 ...  3.60671616  0.84621662\n",
            "    7.93826151]\n",
            "  ...\n",
            "  [ 4.73870659  3.9934237   3.6620369  ...  1.62381005  4.10415649\n",
            "    3.68155098]\n",
            "  [ 2.41665888  1.97600663  2.73844218 ...  4.14287567  5.12220526\n",
            "    4.02195597]\n",
            "  [ 1.95628166  3.73791933  1.07352877 ...  5.51178694  3.77193928\n",
            "    4.06431866]]]\n",
            "-----------------------------------------------------------------------------------\n",
            "For Noise = 3\n",
            "0.0710165258112163 0.019146965299046397 0.5112350241986752 0.19142809247681097\n",
            "(2, 1000, 20108)\n",
            "(2, 1000, 100)\n",
            "----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\n",
            "[[[6.25824976 5.11480618 5.90762043 ... 4.63638496 2.98326325 3.60939097]\n",
            "  [2.58110428 6.22469664 4.75762033 ... 2.80128956 3.73146582 3.40050387]\n",
            "  [8.41908169 6.49519205 4.73073912 ... 3.23749137 7.28933907 5.43512106]\n",
            "  ...\n",
            "  [4.1990819  4.49698925 6.19934893 ... 5.36499357 6.58942127 7.26422977]\n",
            "  [3.72630262 5.36497402 5.33545303 ... 2.38446879 3.31010795 4.83964777]\n",
            "  [4.84625196 6.68000984 3.06326079 ... 4.82690668 4.18769026 3.13816571]]\n",
            "\n",
            " [[5.3819232  6.42872095 4.8175087  ... 4.00654459 4.36059046 5.30182934]\n",
            "  [4.82660627 5.85865211 3.81347847 ... 5.20368624 5.13860703 4.70754814]\n",
            "  [8.42117882 6.13064241 5.78244162 ... 6.0552454  8.20114803 6.29604101]\n",
            "  ...\n",
            "  [6.50343561 6.3374939  8.34054565 ... 6.06358862 5.63518238 6.90795803]\n",
            "  [4.3876152  7.22092438 6.73251915 ... 3.40302229 4.88996077 3.37165761]\n",
            "  [5.18288326 5.02991819 4.43831062 ... 7.19158649 6.67284966 5.94938803]]]\n",
            "-----------------------------------------------------------------------------------\n",
            "For Noise = 4\n",
            "0.07748923183611464 0.019160940742068075 0.862025450545574 0.12696272838033343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-314ffbd0cdea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mndcgs_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndcgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mplot_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mufairs_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mndcgs_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-0c40cc9f85a2>\u001b[0m in \u001b[0;36mplot_comparison\u001b[0;34m(data_a, data_b, ticks, dataset, test_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq91hkoZwUsM",
        "colab_type": "code",
        "outputId": "50ff32a2-dc3a-4040-96ed-1d88e2975740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "round_batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 6.53450775e+00,  5.71905851e+00,  5.43483400e+00,\n",
              "         -1.27266392e-01,  4.91815805e+00,  5.71076345e+00,\n",
              "          5.09895086e+00, -5.84061440e+08,  7.91464710e+00,\n",
              "          6.47825670e+00],\n",
              "        [ 3.54956806e-01,  1.67045283e+00,  8.58583093e-01,\n",
              "         -2.75948048e+00,  1.57211006e+00,  2.50957942e+00,\n",
              "          1.17480123e+00, -2.64591792e+08,  6.08632386e-01,\n",
              "         -3.03320352e+08],\n",
              "        [ 3.96126890e+00,  9.70522976e+00,  6.14833975e+00,\n",
              "          3.17848992e+00,  3.63779998e+00,  4.59124374e+00,\n",
              "          6.78016949e+00,  5.88521910e+00,  3.70954847e+00,\n",
              "          5.48808289e+00],\n",
              "        [ 2.51215839e+00,  2.91567445e+00,  1.12445593e+00,\n",
              "          3.07769728e+00,  3.71527076e+00,  2.85459709e+00,\n",
              "          8.74073148e-01,  3.51849031e+00,  1.26324594e+00,\n",
              "          2.28223467e+00],\n",
              "        [ 3.61823201e+00,  5.03648138e+00,  4.02042627e+00,\n",
              "          7.47110605e-01,  1.58059323e+00, -4.71772448e+08,\n",
              "          3.77919841e+00, -3.13602176e+08, -3.54710752e+08,\n",
              "         -3.42763328e+08],\n",
              "        [ 6.20281029e+00,  2.73059750e+00,  2.06809735e+00,\n",
              "          5.01805878e+00,  5.00350094e+00,  1.82227850e+00,\n",
              "          1.33998466e+00,  4.34592390e+00,  3.39626551e+00,\n",
              "          3.76062083e+00],\n",
              "        [ 2.11249948e+00,  7.21300411e+00,  4.45388937e+00,\n",
              "          2.34890223e+00,  3.00376534e+00,  3.95779920e+00,\n",
              "          6.83330774e+00,  5.37376213e+00,  1.50747049e+00,\n",
              "          3.40054178e+00],\n",
              "        [ 5.07453442e+00, -6.08592064e+08,  5.78462839e+00,\n",
              "          3.30825663e+00,  6.18998241e+00,  8.66960239e+00,\n",
              "         -7.04497472e+08,  4.09585619e+00,  6.62142277e+00,\n",
              "          6.17747021e+00],\n",
              "        [ 3.77657509e+00,  7.33758688e+00,  7.68111372e+00,\n",
              "          1.23566046e-01,  4.18795919e+00,  4.93219328e+00,\n",
              "          7.13740873e+00,  6.64172173e+00,  4.83114815e+00,\n",
              "          5.71455050e+00],\n",
              "        [ 2.92955518e+00, -4.22964768e+08, -2.06977920e+08,\n",
              "          1.06305420e+00,  3.67236912e-01,  4.57619953e+00,\n",
              "         -3.18288800e+08, -1.99239952e+08,  1.04276943e+00,\n",
              "         -4.79587136e+08],\n",
              "        [-5.51601152e+08,  5.53106403e+00, -6.28048768e+08,\n",
              "          5.44682789e+00, -6.80249600e+08,  6.35926342e+00,\n",
              "          7.38927221e+00,  6.23548651e+00, -4.73692800e+08,\n",
              "          4.19129705e+00],\n",
              "        [ 6.67265034e+00,  2.43164277e+00,  2.73844028e+00,\n",
              "          5.39230633e+00,  5.12545013e+00,  5.81011057e+00,\n",
              "          1.53781033e+00,  5.01725388e+00,  3.95927787e+00,\n",
              "          6.44575357e+00],\n",
              "        [ 4.67393303e+00,  2.32133603e+00,  1.87268686e+00,\n",
              "          3.40772247e+00,  1.78768873e+00,  2.76471210e+00,\n",
              "          7.40376472e-01,  3.94886541e+00,  1.60681903e+00,\n",
              "          3.00437045e+00],\n",
              "        [ 2.38908505e+00,  3.80193257e+00,  2.00879812e+00,\n",
              "          1.51843143e+00,  3.64487958e+00, -4.15359200e+08,\n",
              "          4.06323290e+00,  4.75873852e+00, -3.73576224e+08,\n",
              "          3.23833728e+00],\n",
              "        [ 1.53612900e+00, -5.06919392e+08, -5.15495648e+08,\n",
              "          1.49190381e-01,  2.15910602e+00,  2.99713850e+00,\n",
              "          4.35139656e+00,  4.22430086e+00,  2.57155180e+00,\n",
              "          3.25081754e+00],\n",
              "        [ 4.26667356e+00, -5.54936409e-01, -2.75916874e-01,\n",
              "          6.26309061e+00,  1.88359451e+00,  1.09303808e+00,\n",
              "          7.90914774e-01,  8.75162721e-01,  1.68432379e+00,\n",
              "         -1.21087968e-01],\n",
              "        [ 2.11890769e+00, -4.83556224e+08,  2.90539408e+00,\n",
              "         -7.55350888e-01,  1.58064520e+00,  3.01856542e+00,\n",
              "          4.96001863e+00,  2.60305166e+00,  2.07333827e+00,\n",
              "          3.83825207e+00],\n",
              "        [ 4.67821264e+00,  2.41611528e+00,  1.11620009e+00,\n",
              "          6.18493319e+00,  3.32936692e+00,  3.84686065e+00,\n",
              "          1.24875951e+00,  3.78523684e+00,  1.52017510e+00,\n",
              "          2.77339029e+00],\n",
              "        [ 4.81435871e+00,  4.59581041e+00,  1.37223172e+00,\n",
              "          2.89075065e+00,  3.97016597e+00,  5.26095343e+00,\n",
              "          1.76061881e+00,  5.75494385e+00,  2.51333761e+00,\n",
              "          4.46623707e+00],\n",
              "        [-5.89689664e+08,  7.78553247e+00,  6.40084887e+00,\n",
              "          6.49437046e+00,  6.79521561e+00,  8.26359653e+00,\n",
              "          6.96938467e+00,  7.90441799e+00,  6.52135849e+00,\n",
              "          7.31039524e+00],\n",
              "        [ 6.37341213e+00,  4.38132763e+00,  6.06009340e+00,\n",
              "          5.64224434e+00,  6.06013966e+00,  4.83526993e+00,\n",
              "          4.81479406e+00,  7.00084925e+00,  7.17012405e+00,\n",
              "          5.73674345e+00],\n",
              "        [ 1.32325399e+00, -2.59296272e+08,  8.76199722e-01,\n",
              "         -5.00958264e-02,  2.18504596e+00,  3.09594297e+00,\n",
              "          2.40720177e+00, -2.09799936e+08, -9.31361440e+07,\n",
              "         -3.22352064e+08],\n",
              "        [ 6.67236662e+00,  2.25635529e+00,  3.07370019e+00,\n",
              "          5.79150534e+00,  8.39639568e+00,  4.75582218e+00,\n",
              "          3.14879131e+00,  8.99732399e+00,  7.44415331e+00,\n",
              "          7.63911724e+00],\n",
              "        [ 2.18951154e+00, -3.06010496e+08,  2.27933645e+00,\n",
              "          2.63765907e+00,  1.58858657e+00,  3.93490696e+00,\n",
              "          4.42530441e+00,  1.24589038e+00,  2.50111413e+00,\n",
              "         -2.31840688e+08],\n",
              "        [-8.13135552e+08,  4.29087305e+00,  3.94070745e+00,\n",
              "          4.66781521e+00,  6.82093859e+00,  6.47689390e+00,\n",
              "          2.87167454e+00,  7.48971367e+00,  7.70591068e+00,\n",
              "          7.69646692e+00]],\n",
              "\n",
              "       [[ 6.84242916e+00,  5.43675375e+00,  5.71865129e+00,\n",
              "          1.22289240e+00,  2.96712232e+00,  4.53856850e+00,\n",
              "          5.60913038e+00, -4.79050080e+08,  7.06723881e+00,\n",
              "          6.66734266e+00],\n",
              "        [ 2.77869630e+00,  4.69403887e+00,  3.99798846e+00,\n",
              "          1.20239568e+00,  5.90851927e+00,  5.40856838e+00,\n",
              "          3.32798028e+00, -6.46595008e+08,  5.23311329e+00,\n",
              "         -6.75407808e+08],\n",
              "        [ 3.58510351e+00,  7.58163595e+00,  4.96862841e+00,\n",
              "          2.25482082e+00,  3.69455552e+00,  2.95056224e+00,\n",
              "          5.37914467e+00,  5.90923691e+00,  5.00355673e+00,\n",
              "          6.03836966e+00],\n",
              "        [ 3.49325562e+00,  3.22942328e+00,  1.75197423e+00,\n",
              "          3.45135403e+00,  4.15574169e+00,  3.70320654e+00,\n",
              "          1.68288064e+00,  3.93958616e+00,  2.30376101e+00,\n",
              "          2.66431212e+00],\n",
              "        [ 5.33529615e+00,  4.86861849e+00,  5.84989834e+00,\n",
              "          1.41139054e+00,  2.47929668e+00, -5.26808800e+08,\n",
              "          4.63107491e+00, -4.57157216e+08, -4.90668096e+08,\n",
              "         -4.28986400e+08],\n",
              "        [ 4.81860542e+00,  2.37447333e+00,  1.75239873e+00,\n",
              "          3.54821777e+00,  4.13511992e+00,  1.05309021e+00,\n",
              "          5.98569632e-01,  3.91651154e+00,  1.77122915e+00,\n",
              "          1.97642517e+00],\n",
              "        [ 1.53315544e+00,  8.95553017e+00,  4.84244776e+00,\n",
              "         -4.14078057e-01,  2.66654658e+00,  4.53387785e+00,\n",
              "          6.20349169e+00,  5.12072086e+00,  3.97845840e+00,\n",
              "          4.07382774e+00],\n",
              "        [ 5.37339592e+00, -5.31200640e+08,  5.26482248e+00,\n",
              "          2.90442419e+00,  5.36574793e+00,  8.00801754e+00,\n",
              "         -6.29850048e+08,  3.83533096e+00,  6.42295599e+00,\n",
              "          4.84411907e+00],\n",
              "        [ 1.75611997e+00,  5.38708830e+00,  4.08050156e+00,\n",
              "         -2.97440457e+00,  1.43987012e+00,  2.18808556e+00,\n",
              "          3.67694926e+00,  3.85878229e+00,  2.88194656e+00,\n",
              "          4.32042170e+00],\n",
              "        [ 5.11589003e+00, -5.14912000e+08, -3.35569856e+08,\n",
              "          2.98506308e+00,  7.64575899e-01,  4.45629740e+00,\n",
              "         -3.80560032e+08, -3.32112224e+08,  1.48031878e+00,\n",
              "         -5.38321280e+08],\n",
              "        [-4.72720576e+08,  4.10605049e+00, -6.20053888e+08,\n",
              "          4.95479774e+00, -6.64797952e+08,  5.05011654e+00,\n",
              "          6.52405262e+00,  6.05142117e+00, -6.28236224e+08,\n",
              "          5.59075165e+00],\n",
              "        [ 5.52482176e+00,  3.28552198e+00,  2.35300779e+00,\n",
              "          4.15981722e+00,  4.23439026e+00,  3.32185268e+00,\n",
              "          4.39957619e-01,  5.49295902e+00,  3.90085697e+00,\n",
              "          5.95547867e+00],\n",
              "        [ 3.95657539e+00,  3.99479508e+00,  2.57311702e+00,\n",
              "          4.48332262e+00,  2.74648499e+00,  4.18199158e+00,\n",
              "          2.17032194e+00,  3.71695662e+00,  2.92766309e+00,\n",
              "          3.11300254e+00],\n",
              "        [ 3.64924622e+00,  1.23680615e+00,  1.32970190e+00,\n",
              "          3.75652170e+00,  4.12502861e+00, -1.62650256e+08,\n",
              "          3.24119186e+00,  3.09541035e+00, -4.19782496e+08,\n",
              "          2.44029999e+00],\n",
              "        [ 2.87406635e+00, -3.64619456e+08, -5.34007392e+08,\n",
              "          8.66138816e-01,  5.57623148e+00,  3.32594705e+00,\n",
              "          4.88302135e+00,  7.58027411e+00,  3.99786496e+00,\n",
              "          4.90665293e+00],\n",
              "        [ 5.70878029e+00,  2.11582565e+00,  1.71378160e+00,\n",
              "          6.03720570e+00,  2.65540290e+00,  2.70646882e+00,\n",
              "          1.92848241e+00,  3.06973267e+00,  2.48910666e+00,\n",
              "          1.35986161e+00],\n",
              "        [ 3.28682756e+00, -5.36571552e+08,  2.70996165e+00,\n",
              "          1.23197484e+00,  3.06279182e+00,  3.31037927e+00,\n",
              "          5.57293510e+00,  4.44957924e+00,  4.22967052e+00,\n",
              "          5.62896395e+00],\n",
              "        [ 6.60665512e+00,  2.13087177e+00,  1.43697214e+00,\n",
              "          8.46429443e+00,  4.01268625e+00,  3.94733644e+00,\n",
              "          1.94271994e+00,  3.80583239e+00,  2.38215327e+00,\n",
              "          3.39299870e+00],\n",
              "        [ 3.75748825e+00,  1.74119949e+00,  1.43551695e+00,\n",
              "          2.15927553e+00,  3.14995241e+00,  3.20617437e+00,\n",
              "          1.71524927e-01,  4.21368170e+00,  2.10527062e+00,\n",
              "          4.57741499e+00],\n",
              "        [-4.58932640e+08,  6.25002337e+00,  5.15901041e+00,\n",
              "          3.76351857e+00,  7.93031168e+00,  6.81236362e+00,\n",
              "          7.49145031e+00,  6.78934669e+00,  6.69688654e+00,\n",
              "          6.10515070e+00],\n",
              "        [ 6.23172951e+00,  5.35171556e+00,  7.05636024e+00,\n",
              "          5.60555029e+00,  6.50122213e+00,  5.45789003e+00,\n",
              "          5.93153763e+00,  7.80377197e+00,  7.37947416e+00,\n",
              "          5.85887194e+00],\n",
              "        [ 8.14235032e-01, -4.61791400e+07,  3.71717095e-01,\n",
              "         -2.33804297e+00,  1.10606837e+00,  5.95543623e-01,\n",
              "          1.09815991e+00, -1.30678824e+08, -1.82162128e+08,\n",
              "         -1.70436928e+08],\n",
              "        [ 3.77632761e+00,  1.61237574e+00,  2.33274055e+00,\n",
              "          3.58615017e+00,  5.89077044e+00,  3.20115352e+00,\n",
              "          1.93143582e+00,  7.32361174e+00,  5.41854382e+00,\n",
              "          5.55560207e+00],\n",
              "        [ 4.00387573e+00, -6.59056896e+08,  4.08010244e+00,\n",
              "          5.44331968e-02,  1.60810542e+00,  7.11473322e+00,\n",
              "          6.05962610e+00,  3.40115547e+00,  2.73815513e+00,\n",
              "         -4.40338944e+08],\n",
              "        [-7.63807360e+08,  1.02963018e+00,  2.73184443e+00,\n",
              "          5.37849903e+00,  8.65811729e+00,  6.28444958e+00,\n",
              "          2.74312901e+00,  7.29510784e+00,  7.01483250e+00,\n",
              "          8.25329876e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pymQT7pgZZWb",
        "colab_type": "text"
      },
      "source": [
        "# backup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGM-8RKeNZD",
        "colab_type": "code",
        "outputId": "ca4a63fa-d510-4c8c-8ee4-3d7cbbb6979f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# num_users = 25\n",
        "num_items = 10\n",
        "# final_dcg = calcualte_final_dcg(decoder_output_arr2)\n",
        "topkItens = np.argsort(decoder_output_arr2)[:,-num_items:]\n",
        "predsn = []\n",
        "for user in range(topkItens.shape[0]):\n",
        "\n",
        "   predsn.append(decoder_output_arr2[user,sorted(topkItens[user,:])])\n",
        "predsn = np.array(predsn)\n",
        "#print(predsn)\n",
        "\n",
        "dcg_gt = dcg_k_users(predsn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-97f4b46ff0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# final_dcg = calcualte_final_dcg(decoder_output_arr2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtopkItens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_arr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopkItens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'decoder_output_arr2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F3LzJWgiP1v",
        "colab_type": "code",
        "outputId": "65979be2-6e7f-4618-eecc-a3345eb32936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "print (dcg_gt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e82ab825e312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdcg_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dcg_gt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWtO-9oyA-rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for s_noise in range(0, 5):\n",
        "\n",
        "#   if s_noise == 0:\n",
        "#     print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#     plot_comparison([ufairs],[1-ndcgs],['original'],'dataset','test_file')\n",
        "    \n",
        "#   if s_noise == 1:\n",
        "#     print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#     plot_comparison([ufairs],[1-ndcgs],['N(std=0.5)'],'dataset','test_file')\n",
        "\n",
        "#   if s_noise == 2:\n",
        "#     print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#     plot_comparison([ufairs],[1-ndcgs],['N(std=1)'],'dataset','test_file')\n",
        "\n",
        "#   if s_noise == 3:\n",
        "#     print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#     plot_comparison([ufairs],[1-ndcgs],['N(std=2)'],'dataset','test_file')\n",
        "\n",
        "#   if s_noise == 4:\n",
        "#     print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "#     plot_comparison([ufairs],[1-ndcgs],['uniform'],'dataset','test_file')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4nWQ10eeRBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print((decoder_output_arr[0].data).cpu().numpy().shape)\n",
        "# print((decoder_output_arr[1].data).cpu().numpy().shape)\n",
        "# print((decoder_output_arr[2].data).cpu().numpy().shape)\n",
        "# print((decoder_output_arr[0].data).cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# decoder_output_arr\n",
        "# print(decoder_output_arr[0])\n",
        "# print(decoder_output_arr[1])\n",
        "# print(decoder_output_arr[2])\n",
        "# print(dcg_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_eNklLUHBhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGo6YhuhHA3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dcg_k_users(scores):\n",
        "    dcg_round = []\n",
        "    for user in range(scores.shape[0]):\n",
        "        dcg_round.append(dcg_single_ranking(scores[user,:]))\n",
        "    return dcg_round \n",
        "\n",
        "def dcg_single_ranking(scores):\n",
        "    dcg = 0.0\n",
        "    for idx in range(len(scores)):\n",
        "        curr = scores[idx]/np.log2(idx + 2)   \n",
        "        dcg += curr\n",
        "    return dcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pDRCwRUw0RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_dec = []\n",
        "# for dec in decoder_output_arr:\n",
        "#   new_dec.append((dec.data).cpu().numpy()[0])\n",
        "\n",
        "# finalx = np.array(new_dec)\n",
        "\n",
        "# print(finalx.shape)\n",
        "# print(finalx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sROA1GLzSbh",
        "colab_type": "text"
      },
      "source": [
        "# UNFAIRNESS MEASURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOR_3DqMFnLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_users = 5\n",
        "# num_items = 10\n",
        "# new_dec = []\n",
        "# dcgz = []\n",
        "# for dec in decoder_output_arr:\n",
        "#   x = (dec.data[0:1, 0:num_users, 0:num_items]).cpu().numpy()[0]\n",
        "#   #y = \n",
        "#   print(x.shape)  \n",
        "#   # z = np.mean(y)\n",
        "#   # print(z)\n",
        "#   #dcgz.append(z)\n",
        "#   new_dec.append(x)\n",
        "#   # print((dec.data).cpu().numpy()[0])\n",
        "#   # new_dec.append((dec.data).cpu().numpy()[0])\n",
        "\n",
        "# finalx = np.array(new_dec)\n",
        "\n",
        "# # print(dcgz)\n",
        "# print(finalx.shape)\n",
        "# # print(finalx)\n",
        "# z = dcg_k_users(x)\n",
        "# # dcgz.append(z)\n",
        "# print(z)\n",
        "# # print(dcgz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wut6P2KdYkYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def calcualte_final_dcg1(decoder_output_arr):\n",
        "#   #num_users = 6\n",
        "#   final_dcg = []\n",
        "#   for dec in decoder_output_arr:\n",
        "#      x = (dec.data[0:1, 0:num_users, 0:num_items]).cpu().numpy()[0]\n",
        "#      z = dcg_k_users(x)\n",
        "#      final_dcg.append(z)\n",
        "#   return final_dcg   \n",
        "\n",
        "\n",
        "  # batch = decoder_output_arr[batch_to_pick]\n",
        "  # round_batch = batch.data[0:1, 0:num_users, 0:num_items].cpu().numpy()[0]\n",
        "  # print(\"---------------- final_dcg -----------------\")\n",
        "  # print(round_batch)\n",
        "  # print(\"----------------------------------------------\")\n",
        "  # final_dcg = dcg_k_users(round_batch)\n",
        "  # return final_dcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb3xwD8J2ICu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0HPrT0jFn1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Batch_selection_fairness(decoder_output_arr):\n",
        "#   final_pred = [] \n",
        "\n",
        "#   batch = decoder_output_arr[batch_to_pick]\n",
        "#   # print(\"------------------------\")\n",
        "#   # for i in range(0,len(decoder_output_arr)):\n",
        "#   #   print(decoder_output_arr[i].shape)\n",
        "#   # print(\"============================\")\n",
        "#   # print(batch.shape)\n",
        "#   # print(batch)\n",
        "#   # print(\"------------------------\")\n",
        "#   for n_round in range(0,1):\n",
        "#     round_batch = batch.data[0:1, 0:num_rounds, 0:num_items].cpu().numpy()[0]\n",
        "#     final_pred.append(round_batch)\n",
        "\n",
        "#   final_pred = np.array(final_pred)\n",
        "#   return final_pred\n",
        "\n",
        "\n",
        "\n",
        "# def Batch_selection_fairness(decoder_output_arr):\n",
        "#   final_pred = [] \n",
        "\n",
        "#   for n_round in range(0,len(decoder_output_arr)):\n",
        "#     batch = decoder_output_arr[n_round]\n",
        "#     round_batch = batch.data[0:1, 0:num_users, 0:num_items].cpu().numpy()[0]\n",
        "#     final_pred.append(round_batch)\n",
        "\n",
        "#   final_pred = np.array(final_pred)\n",
        "#   return final_pred\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txFTL6Wi2Axv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcualte_final_dcg(decoder_output_arr22):\n",
        "  batch = decoder_output_arr2\n",
        "  round_batch = batch.data[:,0:num_items].cpu().numpy()[0]\n",
        "  print(\"---------------- final_dcg -----------------\")\n",
        "  print(round_batch.size)\n",
        "  print(\"----------------------------------------------\")\n",
        "  final_dcg = dcg_k_users(round_batch)\n",
        "  return final_dcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXxlxqpfzJ2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Fairness_at_k_rounds(X_pred, dcg_gt):\n",
        "    debug = False\n",
        "    print(\"----------------------- Fairness_at_k_rounds  ->   X_pred -------------------------\")\n",
        "    print(X_pred)\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "    ufair_all = []\n",
        "    ndcg_all = []\n",
        "    for user in range(X_pred.shape[1]):\n",
        "        ufair, ndcg = 0.0, 0.0\n",
        "        for item in range(X_pred.shape[2]):\n",
        "            sum_a, sum_r = 0,0\n",
        "            item_ufair, item_ndcg = [], []\n",
        "            for iround in range(X_pred.shape[0]):\n",
        "                att, rel = 0,0\n",
        "                if X_pred[iround,user,item] != -np.inf:\n",
        "                    if debug: print(user,item,iround)\n",
        "                    # NORMALIZE SCORES BETWEEN THE MINIMUN AND MAXIMUN VALUES\n",
        "                    #print(min(X_pred[iround,user,:]),max(X_pred[iround,user,:]))\n",
        "                    norm_scores = ((X_pred[iround,user,:] - min(X_pred[iround,user,:]))/(max(X_pred[iround,user,:])- min(X_pred[iround,user,:])))\n",
        "                    #norm_scores = (X_pred[iround,user,:]/max(X_pred[iround,user,:]))\n",
        "                    if debug: print(norm_scores)\n",
        "                    # INDEX OF ITEMS SORTED IN DESCENDING ORDER\n",
        "                    if debug: print(np.argsort(norm_scores)[::-1]) \n",
        "                    # POSITION OF THE CURRENT ITEM\n",
        "                    if debug: print(max(np.argsort(norm_scores)) - np.where(np.argsort(norm_scores) == item)[0][0]) \n",
        "                    att = np.where(np.argsort(norm_scores) == item)[0][0]/max(np.argsort(norm_scores))\n",
        "                    if debug: print('Attention: '+ str(att)) \n",
        "                    sum_a = sum_a + att\n",
        "                    rel = norm_scores[item]\n",
        "                    if debug: print('Relevance: '+str(rel))\n",
        "                    sum_r = sum_r + rel\n",
        "                    if debug: print('Unfairness: '+str(abs(att - rel)))\n",
        "                    if debug: print('DCG: '+str(dcg_single_ranking(X_pred[iround,user,:])))\n",
        "                    if debug: print('NDCG: '+str(dcg_single_ranking(X_pred[iround,user,:])/dcg_gt[user]))\n",
        "                    if debug: input()\n",
        "                    item_ufair.append(abs(att - rel)) \n",
        "                    item_ndcg.append(dcg_single_ranking(X_pred[iround,user,:])/dcg_gt[user])\n",
        "                else: \n",
        "                    print(\"ALERT\")    \n",
        "                    print(user,item,iround) \n",
        "            #plot_curve(item_ufair,item_ndcg)\n",
        "            # SUMS THE UNFAIRNESS OF CURRENT ITEM\n",
        "            ufair = ufair + (abs(sum_a - sum_r)/X_pred.shape[0])\n",
        "            ndcg = ndcg + (np.sum(item_ndcg)/X_pred.shape[0])\n",
        "            if debug: print('Unfairness of Item: '+str((abs(sum_a - sum_r)/X_pred.shape[0])))\n",
        "            if debug: print('Total Current Unfairness: '+str(ufair/(item+1)))\n",
        "            if debug: print('-----------------------------------')\n",
        "        if debug: print('Normalized Total Unfairness: '+str(ufair/X_pred.shape[2]))\n",
        "        if debug: print('Normalized Total NDCG: '+str(ndcg/X_pred.shape[2]))\n",
        "        # normalize by the number of items\n",
        "        ufair_all.append(ufair/X_pred.shape[2])\n",
        "        ndcg_all.append(ndcg/X_pred.shape[2])\n",
        "    return np.array(ufair_all), np.array(ndcg_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13AQBOD-Qu-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_box_color(bp, color):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.setp(bp['boxes'], color=color)\n",
        "    plt.setp(bp['whiskers'], color=color)\n",
        "    plt.setp(bp['caps'], color=color)\n",
        "    plt.setp(bp['medians'], color=color)\n",
        "\n",
        "def plot_comparison(data_a, data_b, ticks, dataset, test_file):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    bpl = plt.boxplot(data_a, positions=np.array(range(len(data_a)))*2.0-0.4, sym='', widths=0.6)\n",
        "    bpr = plt.boxplot(data_b, positions=np.array(range(len(data_b)))*2.0+0.4, sym='', widths=0.6)\n",
        "    #bpr = plt.boxplot(data_c, positions=np.array(range(len(data_b)))*2.0+0.4, sym='', widths=0.6)\n",
        "    set_box_color(bpl, '#D7191C') # colors are from http://colorbrewer2.org/\n",
        "    set_box_color(bpr, '#2C7BB6')\n",
        "    #set_box_color(bpr, '#2C7BB6')\n",
        "    \n",
        "    # draw temporary red and blue lines and use them to create a legend\n",
        "    plt.plot([], c='#D7191C', label='Unfairness@100')\n",
        "    plt.plot([], c='#2C7BB6', label='1 - NDCG@100')\n",
        "    #plt.plot([], c='#2C7BB6', label='CNN + STFT')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
        "    plt.xlim(-2, len(ticks)*2)\n",
        "    plt.ylim(-0.2,1.00)\n",
        "    #plt.ylim(np.min(np.concatenate((data_a,data_b),axis=1)), np.max(np.concatenate((data_a,data_b),axis=1)))\n",
        "    plt.tight_layout()\n",
        "    from google.colab import files\n",
        "    plt.savefig(\"result.pdf\")\n",
        "    files.download(\"result.pdf\") \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8sGP0Z1QDsP",
        "colab_type": "code",
        "outputId": "9ad08be7-ce15-4486-8ebf-eba9052383bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# print(\"NO NOISE\")\n",
        "# ufairs, ndcgs = test_model_k_rounds(p_dims, 0, test_data, num_rounds, num_users, num_items, topkItens, dcg_gt, dataset)\n",
        "# ufairs, ndcgs = Fairness_at_k_rounds(final_pred, final_dcg)\n",
        "# print(ufairs)\n",
        "# print(ndcgs)\n",
        "# print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs)) \n",
        "#print(\"NORMAL NOISE STD 0.5\")\n",
        "# ufairs_n05, ndcgs_n05 = test_model_k_rounds(p_dims, 1, test_data, num_rounds, num_users, num_items, topkItens, dcg_gt, dataset)\n",
        "#print(np.mean(ufairs_n05),np.std(ufairs_n05),np.mean(ndcgs_n05),np.std(ndcgs_n05))\n",
        "#print(\"NORMAL NOISE STD 1.0\")\n",
        "#ufairs_n10, ndcgs_n10 = test_model_k_rounds(p_dims, 2, test_data, num_rounds, num_users, num_items, topkItens, dcg_gt, dataset)\n",
        "#print(np.mean(ufairs_n10),np.std(ufairs_n10),np.mean(ndcgs_n10),np.std(ndcgs_n10))\n",
        "#print(\"NORMAL NOISE STD 2.0\")\n",
        "#ufairs_n20, ndcgs_n20 = test_model_k_rounds(p_dims, 3, test_data, num_rounds, num_users, num_items, topkItens, dcg_gt, dataset)\n",
        "#print(np.mean(ufairs_n20),np.std(ufairs_n20),np.mean(ndcgs_n20),np.std(ndcgs_n20))\n",
        "#print(\"UNIFORM NOISE\") \n",
        "#ufairs_unif, ndcgs_unif = test_model_k_rounds(p_dims, 4, test_data, num_rounds, num_users, num_items, topkItens, dcg_gt, dataset)\n",
        "#print(np.mean(ufairs_unif),np.std(ufairs_unif),np.mean(ndcgs_unif),np.std(ndcgs_unif))\n",
        "\n",
        "# plot_comparison([ufairs,ufairs_n05, ufairs_n10,ufairs_n20, ufairs_unif],[1-ndcgs,1-ndcgs_n05, 1-ndcgs_n10,1-ndcgs_n20,1-ndcgs_unif],['original','N(std=0.5)','N(std=1.0)','N(std=2.0)','uniform'], dataset, test_file)\n",
        "\n",
        "\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "test_reader, total_items = load_data2(hyper_params)\n",
        "\n",
        "# hyper_params['noise'] = 0\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "  \n",
        "criterion = VAELoss(hyper_params)\n",
        "s_noise = 1\n",
        "metrics, len_to_ndcg_at_100_map, decoder_output_arr, dcg_arr = fairness_evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "final_pred = Batch_selection_fairness(decoder_output_arr)\n",
        "final_dcg = calcualte_final_dcg(decoder_output_arr)\n",
        "ufairs, ndcgs = Fairness_at_k_rounds(final_pred, final_dcg)\n",
        "print(\"original: \",np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "\n",
        "print(\"\\n\\n ***************************** \\n\\n\")\n",
        "\n",
        "hyper_params['noise'] = 1\n",
        "criterion = VAELoss(hyper_params)\n",
        "s_noise = 2\n",
        "metrics, len_to_ndcg_at_100_map, decoder_output_arr, dcg_arr = fairness_evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "final_pred =  Batch_selection_fairness(decoder_output_arr)\n",
        "ufairs_n05, ndcgs_n05 = Fairness_at_k_rounds(final_pred, final_dcg)\n",
        "print(\"N(std=0.5): \",np.mean(ufairs_n05),np.std(ufairs_n05),np.mean(ndcgs_n05),np.std(ndcgs_n05))\n",
        "\n",
        "#plot_comparison([ufairs,ufairs_n05],[1-ndcgs,1-ndcgs_n05],['original', 'N(std=0.5)'],'dataset','test_file')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-dd438009f9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS-5a27KzszU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"NO NOISE\")\n",
        "# ufairs, ndcgs = Fairness_at_k_rounds(final_pred, final_dcg)\n",
        "# print(np.mean(ufairs),np.std(ufairs),np.mean(ndcgs),np.std(ndcgs))\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMbltWqv7hAY",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ijFh3x6y6Ej_",
        "colab_type": "code",
        "outputId": "df70e2d8-6a92-4030-8211-3d106f65f7b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "def train(reader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    batch = 0\n",
        "    batch_limit = int(train_reader.num_b)\n",
        "    total_anneal_steps = 200000\n",
        "    anneal = 0.0\n",
        "    update_count = 0.0\n",
        "    anneal_cap = 0.2\n",
        "\n",
        "    for x, y_s in reader.iter():\n",
        "        batch += 1\n",
        "        \n",
        "        # Empty the gradients\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        # Forward pass\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "        \n",
        "        # Anneal logic\n",
        "        if total_anneal_steps > 0:\n",
        "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "        else:\n",
        "            anneal = anneal_cap\n",
        "        update_count += 1.0\n",
        "        \n",
        "        # Logging mechanism\n",
        "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
        "            div = hyper_params['batch_log_interval']\n",
        "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
        "            if div <= 0: div = 1\n",
        "\n",
        "            cur_loss = (total_loss / div)\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
        "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
        "            )\n",
        "            \n",
        "            file_write(hyper_params['log_file'], ss)\n",
        "\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Train It..\n",
        "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "\n",
        "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
        "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
        "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of validation batches: {:4d}\".format(val_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
        "\n",
        "model = Model(hyper_params)\n",
        "if is_cuda_available: model.cuda()\n",
        "\n",
        "criterion = VAELoss(hyper_params)\n",
        "\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    optimizer = torch.optim.Adagrad(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr = hyper_params['learning_rate']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adadelta':\n",
        "    optimizer = torch.optim.Adadelta(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "\n",
        "file_write(hyper_params['log_file'], str(model))\n",
        "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
        "\n",
        "best_val_ndcg = None\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        train(train_reader)\n",
        "        \n",
        "        # Calulating the metrics on the train set\n",
        "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
        "        string = \"\"\n",
        "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string += ' (TRAIN)'\n",
        "    \n",
        "        # Calulating the metrics on the validation set\n",
        "        metrics, _ = evaluate(model, criterion, val_reader, hyper_params, False)\n",
        "        string2 = \"\"\n",
        "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string2 += ' (VAL)'\n",
        "\n",
        "        ss  = '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string2\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        file_write(hyper_params['log_file'], ss)\n",
        "        \n",
        "        if not best_val_ndcg or metrics['NDCG@100'] >= best_val_ndcg:\n",
        "            with open(hyper_params['model_file_name'], 'wb') as f: torch.save(model, f)\n",
        "            best_val_ndcg = metrics['NDCG@100']\n",
        "\n",
        "except KeyboardInterrupt: print('Exiting from training early')\n",
        "\n",
        "# Plot Traning graph\n",
        "f = open(model.hyper_params['log_file'])\n",
        "lines = f.readlines()\n",
        "lines.reverse()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for line in lines:\n",
        "    if line[:10] == 'Simulation' and len(train) > 1: break\n",
        "    elif line[:10] == 'Simulation' and len(train) <= 1: train, test = [], []\n",
        "        \n",
        "    if line[2:5] == 'end' and line[-5:-2] == 'VAL': test.append(line.strip().split(\"|\"))\n",
        "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN': train.append(line.strip().split(\"|\"))\n",
        "\n",
        "train.reverse()\n",
        "test.reverse()\n",
        "\n",
        "train_ndcg = []\n",
        "test_ndcg = []\n",
        "test_loss, train_loss = [], []\n",
        "\n",
        "for i in train:\n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            train_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            train_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "total, avg_runtime = 0.0, 0.0\n",
        "for i in test:\n",
        "    avg_runtime += float(i[2].split(\" \")[2][:-1])\n",
        "    total += 1.0\n",
        "    \n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            test_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            test_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
        "ax1.set_title(hyper_params[\"project_name\"],fontweight=\"bold\", size=20)\n",
        "ax1.plot(test_ndcg, 'b-')\n",
        "ax1.set_xlabel('Epochs', fontsize = 20.0)\n",
        "ax1.set_ylabel('NDCG@100', color='b', fontsize = 20.0)\n",
        "ax1.tick_params('y', colors='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(test_loss, 'r--')\n",
        "ax2.set_ylabel('Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "fig.tight_layout()\n",
        "if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "fig.savefig(\"saved_plots/learning_curve_\" + hyper_params[\"project_name\"] + \".pdf\")\n",
        "plt.show()\n",
        "\n",
        "# Checking metrics for the test set on best saved model\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "string = \"\"\n",
        "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "ss  = '=' * 89\n",
        "ss += '\\n| End of training'\n",
        "ss += string + \" (TEST)\"\n",
        "ss += '\\n'\n",
        "ss += '=' * 89\n",
        "file_write(hyper_params['log_file'], ss)\n",
        "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8538846/8538846 [00:17<00:00, 478653.46it/s]\n",
            "100%|██████████| 581927/581927 [00:00<00:00, 696074.04it/s]\n",
            "100%|██████████| 150474/150474 [00:00<00:00, 705372.77it/s]\n",
            "100%|██████████| 571057/571057 [00:01<00:00, 309895.22it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 667323.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Simulation run on: 2020-04-03 00:26:58.259192\n",
            "\n",
            "\n",
            "Data reading complete!\n",
            "Number of train batches: 116677\n",
            "Number of validation batches: 10000\n",
            "Number of test batches: 10000\n",
            "Total Items: 20108\n",
            "\n",
            "Model(\n",
            "  (encoder): Encoder(\n",
            "    (linear1): Linear(in_features=200, out_features=150, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (linear1): Linear(in_features=64, out_features=150, bias=True)\n",
            "    (linear2): Linear(in_features=150, out_features=20108, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (item_embed): Embedding(20108, 256)\n",
            "  (gru): GRU(256, 200, batch_first=True)\n",
            "  (linear1): Linear(in_features=150, out_features=128, bias=True)\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "\n",
            "Model Built!\n",
            "Starting Training...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVN5tMUHSyoR",
        "colab_type": "code",
        "outputId": "600b70b2-cb63-4115-cfb0-28048d6094c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(reader):\n",
        "    model.train()\n",
        "    \n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    batch = 0\n",
        "    batch_limit = int(train_reader.num_b)\n",
        "    total_anneal_steps = 200000\n",
        "    anneal = 0.0\n",
        "    update_count = 0.0\n",
        "    anneal_cap = 0.2\n",
        "    \n",
        "    for x, y_s in reader.iter():\n",
        "        \n",
        "        batch += 1\n",
        "        \n",
        "        # Empty the gradients\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        # Forward pass\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.data\n",
        "        \n",
        "        # Anneal logic\n",
        "        if total_anneal_steps > 0:\n",
        "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
        "        else:\n",
        "            anneal = anneal_cap\n",
        "        update_count += 1.0\n",
        "        \n",
        "        # Logging mechanism\n",
        "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
        "            div = hyper_params['batch_log_interval']\n",
        "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
        "            if div <= 0: div = 1\n",
        "\n",
        "            cur_loss = (total_loss / div)\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
        "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
        "            )\n",
        "            \n",
        "            file_write(hyper_params['log_file'], ss)\n",
        "\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Train It..\n",
        "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "\n",
        "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
        "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
        "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of validation batches: {:4d}\".format(val_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
        "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
        "\n",
        "model = Model(hyper_params)\n",
        "if is_cuda_available: model.cuda()\n",
        "\n",
        "criterion = VAELoss(hyper_params)\n",
        "\n",
        "if hyper_params['optimizer'] == 'adagrad':\n",
        "    optimizer = torch.optim.Adagrad(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr = hyper_params['learning_rate']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adadelta':\n",
        "    optimizer = torch.optim.Adadelta(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "elif hyper_params['optimizer'] == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(\n",
        "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
        "    )\n",
        "\n",
        "file_write(hyper_params['log_file'], str(model))\n",
        "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
        "\n",
        "best_val_ndcg = None\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        \n",
        "        train(train_reader)\n",
        "        \n",
        "        # Calulating the metrics on the train set\n",
        "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
        "        string = \"\"\n",
        "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string += ' (TRAIN)'\n",
        "    \n",
        "        # Calulating the metrics on the validation set\n",
        "        metrics, _ = evaluate(model, criterion, val_reader, hyper_params, False)\n",
        "        string2 = \"\"\n",
        "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
        "        string2 += ' (VAL)'\n",
        "\n",
        "        ss  = '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
        "        ss += string2\n",
        "        ss += '\\n'\n",
        "        ss += '-' * 89\n",
        "        file_write(hyper_params['log_file'], ss)\n",
        "        \n",
        "        if not best_val_ndcg or metrics['NDCG@100'] >= best_val_ndcg:\n",
        "            with open(hyper_params['model_file_name'], 'wb') as f: torch.save(model, f)\n",
        "            best_val_ndcg = metrics['NDCG@100']\n",
        "\n",
        "except KeyboardInterrupt: print('Exiting from training early')\n",
        "\n",
        "# Plot Traning graph\n",
        "f = open(model.hyper_params['log_file'])\n",
        "lines = f.readlines()\n",
        "lines.reverse()\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "\n",
        "for line in lines:\n",
        "    if line[:10] == 'Simulation' and len(train) > 1: break\n",
        "    elif line[:10] == 'Simulation' and len(train) <= 1: train, test = [], []\n",
        "        \n",
        "    if line[2:5] == 'end' and line[-5:-2] == 'VAL': test.append(line.strip().split(\"|\"))\n",
        "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN': train.append(line.strip().split(\"|\"))\n",
        "\n",
        "train.reverse()\n",
        "test.reverse()\n",
        "\n",
        "train_ndcg = []\n",
        "test_ndcg = []\n",
        "test_loss, train_loss = [], []\n",
        "\n",
        "for i in train:\n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            train_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            train_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "total, avg_runtime = 0.0, 0.0\n",
        "for i in test:\n",
        "    avg_runtime += float(i[2].split(\" \")[2][:-1])\n",
        "    total += 1.0\n",
        "    \n",
        "    for metric in i:\n",
        "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
        "            test_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
        "        if metric.split(\"=\")[0] == \" loss \":\n",
        "            test_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
        "ax1.set_title(hyper_params[\"project_name\"],fontweight=\"bold\", size=20)\n",
        "ax1.plot(test_ndcg, 'b-')\n",
        "ax1.set_xlabel('Epochs', fontsize = 20.0)\n",
        "ax1.set_ylabel('NDCG@100', color='b', fontsize = 20.0)\n",
        "ax1.tick_params('y', colors='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(test_loss, 'r--')\n",
        "ax2.set_ylabel('Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "fig.tight_layout()\n",
        "if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
        "fig.savefig(\"saved_plots/learning_curve_\" + hyper_params[\"project_name\"] + \".pdf\")\n",
        "plt.show()\n",
        "\n",
        "# Checking metrics for the test set on best saved model\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "string = \"\"\n",
        "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "ss  = '=' * 89\n",
        "ss += '\\n| End of training'\n",
        "ss += string + \" (TEST)\"\n",
        "ss += '\\n'\n",
        "ss += '=' * 89\n",
        "file_write(hyper_params['log_file'], ss)\n",
        "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8538846/8538846 [00:14<00:00, 580437.06it/s]\n",
            "100%|██████████| 581927/581927 [00:00<00:00, 783423.54it/s]\n",
            "100%|██████████| 150474/150474 [00:00<00:00, 762838.54it/s]\n",
            "100%|██████████| 571057/571057 [00:00<00:00, 791172.15it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 738129.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Simulation run on: 2020-04-10 18:15:26.267715\n",
            "\n",
            "\n",
            "Data reading complete!\n",
            "Number of train batches: 116677\n",
            "Number of validation batches: 10000\n",
            "Number of test batches: 10000\n",
            "Total Items: 20108\n",
            "\n",
            "Model(\n",
            "  (encoder): Encoder(\n",
            "    (linear1): Linear(in_features=200, out_features=150, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (linear1): Linear(in_features=64, out_features=150, bias=True)\n",
            "    (linear2): Linear(in_features=150, out_features=20108, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (item_embed): Embedding(20108, 256)\n",
            "  (gru): GRU(256, 200, batch_first=True)\n",
            "  (linear1): Linear(in_features=150, out_features=128, bias=True)\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "\n",
            "Model Built!\n",
            "Starting Training...\n",
            "\n",
            "| epoch   1 | 10000/116677 batches | ms/batch 13.82 | loss 515.7082\n",
            "| epoch   1 | 20000/116677 batches | ms/batch 13.92 | loss 488.9114\n",
            "| epoch   1 | 30000/116677 batches | ms/batch 14.33 | loss 496.9965\n",
            "| epoch   1 | 40000/116677 batches | ms/batch 14.09 | loss 472.9463\n",
            "| epoch   1 | 50000/116677 batches | ms/batch 13.95 | loss 471.5087\n",
            "| epoch   1 | 60000/116677 batches | ms/batch 13.86 | loss 471.1125\n",
            "| epoch   1 | 70000/116677 batches | ms/batch 14.08 | loss 488.4983\n",
            "| epoch   1 | 80000/116677 batches | ms/batch 13.73 | loss 467.1022\n",
            "| epoch   1 | 90000/116677 batches | ms/batch 13.65 | loss 461.7840\n",
            "| epoch   1 | 100000/116677 batches | ms/batch 13.79 | loss 472.3294\n",
            "| epoch   1 | 110000/116677 batches | ms/batch 13.68 | loss 464.1661\n",
            "| epoch   1 | 116677/116677 batches | ms/batch 13.83 | loss 473.6656\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1702.56s | loss = 389.1412 | NDCG@10 = 15.0489 | Rec@10 = 12.6099 | Prec@10 = 10.6 | NDCG@100 = 26.7431 | Rec@100 = 49.5602 | Prec@100 = 5.33 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1702.56s | loss = 361.3858 | NDCG@10 = 15.0342 | Rec@10 = 13.4204 | Prec@10 = 11.034 | NDCG@100 = 26.8929 | Rec@100 = 48.8788 | Prec@100 = 5.134 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 | 10000/116677 batches | ms/batch 13.77 | loss 467.8755\n",
            "| epoch   2 | 20000/116677 batches | ms/batch 13.49 | loss 449.6585\n",
            "| epoch   2 | 30000/116677 batches | ms/batch 13.70 | loss 463.3777\n",
            "| epoch   2 | 40000/116677 batches | ms/batch 13.85 | loss 475.2207\n",
            "| epoch   2 | 50000/116677 batches | ms/batch 13.63 | loss 460.2466\n",
            "| epoch   2 | 60000/116677 batches | ms/batch 13.72 | loss 467.3964\n",
            "| epoch   2 | 70000/116677 batches | ms/batch 13.96 | loss 486.4018\n",
            "| epoch   2 | 80000/116677 batches | ms/batch 13.66 | loss 466.5799\n",
            "| epoch   2 | 90000/116677 batches | ms/batch 13.59 | loss 463.2552\n",
            "| epoch   2 | 100000/116677 batches | ms/batch 13.78 | loss 472.6610\n",
            "| epoch   2 | 110000/116677 batches | ms/batch 13.64 | loss 464.8685\n",
            "| epoch   2 | 116677/116677 batches | ms/batch 13.75 | loss 468.5961\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1680.39s | loss = 387.2487 | NDCG@10 = 16.4495 | Rec@10 = 14.4873 | Prec@10 = 12.25 | NDCG@100 = 27.4221 | Rec@100 = 50.2296 | Prec@100 = 5.43 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1680.39s | loss = 359.1912 | NDCG@10 = 15.0346 | Rec@10 = 13.4065 | Prec@10 = 11.067 | NDCG@100 = 26.9635 | Rec@100 = 49.1787 | Prec@100 = 5.1438 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 | 10000/116677 batches | ms/batch 13.57 | loss 458.9092\n",
            "| epoch   3 | 20000/116677 batches | ms/batch 13.78 | loss 471.8476\n",
            "| epoch   3 | 30000/116677 batches | ms/batch 13.63 | loss 464.4502\n",
            "| epoch   3 | 40000/116677 batches | ms/batch 13.72 | loss 469.6451\n",
            "| epoch   3 | 50000/116677 batches | ms/batch 13.67 | loss 468.3356\n",
            "| epoch   3 | 60000/116677 batches | ms/batch 13.73 | loss 468.1150\n",
            "| epoch   3 | 70000/116677 batches | ms/batch 13.50 | loss 457.1969\n",
            "| epoch   3 | 80000/116677 batches | ms/batch 13.68 | loss 467.5574\n",
            "| epoch   3 | 90000/116677 batches | ms/batch 13.53 | loss 456.0714\n",
            "| epoch   3 | 100000/116677 batches | ms/batch 13.63 | loss 465.5720\n",
            "| epoch   3 | 110000/116677 batches | ms/batch 13.72 | loss 469.5946\n",
            "| epoch   3 | 116677/116677 batches | ms/batch 13.63 | loss 466.7583\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1672.84s | loss = 383.9633 | NDCG@10 = 16.941 | Rec@10 = 14.9694 | Prec@10 = 12.15 | NDCG@100 = 27.7667 | Rec@100 = 50.2806 | Prec@100 = 5.485 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1672.84s | loss = 358.1594 | NDCG@10 = 15.8313 | Rec@10 = 14.1402 | Prec@10 = 11.636 | NDCG@100 = 27.6925 | Rec@100 = 49.7613 | Prec@100 = 5.2618 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 | 10000/116677 batches | ms/batch 13.73 | loss 470.8002\n",
            "| epoch   4 | 20000/116677 batches | ms/batch 13.42 | loss 452.7590\n",
            "| epoch   4 | 30000/116677 batches | ms/batch 13.43 | loss 464.2484\n",
            "| epoch   4 | 40000/116677 batches | ms/batch 13.32 | loss 460.1124\n",
            "| epoch   4 | 50000/116677 batches | ms/batch 13.39 | loss 467.2878\n",
            "| epoch   4 | 60000/116677 batches | ms/batch 13.37 | loss 465.3800\n",
            "| epoch   4 | 70000/116677 batches | ms/batch 13.38 | loss 465.9035\n",
            "| epoch   4 | 80000/116677 batches | ms/batch 13.35 | loss 462.6730\n",
            "| epoch   4 | 90000/116677 batches | ms/batch 13.49 | loss 474.2470\n",
            "| epoch   4 | 100000/116677 batches | ms/batch 13.33 | loss 456.2493\n",
            "| epoch   4 | 110000/116677 batches | ms/batch 13.49 | loss 465.9430\n",
            "| epoch   4 | 116677/116677 batches | ms/batch 13.54 | loss 467.6759\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1646.76s | loss = 385.2149 | NDCG@10 = 15.9312 | Rec@10 = 14.1939 | Prec@10 = 12.15 | NDCG@100 = 26.6724 | Rec@100 = 49.5241 | Prec@100 = 5.53 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 1646.76s | loss = 357.6605 | NDCG@10 = 15.4669 | Rec@10 = 13.8275 | Prec@10 = 11.334 | NDCG@100 = 27.3683 | Rec@100 = 49.5189 | Prec@100 = 5.2057 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 | 10000/116677 batches | ms/batch 13.48 | loss 463.7096\n",
            "| epoch   5 | 20000/116677 batches | ms/batch 13.53 | loss 467.1612\n",
            "| epoch   5 | 30000/116677 batches | ms/batch 13.25 | loss 448.6556\n",
            "| epoch   5 | 40000/116677 batches | ms/batch 13.46 | loss 469.8743\n",
            "| epoch   5 | 50000/116677 batches | ms/batch 13.83 | loss 474.6911\n",
            "| epoch   5 | 60000/116677 batches | ms/batch 13.60 | loss 471.3985\n",
            "| epoch   5 | 70000/116677 batches | ms/batch 13.53 | loss 464.4263\n",
            "| epoch   5 | 80000/116677 batches | ms/batch 13.46 | loss 466.9898\n",
            "| epoch   5 | 90000/116677 batches | ms/batch 13.38 | loss 460.9966\n",
            "| epoch   5 | 100000/116677 batches | ms/batch 13.37 | loss 457.1481\n",
            "| epoch   5 | 110000/116677 batches | ms/batch 13.41 | loss 461.9910\n",
            "| epoch   5 | 116677/116677 batches | ms/batch 13.35 | loss 455.7207\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1650.59s | loss = 384.2856 | NDCG@10 = 18.0895 | Rec@10 = 14.7407 | Prec@10 = 12.5 | NDCG@100 = 29.1616 | Rec@100 = 51.4708 | Prec@100 = 5.595 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 1650.59s | loss = 357.4032 | NDCG@10 = 15.8726 | Rec@10 = 14.0814 | Prec@10 = 11.673 | NDCG@100 = 27.6844 | Rec@100 = 49.7592 | Prec@100 = 5.2479 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 | 10000/116677 batches | ms/batch 13.31 | loss 459.4677\n",
            "| epoch   6 | 20000/116677 batches | ms/batch 13.38 | loss 462.8027\n",
            "| epoch   6 | 30000/116677 batches | ms/batch 13.52 | loss 474.4834\n",
            "| epoch   6 | 40000/116677 batches | ms/batch 13.37 | loss 463.7755\n",
            "| epoch   6 | 50000/116677 batches | ms/batch 13.43 | loss 470.3268\n",
            "| epoch   6 | 60000/116677 batches | ms/batch 13.25 | loss 460.7422\n",
            "| epoch   6 | 70000/116677 batches | ms/batch 13.32 | loss 459.0148\n",
            "| epoch   6 | 80000/116677 batches | ms/batch 13.26 | loss 458.3864\n",
            "| epoch   6 | 90000/116677 batches | ms/batch 13.32 | loss 461.4113\n",
            "| epoch   6 | 100000/116677 batches | ms/batch 13.24 | loss 457.7347\n",
            "| epoch   6 | 110000/116677 batches | ms/batch 13.28 | loss 461.3316\n",
            "| epoch   6 | 116677/116677 batches | ms/batch 13.61 | loss 477.5353\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1635.47s | loss = 385.22 | NDCG@10 = 16.6122 | Rec@10 = 13.3565 | Prec@10 = 11.45 | NDCG@100 = 28.2895 | Rec@100 = 51.4087 | Prec@100 = 5.55 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 1635.47s | loss = 357.2853 | NDCG@10 = 15.394 | Rec@10 = 13.8253 | Prec@10 = 11.327 | NDCG@100 = 27.3123 | Rec@100 = 49.348 | Prec@100 = 5.1966 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 | 10000/116677 batches | ms/batch 13.25 | loss 457.0331\n",
            "| epoch   7 | 20000/116677 batches | ms/batch 13.18 | loss 454.0043\n",
            "| epoch   7 | 30000/116677 batches | ms/batch 13.33 | loss 463.9193\n",
            "| epoch   7 | 40000/116677 batches | ms/batch 13.49 | loss 474.6633\n",
            "| epoch   7 | 50000/116677 batches | ms/batch 13.27 | loss 464.1142\n",
            "| epoch   7 | 60000/116677 batches | ms/batch 13.15 | loss 451.7869\n",
            "| epoch   7 | 70000/116677 batches | ms/batch 13.25 | loss 463.9527\n",
            "| epoch   7 | 80000/116677 batches | ms/batch 13.40 | loss 468.2340\n",
            "| epoch   7 | 90000/116677 batches | ms/batch 13.25 | loss 460.8358\n",
            "| epoch   7 | 100000/116677 batches | ms/batch 13.43 | loss 474.7873\n",
            "| epoch   7 | 110000/116677 batches | ms/batch 13.35 | loss 465.1540\n",
            "| epoch   7 | 116677/116677 batches | ms/batch 13.23 | loss 458.8332\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1629.23s | loss = 385.3314 | NDCG@10 = 17.5956 | Rec@10 = 14.9517 | Prec@10 = 12.2 | NDCG@100 = 29.0991 | Rec@100 = 52.0587 | Prec@100 = 5.545 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 1629.23s | loss = 357.5218 | NDCG@10 = 15.4134 | Rec@10 = 13.7734 | Prec@10 = 11.448 | NDCG@100 = 27.4939 | Rec@100 = 49.9346 | Prec@100 = 5.2913 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 | 10000/116677 batches | ms/batch 13.11 | loss 445.5217\n",
            "| epoch   8 | 20000/116677 batches | ms/batch 13.32 | loss 465.1242\n",
            "| epoch   8 | 30000/116677 batches | ms/batch 13.56 | loss 477.1321\n",
            "| epoch   8 | 40000/116677 batches | ms/batch 13.15 | loss 453.4804\n",
            "| epoch   8 | 50000/116677 batches | ms/batch 13.41 | loss 470.3691\n",
            "| epoch   8 | 60000/116677 batches | ms/batch 13.35 | loss 465.4047\n",
            "| epoch   8 | 70000/116677 batches | ms/batch 13.48 | loss 472.9494\n",
            "| epoch   8 | 80000/116677 batches | ms/batch 13.12 | loss 451.0320\n",
            "| epoch   8 | 90000/116677 batches | ms/batch 13.31 | loss 464.5284\n",
            "| epoch   8 | 100000/116677 batches | ms/batch 13.27 | loss 460.8416\n",
            "| epoch   8 | 110000/116677 batches | ms/batch 13.29 | loss 464.8867\n",
            "| epoch   8 | 116677/116677 batches | ms/batch 13.29 | loss 466.3747\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1630.11s | loss = 383.8528 | NDCG@10 = 16.665 | Rec@10 = 14.5097 | Prec@10 = 11.85 | NDCG@100 = 28.0864 | Rec@100 = 51.2359 | Prec@100 = 5.58 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 1630.11s | loss = 356.8442 | NDCG@10 = 16.0068 | Rec@10 = 14.1429 | Prec@10 = 11.681 | NDCG@100 = 27.8939 | Rec@100 = 49.8978 | Prec@100 = 5.3016 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 | 10000/116677 batches | ms/batch 13.15 | loss 452.5704\n",
            "| epoch   9 | 20000/116677 batches | ms/batch 13.14 | loss 454.6752\n",
            "| epoch   9 | 30000/116677 batches | ms/batch 13.24 | loss 460.2662\n",
            "| epoch   9 | 40000/116677 batches | ms/batch 13.44 | loss 475.6803\n",
            "| epoch   9 | 50000/116677 batches | ms/batch 13.30 | loss 463.4317\n",
            "| epoch   9 | 60000/116677 batches | ms/batch 13.35 | loss 468.7396\n",
            "| epoch   9 | 70000/116677 batches | ms/batch 13.34 | loss 463.1788\n",
            "| epoch   9 | 80000/116677 batches | ms/batch 13.32 | loss 465.5398\n",
            "| epoch   9 | 90000/116677 batches | ms/batch 13.26 | loss 460.8313\n",
            "| epoch   9 | 100000/116677 batches | ms/batch 13.21 | loss 456.5254\n",
            "| epoch   9 | 110000/116677 batches | ms/batch 13.32 | loss 465.8295\n",
            "| epoch   9 | 116677/116677 batches | ms/batch 13.45 | loss 470.4854\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1628.37s | loss = 384.36 | NDCG@10 = 18.4191 | Rec@10 = 16.4051 | Prec@10 = 12.8 | NDCG@100 = 28.672 | Rec@100 = 50.8789 | Prec@100 = 5.455 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 1628.37s | loss = 356.229 | NDCG@10 = 15.5966 | Rec@10 = 14.0078 | Prec@10 = 11.449 | NDCG@100 = 27.4376 | Rec@100 = 49.439 | Prec@100 = 5.2117 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 | 10000/116677 batches | ms/batch 13.23 | loss 457.3590\n",
            "| epoch  10 | 20000/116677 batches | ms/batch 13.23 | loss 454.9706\n",
            "| epoch  10 | 30000/116677 batches | ms/batch 13.30 | loss 463.9684\n",
            "| epoch  10 | 40000/116677 batches | ms/batch 13.44 | loss 470.8296\n",
            "| epoch  10 | 50000/116677 batches | ms/batch 13.29 | loss 462.0360\n",
            "| epoch  10 | 60000/116677 batches | ms/batch 13.35 | loss 467.3787\n",
            "| epoch  10 | 70000/116677 batches | ms/batch 13.32 | loss 462.5497\n",
            "| epoch  10 | 80000/116677 batches | ms/batch 13.40 | loss 468.1197\n",
            "| epoch  10 | 90000/116677 batches | ms/batch 13.33 | loss 464.2676\n",
            "| epoch  10 | 100000/116677 batches | ms/batch 13.21 | loss 454.2086\n",
            "| epoch  10 | 110000/116677 batches | ms/batch 13.34 | loss 463.9356\n",
            "| epoch  10 | 116677/116677 batches | ms/batch 13.32 | loss 464.1107\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1630.98s | loss = 384.6796 | NDCG@10 = 16.2035 | Rec@10 = 14.3839 | Prec@10 = 11.5 | NDCG@100 = 27.716 | Rec@100 = 50.6003 | Prec@100 = 5.545 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 1630.98s | loss = 357.2536 | NDCG@10 = 15.2907 | Rec@10 = 13.8219 | Prec@10 = 11.239 | NDCG@100 = 27.2153 | Rec@100 = 49.4991 | Prec@100 = 5.1686 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 | 10000/116677 batches | ms/batch 13.16 | loss 450.7879\n",
            "| epoch  11 | 20000/116677 batches | ms/batch 13.36 | loss 467.4327\n",
            "| epoch  11 | 30000/116677 batches | ms/batch 13.08 | loss 449.2977\n",
            "| epoch  11 | 40000/116677 batches | ms/batch 13.28 | loss 461.6892\n",
            "| epoch  11 | 50000/116677 batches | ms/batch 13.31 | loss 464.1856\n",
            "| epoch  11 | 60000/116677 batches | ms/batch 13.23 | loss 457.7048\n",
            "| epoch  11 | 70000/116677 batches | ms/batch 13.33 | loss 467.0268\n",
            "| epoch  11 | 80000/116677 batches | ms/batch 13.22 | loss 456.4501\n",
            "| epoch  11 | 90000/116677 batches | ms/batch 13.34 | loss 467.2553\n",
            "| epoch  11 | 100000/116677 batches | ms/batch 13.27 | loss 461.4214\n",
            "| epoch  11 | 110000/116677 batches | ms/batch 13.55 | loss 477.3550\n",
            "| epoch  11 | 116677/116677 batches | ms/batch 13.50 | loss 476.4089\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1629.43s | loss = 383.6645 | NDCG@10 = 18.0169 | Rec@10 = 14.8678 | Prec@10 = 12.4 | NDCG@100 = 28.8116 | Rec@100 = 50.7551 | Prec@100 = 5.545 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 1629.43s | loss = 356.7992 | NDCG@10 = 15.7498 | Rec@10 = 14.0792 | Prec@10 = 11.631 | NDCG@100 = 27.5853 | Rec@100 = 49.719 | Prec@100 = 5.2829 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 | 10000/116677 batches | ms/batch 13.54 | loss 474.8755\n",
            "| epoch  12 | 20000/116677 batches | ms/batch 13.27 | loss 460.6954\n",
            "| epoch  12 | 30000/116677 batches | ms/batch 13.48 | loss 473.3989\n",
            "| epoch  12 | 40000/116677 batches | ms/batch 13.32 | loss 462.7107\n",
            "| epoch  12 | 50000/116677 batches | ms/batch 13.27 | loss 458.7108\n",
            "| epoch  12 | 60000/116677 batches | ms/batch 13.37 | loss 467.5242\n",
            "| epoch  12 | 70000/116677 batches | ms/batch 13.25 | loss 457.8435\n",
            "| epoch  12 | 80000/116677 batches | ms/batch 13.33 | loss 461.0917\n",
            "| epoch  12 | 90000/116677 batches | ms/batch 13.43 | loss 469.1765\n",
            "| epoch  12 | 100000/116677 batches | ms/batch 13.16 | loss 448.6546\n",
            "| epoch  12 | 110000/116677 batches | ms/batch 13.18 | loss 454.6646\n",
            "| epoch  12 | 116677/116677 batches | ms/batch 13.32 | loss 461.6265\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1633.01s | loss = 383.3182 | NDCG@10 = 16.038 | Rec@10 = 14.7353 | Prec@10 = 11.85 | NDCG@100 = 27.1279 | Rec@100 = 50.3793 | Prec@100 = 5.49 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 1633.01s | loss = 356.3701 | NDCG@10 = 15.7067 | Rec@10 = 13.9509 | Prec@10 = 11.576 | NDCG@100 = 27.6321 | Rec@100 = 49.7648 | Prec@100 = 5.235 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 | 10000/116677 batches | ms/batch 13.49 | loss 471.7125\n",
            "| epoch  13 | 20000/116677 batches | ms/batch 13.26 | loss 457.6441\n",
            "| epoch  13 | 30000/116677 batches | ms/batch 13.35 | loss 462.4188\n",
            "| epoch  13 | 40000/116677 batches | ms/batch 13.23 | loss 459.8980\n",
            "| epoch  13 | 50000/116677 batches | ms/batch 13.35 | loss 465.2036\n",
            "| epoch  13 | 60000/116677 batches | ms/batch 13.39 | loss 468.5459\n",
            "| epoch  13 | 70000/116677 batches | ms/batch 13.43 | loss 469.4281\n",
            "| epoch  13 | 80000/116677 batches | ms/batch 13.32 | loss 461.0539\n",
            "| epoch  13 | 90000/116677 batches | ms/batch 13.31 | loss 461.3298\n",
            "| epoch  13 | 100000/116677 batches | ms/batch 13.40 | loss 465.7961\n",
            "| epoch  13 | 110000/116677 batches | ms/batch 13.26 | loss 459.0055\n",
            "| epoch  13 | 116677/116677 batches | ms/batch 13.06 | loss 441.3925\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1633.17s | loss = 385.8574 | NDCG@10 = 16.3096 | Rec@10 = 13.7021 | Prec@10 = 11.75 | NDCG@100 = 27.818 | Rec@100 = 51.4222 | Prec@100 = 5.615 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 1633.17s | loss = 358.0028 | NDCG@10 = 15.4404 | Rec@10 = 13.7342 | Prec@10 = 11.41 | NDCG@100 = 27.2712 | Rec@100 = 49.3907 | Prec@100 = 5.2418 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 | 10000/116677 batches | ms/batch 13.34 | loss 461.7330\n",
            "| epoch  14 | 20000/116677 batches | ms/batch 13.27 | loss 455.5114\n",
            "| epoch  14 | 30000/116677 batches | ms/batch 13.47 | loss 471.9596\n",
            "| epoch  14 | 40000/116677 batches | ms/batch 13.17 | loss 447.1707\n",
            "| epoch  14 | 50000/116677 batches | ms/batch 13.31 | loss 457.1918\n",
            "| epoch  14 | 60000/116677 batches | ms/batch 13.57 | loss 476.2708\n",
            "| epoch  14 | 70000/116677 batches | ms/batch 13.52 | loss 472.3150\n",
            "| epoch  14 | 80000/116677 batches | ms/batch 13.28 | loss 458.3230\n",
            "| epoch  14 | 90000/116677 batches | ms/batch 13.35 | loss 459.6116\n",
            "| epoch  14 | 100000/116677 batches | ms/batch 13.37 | loss 462.4268\n",
            "| epoch  14 | 110000/116677 batches | ms/batch 13.43 | loss 462.6671\n",
            "| epoch  14 | 116677/116677 batches | ms/batch 13.40 | loss 466.6982\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1638.38s | loss = 383.9586 | NDCG@10 = 16.9517 | Rec@10 = 13.9265 | Prec@10 = 11.55 | NDCG@100 = 28.7138 | Rec@100 = 51.6387 | Prec@100 = 5.58 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 1638.38s | loss = 356.2226 | NDCG@10 = 15.7091 | Rec@10 = 14.0944 | Prec@10 = 11.611 | NDCG@100 = 27.6721 | Rec@100 = 49.9695 | Prec@100 = 5.2702 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 | 10000/116677 batches | ms/batch 13.57 | loss 474.6288\n",
            "| epoch  15 | 20000/116677 batches | ms/batch 13.39 | loss 466.8512\n",
            "| epoch  15 | 30000/116677 batches | ms/batch 13.22 | loss 452.1200\n",
            "| epoch  15 | 40000/116677 batches | ms/batch 13.64 | loss 479.4101\n",
            "| epoch  15 | 50000/116677 batches | ms/batch 13.28 | loss 457.9919\n",
            "| epoch  15 | 60000/116677 batches | ms/batch 13.27 | loss 456.7517\n",
            "| epoch  15 | 70000/116677 batches | ms/batch 13.22 | loss 456.8335\n",
            "| epoch  15 | 80000/116677 batches | ms/batch 13.22 | loss 453.0787\n",
            "| epoch  15 | 90000/116677 batches | ms/batch 13.35 | loss 463.7116\n",
            "| epoch  15 | 100000/116677 batches | ms/batch 13.30 | loss 453.2627\n",
            "| epoch  15 | 110000/116677 batches | ms/batch 13.65 | loss 481.4431\n",
            "| epoch  15 | 116677/116677 batches | ms/batch 13.19 | loss 448.7624\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1637.74s | loss = 384.5163 | NDCG@10 = 18.5122 | Rec@10 = 15.8356 | Prec@10 = 13.3 | NDCG@100 = 28.6228 | Rec@100 = 51.1172 | Prec@100 = 5.545 (TRAIN)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 1637.74s | loss = 356.6079 | NDCG@10 = 15.8464 | Rec@10 = 14.147 | Prec@10 = 11.542 | NDCG@100 = 27.7568 | Rec@100 = 49.8581 | Prec@100 = 5.2269 (VAL)\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | loss = 350.9624 | NDCG@10 = 15.5975 | Rec@10 = 13.9133 | Prec@10 = 11.405 | NDCG@100 = 27.3556 | Rec@100 = 49.5975 | Prec@100 = 5.1352 (TEST)\n",
            "=========================================================================================\n",
            "average runtime per epoch = 1645.2687 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58X015llSBI",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib6yaz0WlTJt",
        "colab_type": "text"
      },
      "source": [
        "# Testphase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHA-MsxB9bd9",
        "colab_type": "code",
        "outputId": "9fe180b0-7b8a-4d89-d4f6-4ddd41ff6e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Checking metrics for the test set on best saved model\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "hyper_params['noise'] = 2\n",
        "criterion = VAELoss(hyper_params)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "string = \"\"\n",
        "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "ss  = '=' * 89\n",
        "ss += '\\n| End of training'\n",
        "ss += string + \" (TEST)\"\n",
        "ss += '\\n'\n",
        "ss += '=' * 89\n",
        "file_write(hyper_params['log_file'], ss)\n",
        "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 53, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 53, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 37, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 37, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 125, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 125, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 94, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 94, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 33, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 33, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 58, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 58, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 96, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 96, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 26, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 26, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 4, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 4, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 103, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 103, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 3, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 3, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 102, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 102, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 72, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 72, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 46, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 46, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 3, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 3, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 3, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 3, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 343, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 343, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 132, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 132, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 190, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 190, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 70, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 70, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 105, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 105, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 4, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 4, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 68, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 68, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 113, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 113, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 45, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 45, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 55, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 55, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 86, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 86, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 65, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 65, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 63, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 63, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 56, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 56, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 128, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 128, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 98, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 98, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 80, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 80, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 54, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 54, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 100, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 100, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 84, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 84, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 65, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 65, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 166, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 166, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 150, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 150, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 92, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 92, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 107, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 107, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 33, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 33, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 30, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 30, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 18, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 18, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 94, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 94, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 34, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 34, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 65, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 65, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 50, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 50, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 47, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 47, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 97, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 97, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 55, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 55, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 122, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 122, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 71, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 71, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 48, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 48, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 43, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 43, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 95, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 95, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 149, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 149, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 452, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 452, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 55, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 55, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 59, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 59, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 26, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 26, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 33, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 33, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 28, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 28, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 56, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 56, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 56, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 56, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 51, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 51, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 17, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 17, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 57, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 57, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 118, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 118, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 53, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 53, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 29, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 29, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 198, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 198, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 146, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 146, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 3, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 3, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 36, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 36, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 90, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 90, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 263, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 263, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 57, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 57, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 115, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 115, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 156, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 156, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 17, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 17, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 63, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 63, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 28, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 28, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 99, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 99, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 43, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 43, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 110, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 110, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 34, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 34, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 106, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 106, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 42, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 42, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 52, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 52, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 118, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 118, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 136, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 136, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 17, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 17, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 150, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 150, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 4, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 4, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 50, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 50, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 39, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 39, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 424, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 424, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 43, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 43, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 487, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 487, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 90, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 90, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 90, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 90, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 97, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 97, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 111, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 111, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 374, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 374, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 341, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 341, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 87, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 87, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 46, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 46, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 147, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 147, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 135, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 135, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 75, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 75, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 41, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 41, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 62, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 62, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 29, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 29, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 27, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 27, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 69, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 69, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 72, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 72, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 171, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 171, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 197, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 197, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 47, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 47, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 43, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 43, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 148, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 148, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 68, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 68, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 64, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 64, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 91, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 91, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 34, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 34, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 76, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 76, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 44, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 44, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 69, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 69, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 29, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 29, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 18, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 18, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 17, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 17, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 195, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 195, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 295, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 295, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 83, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 83, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 220, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 220, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 18, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 18, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 40, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 40, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 424, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 424, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 130, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 130, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 51, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 51, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 27, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 27, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 55, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 55, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 59, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 59, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 183, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 183, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 156, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 156, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 57, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 57, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 193, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 193, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 96, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 96, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 28, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 28, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 69, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 69, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 56, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 56, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 13, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 13, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 87, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 87, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 28, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 28, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 257, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 257, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 77, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 77, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 44, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 44, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 56, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 56, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 41, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 41, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 123, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 123, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 4, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 4, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 163, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 163, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 48, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 48, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 159, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 159, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 27, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 27, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 150, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 150, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 41, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 41, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 80, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 80, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 127, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 127, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 74, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 74, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 69, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 69, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 38, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 38, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 3, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 3, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 303, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 303, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 111, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 111, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 30, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 30, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 79, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 79, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 4, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 4, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 101, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 101, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 77, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 77, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 297, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 297, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 82, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 82, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 137, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 137, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 478, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 478, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 83, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 83, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 74, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 74, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 26, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 26, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 55, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 55, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 62, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 62, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 72, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 72, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 93, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 93, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 39, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 39, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 219, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 219, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 131, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 131, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 156, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 156, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 15, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 15, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 20, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 20, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 29, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 29, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 183, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 183, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 36, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 36, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 29, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 29, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 39, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 39, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 74, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 74, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 146, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 146, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 16, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 16, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 40, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 40, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 90, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 90, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 32, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 32, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 44, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 44, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 71, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 71, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 22, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 22, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 46, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 46, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 60, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 60, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 65, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 65, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 34, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 34, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 111, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 111, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 35, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 35, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 28, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 28, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 61, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 61, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 51, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 51, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 33, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 33, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 39, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 39, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 9, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 9, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 25, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 25, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 23, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 23, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 37, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 37, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 43, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 43, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 110, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 110, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 31, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 31, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 61, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 61, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 12, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 12, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 93, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 93, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 6, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 6, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 93, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 93, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 45, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 45, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 17, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 17, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 5, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 5, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 51, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 51, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 21, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 21, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 82, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 82, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 19, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 19, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 42, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 42, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 164, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 164, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 52, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 52, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 10, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 10, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 7, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 7, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 24, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 24, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 11, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 11, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 186, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 186, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 79, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 79, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 26, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 26, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 179, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 179, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 8, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 8, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 182, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 182, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 38, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 38, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n",
            "output decoder\n",
            "torch.Size([1, 14, 20108])\n",
            "after decoder after criterian\n",
            "torch.Size([1, 14, 20108])\n",
            "x_scattered\n",
            "torch.Size([1, 20108])\n",
            "x scattered after \n",
            "last pred\n",
            "torch.Size([1, 20108])\n",
            "score\n",
            "torch.Size([20108])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAFSCAYAAADSLEioAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTURERESUAgbUREREREQp+P+3kPxV6v+lawAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | loss = 358.81 | NDCG@10 = 14.1517 | Rec@10 = 12.8327 | Prec@10 = 10.403 | NDCG@100 = 25.7355 | Rec@100 = 47.7898 | Prec@100 = 4.9301 (TEST)\n",
            "=========================================================================================\n",
            "average runtime per epoch = 2059.1587 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz84XqLi9uy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-WnBUUZVjgm",
        "colab_type": "code",
        "outputId": "69b8ea73-2ebd-4156-c0c5-43324d649f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#HELLOOOOO\n",
        "\n",
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "hyper_params['noise'] = 2\n",
        "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
        "\n",
        "criterion = VAELoss(hyper_params)\n",
        "\n",
        "decoder_output,last_predictions,predicted_scores,dcg,metrics, len_to_ndcg_at_100_map = Fairness_evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "#print ('the shape ')\n",
        "#print (decoder_output.shape)\n",
        "#print(decoder_output.shape)\n",
        "#print(last_predictions.shape)\n",
        "#print(predicted_scores.shape)\n",
        "\n",
        "#print(last_predictions.shape)\n",
        "#print (last_predictions)\n",
        "#print (predicted_scores)\n",
        "#ufairs, ndcgs = Fairness_at_k_rounds(last_predictions, dcg)\n",
        "print (metrics)\n",
        "print (len_to_ndcg_at_100_map)\n",
        "# Plot sequence length vs NDCG@100 graph\n",
        "#plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "#string = \"\"\n",
        "#for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "#ss  = '=' * 89\n",
        "#ss += '\\n| End of training'\n",
        "#ss += string + \" (TEST)\"\n",
        "#ss += '\\n'\n",
        "#ss += '=' * 89\n",
        "#file_write(hyper_params['log_file'], ss)\n",
        "#print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8538846/8538846 [00:13<00:00, 626597.19it/s]\n",
            "100%|██████████| 581927/581927 [00:00<00:00, 815364.97it/s]\n",
            "100%|██████████| 150474/150474 [00:00<00:00, 679889.24it/s]\n",
            "100%|██████████| 571057/571057 [00:00<00:00, 863125.04it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 868656.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [ 2.0951,  7.1749,  4.9191,  ..., -0.8407, -0.8407, -0.8407],\n",
            "         [ 1.5107,  6.6356,  4.2011,  ..., -0.6683, -0.6683, -0.6683]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 4.7825,  7.7302,  6.5286,  ..., -1.1555, -1.1555, -1.1555],\n",
            "         [ 4.6629,  7.6848,  6.9256,  ..., -1.1076, -1.1076, -1.1076],\n",
            "         [ 4.5981,  7.7719,  6.7112,  ..., -1.1284, -1.1284, -1.1284],\n",
            "         ...,\n",
            "         [ 6.3781,  7.1073,  5.9001,  ..., -0.9977, -0.9977, -0.9977],\n",
            "         [ 5.1496,  6.8490,  5.7652,  ..., -0.9399, -0.9399, -0.9399],\n",
            "         [ 6.1191,  8.4203,  7.1004,  ..., -0.9383, -0.9383, -0.9383]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 5.7238,  7.6555,  7.2060,  ..., -1.0971, -1.0971, -1.0971],\n",
            "         [ 5.1239,  6.7759,  6.5815,  ..., -1.0350, -1.0350, -1.0350],\n",
            "         [ 4.7901,  7.9023,  7.1465,  ..., -1.0376, -1.0376, -1.0376],\n",
            "         ...,\n",
            "         [ 4.5408,  6.8244,  5.6129,  ..., -1.0950, -1.0950, -1.0950],\n",
            "         [ 3.9439,  6.5244,  5.9338,  ..., -1.0667, -1.0667, -1.0667],\n",
            "         [ 4.5573,  7.2756,  6.3256,  ..., -1.0911, -1.0911, -1.0911]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 2.7662,  5.5032,  4.4225,  ..., -1.0438, -1.0438, -1.0438],\n",
            "         [ 4.0576,  6.5801,  5.8785,  ..., -0.9674, -0.9674, -0.9674],\n",
            "         [ 4.6377,  7.4780,  6.9137,  ..., -0.9353, -0.9353, -0.9353],\n",
            "         ...,\n",
            "         [ 6.5638,  5.0960,  4.4548,  ..., -0.7342, -0.7342, -0.7342],\n",
            "         [ 7.1686,  5.1632,  3.9881,  ..., -0.7111, -0.7111, -0.7111],\n",
            "         [ 7.5026,  5.1673,  3.9785,  ..., -0.6799, -0.6799, -0.6799]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 83, 20108])\n",
            "tensor([[[ 1.0390,  5.0665,  3.3497,  ..., -0.8465, -0.8465, -0.8465],\n",
            "         [ 1.6606,  5.0473,  3.9980,  ..., -0.8322, -0.8322, -0.8322],\n",
            "         [ 2.1892,  5.9089,  4.6561,  ..., -0.8718, -0.8718, -0.8718],\n",
            "         ...,\n",
            "         [ 4.9359,  6.0635,  6.2839,  ..., -0.7443, -0.7443, -0.7443],\n",
            "         [ 4.3142,  5.6737,  6.0026,  ..., -0.6862, -0.6862, -0.6862],\n",
            "         [ 4.0165,  5.0220,  5.5454,  ..., -0.6554, -0.6554, -0.6554]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 41, 20108])\n",
            "tensor([[[ 7.0252,  8.3753,  7.3348,  ..., -1.0161, -1.0161, -1.0161],\n",
            "         [ 6.6316,  7.2914,  6.9910,  ..., -1.1325, -1.1325, -1.1325],\n",
            "         [ 6.3475,  5.8359,  5.9685,  ..., -1.0587, -1.0587, -1.0587],\n",
            "         ...,\n",
            "         [ 5.9988,  5.0306,  4.7994,  ..., -0.8119, -0.8119, -0.8119],\n",
            "         [ 6.2212,  5.5489,  5.1187,  ..., -0.7950, -0.7950, -0.7950],\n",
            "         [ 6.0187,  5.7196,  5.0088,  ..., -0.7893, -0.7893, -0.7893]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 18, 20108])\n",
            "tensor([[[ 4.8412,  7.5411,  6.1245,  ..., -1.1117, -1.1117, -1.1117],\n",
            "         [ 5.4297,  7.7246,  6.2845,  ..., -0.9124, -0.9124, -0.9124],\n",
            "         [ 5.3252,  6.5035,  5.0578,  ..., -0.7563, -0.7563, -0.7563],\n",
            "         ...,\n",
            "         [ 6.7356,  2.3634,  1.4402,  ..., -0.4314, -0.4314, -0.4314],\n",
            "         [ 6.6758,  1.8729,  1.1515,  ..., -0.4572, -0.4572, -0.4572],\n",
            "         [ 5.9891,  1.5784,  1.1164,  ..., -0.4160, -0.4160, -0.4160]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 4.4907,  6.7745,  6.4499,  ..., -1.1530, -1.1530, -1.1530],\n",
            "         [ 4.8663,  5.9403,  5.6166,  ..., -1.0982, -1.0982, -1.0982],\n",
            "         [ 4.3682,  6.1395,  5.8078,  ..., -1.0628, -1.0628, -1.0628],\n",
            "         ...,\n",
            "         [ 4.6754,  3.5482,  5.0987,  ..., -0.9508, -0.9508, -0.9508],\n",
            "         [ 3.8361,  3.7726,  5.0436,  ..., -0.9570, -0.9570, -0.9570],\n",
            "         [ 3.1105,  3.5822,  4.4574,  ..., -0.8615, -0.8615, -0.8615]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 224, 20108])\n",
            "tensor([[[ 5.1284,  7.4136,  5.6789,  ..., -0.9956, -0.9956, -0.9956],\n",
            "         [ 5.4734,  7.2244,  6.3526,  ..., -1.0744, -1.0744, -1.0744],\n",
            "         [ 6.3388,  7.0466,  6.4365,  ..., -1.1405, -1.1405, -1.1405],\n",
            "         ...,\n",
            "         [ 2.8851,  2.4719,  3.3860,  ..., -0.9227, -0.9227, -0.9227],\n",
            "         [ 2.3449,  2.0359,  2.8885,  ..., -0.9452, -0.9452, -0.9452],\n",
            "         [ 2.7788,  2.2988,  2.9076,  ..., -0.9391, -0.9391, -0.9391]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 4.0084,  6.5674,  5.5444,  ..., -1.0280, -1.0280, -1.0280],\n",
            "         [ 4.3074,  5.9814,  5.4688,  ..., -0.9784, -0.9784, -0.9784],\n",
            "         [ 3.5282,  3.8055,  3.4471,  ..., -0.9195, -0.9195, -0.9195]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 41, 20108])\n",
            "tensor([[[ 5.0452,  7.3642,  6.3137,  ..., -1.0690, -1.0690, -1.0690],\n",
            "         [ 4.9836,  7.2819,  6.1471,  ..., -1.0158, -1.0158, -1.0158],\n",
            "         [ 5.7649,  7.4994,  7.4698,  ..., -1.0763, -1.0763, -1.0763],\n",
            "         ...,\n",
            "         [ 7.6513,  8.0701,  7.1026,  ..., -0.9335, -0.9335, -0.9335],\n",
            "         [ 7.3817,  7.9563,  6.7576,  ..., -0.9661, -0.9661, -0.9661],\n",
            "         [ 6.6240,  7.6730,  6.8055,  ..., -0.9337, -0.9337, -0.9337]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 101, 20108])\n",
            "tensor([[[ 3.4094,  4.0835,  3.3484,  ..., -1.0190, -1.0190, -1.0190],\n",
            "         [ 3.3636,  6.2247,  4.6500,  ..., -1.0768, -1.0768, -1.0768],\n",
            "         [ 2.9035,  6.1991,  3.7752,  ..., -1.0459, -1.0459, -1.0459],\n",
            "         ...,\n",
            "         [ 4.2007,  5.0080,  5.0102,  ..., -0.9322, -0.9322, -0.9322],\n",
            "         [ 3.5755,  4.5382,  4.8152,  ..., -0.9586, -0.9586, -0.9586],\n",
            "         [ 2.6499,  4.4424,  4.3536,  ..., -0.9187, -0.9187, -0.9187]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 142, 20108])\n",
            "tensor([[[ 2.5097,  5.6308,  4.4878,  ..., -1.0848, -1.0848, -1.0848],\n",
            "         [ 2.3443,  5.4312,  4.1844,  ..., -1.0786, -1.0786, -1.0786],\n",
            "         [ 2.2082,  5.7204,  3.6594,  ..., -1.0767, -1.0767, -1.0767],\n",
            "         ...,\n",
            "         [ 7.1892,  6.8977,  6.7339,  ..., -0.9071, -0.9071, -0.9071],\n",
            "         [ 6.7415,  6.7850,  6.7135,  ..., -0.8717, -0.8717, -0.8717],\n",
            "         [ 6.9307,  6.6220,  6.6264,  ..., -0.9153, -0.9153, -0.9153]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 67, 20108])\n",
            "tensor([[[ 4.1881,  6.3687,  3.6951,  ..., -0.5571, -0.5571, -0.5571],\n",
            "         [ 6.1783,  6.3553,  3.5659,  ..., -0.4620, -0.4620, -0.4620],\n",
            "         [ 5.8100,  5.7977,  2.9078,  ..., -0.3805, -0.3805, -0.3805],\n",
            "         ...,\n",
            "         [ 4.3609,  4.3027,  4.0829,  ..., -0.7786, -0.7786, -0.7786],\n",
            "         [ 3.8927,  4.5463,  4.0353,  ..., -0.7908, -0.7908, -0.7908],\n",
            "         [ 4.0389,  4.7477,  4.5165,  ..., -0.8439, -0.8439, -0.8439]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 5.9960,  5.3959,  4.1441,  ..., -0.8074, -0.8074, -0.8074],\n",
            "         [ 5.1588,  4.6876,  3.1463,  ..., -0.7395, -0.7395, -0.7395],\n",
            "         [ 5.5061,  4.9183,  3.3949,  ..., -0.6786, -0.6786, -0.6786],\n",
            "         ...,\n",
            "         [ 5.1826,  2.8618,  1.0224,  ..., -0.5135, -0.5135, -0.5135],\n",
            "         [ 4.8500,  2.8258,  0.5397,  ..., -0.4385, -0.4385, -0.4385],\n",
            "         [ 5.0538,  2.8464,  0.8626,  ..., -0.5141, -0.5141, -0.5141]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 100, 20108])\n",
            "tensor([[[ 4.6781,  6.9845,  6.2327,  ..., -1.0068, -1.0068, -1.0068],\n",
            "         [ 6.3310,  6.6052,  7.0053,  ..., -1.0721, -1.0721, -1.0721],\n",
            "         [ 6.1097,  6.6084,  7.5047,  ..., -1.0820, -1.0820, -1.0820],\n",
            "         ...,\n",
            "         [ 5.4750,  6.0470,  7.1388,  ..., -1.0982, -1.0982, -1.0982],\n",
            "         [ 4.8236,  6.0173,  6.4601,  ..., -1.0304, -1.0304, -1.0304],\n",
            "         [ 4.5435,  6.8631,  5.9050,  ..., -0.9585, -0.9585, -0.9585]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 45, 20108])\n",
            "tensor([[[ 3.5086,  4.6516,  2.3651,  ..., -0.5024, -0.5024, -0.5024],\n",
            "         [ 3.6602,  4.6479,  2.8659,  ..., -0.5037, -0.5037, -0.5037],\n",
            "         [ 3.2192,  4.5519,  3.0727,  ..., -0.4539, -0.4539, -0.4539],\n",
            "         ...,\n",
            "         [ 5.0207,  1.3487,  0.4960,  ..., -0.3120, -0.3120, -0.3120],\n",
            "         [ 4.8753,  1.0553,  0.3701,  ..., -0.3100, -0.3100, -0.3100],\n",
            "         [ 5.0661,  1.5767,  0.7303,  ..., -0.3204, -0.3204, -0.3204]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 127, 20108])\n",
            "tensor([[[ 5.4527,  8.1020,  6.1067,  ..., -0.9581, -0.9581, -0.9581],\n",
            "         [ 5.2232,  8.1445,  6.8940,  ..., -0.9585, -0.9585, -0.9585],\n",
            "         [ 4.6139,  7.9405,  5.6385,  ..., -0.9039, -0.9039, -0.9039],\n",
            "         ...,\n",
            "         [ 5.4054,  4.8694,  5.2377,  ..., -0.9208, -0.9208, -0.9208],\n",
            "         [ 4.9923,  5.2927,  5.6193,  ..., -0.9393, -0.9393, -0.9393],\n",
            "         [ 4.8557,  4.7938,  5.4343,  ..., -0.8719, -0.8719, -0.8719]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 2.9794,  4.4905,  3.8625,  ..., -1.0262, -1.0262, -1.0262],\n",
            "         [ 2.5141,  4.4140,  3.5332,  ..., -1.0146, -1.0146, -1.0146],\n",
            "         [ 3.3749,  5.8372,  4.2554,  ..., -0.9010, -0.9010, -0.9010],\n",
            "         ...,\n",
            "         [ 5.6031,  6.9717,  5.9824,  ..., -0.8160, -0.8160, -0.8160],\n",
            "         [ 5.4316,  6.3315,  5.3811,  ..., -0.7861, -0.7861, -0.7861],\n",
            "         [ 5.2462,  7.3521,  5.6850,  ..., -0.8063, -0.8063, -0.8063]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 5.6779,  6.3021,  6.2530,  ..., -1.1032, -1.1032, -1.1032],\n",
            "         [ 6.1510,  7.3653,  7.5049,  ..., -1.0896, -1.0896, -1.0896],\n",
            "         [ 5.8490,  7.1416,  7.0626,  ..., -1.0961, -1.0961, -1.0961],\n",
            "         ...,\n",
            "         [ 4.6738,  6.3815,  6.3436,  ..., -1.1146, -1.1146, -1.1146],\n",
            "         [ 5.2312,  6.3344,  6.1130,  ..., -1.0833, -1.0833, -1.0833],\n",
            "         [ 5.6569,  6.4909,  6.5478,  ..., -1.0857, -1.0857, -1.0857]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 4.4955,  6.6550,  5.8106,  ..., -0.9582, -0.9582, -0.9582],\n",
            "         [ 4.6932,  7.3606,  6.8682,  ..., -0.9924, -0.9924, -0.9924],\n",
            "         [ 5.0250,  6.7093,  7.1155,  ..., -1.0103, -1.0103, -1.0103],\n",
            "         [ 5.1032,  6.6105,  5.9146,  ..., -0.8238, -0.8238, -0.8238],\n",
            "         [ 4.5029,  7.0736,  6.5848,  ..., -0.8408, -0.8408, -0.8408],\n",
            "         [ 4.4124,  5.1831,  6.5751,  ..., -0.9900, -0.9900, -0.9900]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 114, 20108])\n",
            "tensor([[[ 3.1769,  5.3153,  3.9189,  ..., -1.0481, -1.0481, -1.0481],\n",
            "         [ 3.1931,  5.4922,  4.1802,  ..., -1.0779, -1.0779, -1.0779],\n",
            "         [ 3.1779,  5.7233,  3.9899,  ..., -1.0174, -1.0174, -1.0174],\n",
            "         ...,\n",
            "         [ 2.7257,  4.2687,  3.9783,  ..., -0.5872, -0.5872, -0.5872],\n",
            "         [ 3.5219,  4.2722,  4.2478,  ..., -0.6736, -0.6736, -0.6736],\n",
            "         [ 4.0036,  4.7470,  4.3606,  ..., -0.7758, -0.7758, -0.7758]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 47, 20108])\n",
            "tensor([[[ 4.7219,  7.7922,  7.2218,  ..., -1.0615, -1.0615, -1.0615],\n",
            "         [ 4.7485,  8.5640,  6.6366,  ..., -1.0340, -1.0340, -1.0340],\n",
            "         [ 6.1865,  8.1010,  7.0156,  ..., -1.1450, -1.1450, -1.1450],\n",
            "         ...,\n",
            "         [ 2.3129,  5.5448,  5.2363,  ..., -0.7129, -0.7129, -0.7129],\n",
            "         [ 2.2298,  5.4915,  4.7865,  ..., -0.7917, -0.7917, -0.7917],\n",
            "         [ 1.8048,  5.4714,  4.9569,  ..., -0.7410, -0.7410, -0.7410]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 58, 20108])\n",
            "tensor([[[ 4.2653,  5.5667,  5.0752,  ..., -1.0822, -1.0822, -1.0822],\n",
            "         [ 3.0064,  6.2196,  4.7037,  ..., -1.0851, -1.0851, -1.0851],\n",
            "         [ 3.0570,  6.2857,  5.1027,  ..., -1.1116, -1.1116, -1.1116],\n",
            "         ...,\n",
            "         [ 4.0957,  7.6387,  6.4825,  ..., -0.8634, -0.8634, -0.8634],\n",
            "         [ 4.2554,  7.8794,  6.6060,  ..., -0.8384, -0.8384, -0.8384],\n",
            "         [ 4.5300,  7.9150,  6.5311,  ..., -0.8781, -0.8781, -0.8781]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 175, 20108])\n",
            "tensor([[[ 6.2855,  7.9549,  7.8690,  ..., -1.1486, -1.1486, -1.1486],\n",
            "         [ 5.4297,  8.1884,  7.1523,  ..., -1.1290, -1.1290, -1.1290],\n",
            "         [ 5.2811,  7.1626,  6.9788,  ..., -1.0496, -1.0496, -1.0496],\n",
            "         ...,\n",
            "         [ 4.3330,  4.4898,  3.5053,  ..., -0.8892, -0.8892, -0.8892],\n",
            "         [ 4.1082,  4.0831,  3.1062,  ..., -0.8888, -0.8888, -0.8888],\n",
            "         [ 3.6740,  3.2131,  2.3524,  ..., -0.9119, -0.9119, -0.9119]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 75, 20108])\n",
            "tensor([[[ 5.3387,  6.6423,  4.9309,  ..., -0.6476, -0.6476, -0.6476],\n",
            "         [ 6.7711,  9.3056,  7.5303,  ..., -0.8595, -0.8595, -0.8595],\n",
            "         [ 7.2334,  9.1032,  8.6822,  ..., -0.8177, -0.8177, -0.8177],\n",
            "         ...,\n",
            "         [ 5.4418,  3.7945,  4.6893,  ..., -0.9667, -0.9667, -0.9667],\n",
            "         [ 6.1168,  4.1777,  4.5833,  ..., -1.0043, -1.0043, -1.0043],\n",
            "         [ 5.6058,  3.3689,  4.3487,  ..., -0.9784, -0.9784, -0.9784]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 2.3987,  4.7232,  2.9121,  ..., -0.9680, -0.9680, -0.9680],\n",
            "         [ 4.1019,  6.2040,  5.2334,  ..., -1.1086, -1.1086, -1.1086],\n",
            "         [ 4.3973,  6.2168,  6.4879,  ..., -1.0600, -1.0600, -1.0600],\n",
            "         ...,\n",
            "         [ 3.0634,  6.6715,  6.6021,  ..., -0.8379, -0.8379, -0.8379],\n",
            "         [ 3.3570,  7.4325,  7.1022,  ..., -0.8381, -0.8381, -0.8381],\n",
            "         [ 3.4474,  6.6030,  6.1601,  ..., -0.8601, -0.8601, -0.8601]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 70, 20108])\n",
            "tensor([[[ 3.6593,  7.0502,  6.2645,  ..., -1.1478, -1.1478, -1.1478],\n",
            "         [ 4.5649,  6.6785,  6.3417,  ..., -1.1442, -1.1442, -1.1442],\n",
            "         [ 4.8152,  6.1855,  6.8075,  ..., -0.9984, -0.9984, -0.9984],\n",
            "         ...,\n",
            "         [ 1.3220,  3.4214,  2.0897,  ..., -0.5616, -0.5616, -0.5616],\n",
            "         [ 1.0117,  3.2016,  2.1958,  ..., -0.4863, -0.4863, -0.4863],\n",
            "         [ 1.0757,  3.1440,  2.0918,  ..., -0.5407, -0.5407, -0.5407]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.0868,  5.3205,  3.5657,  ..., -1.0327, -1.0327, -1.0327],\n",
            "         [ 2.7301,  4.5125,  3.1839,  ..., -1.0438, -1.0438, -1.0438],\n",
            "         [ 2.4429,  5.1594,  3.6558,  ..., -1.0403, -1.0403, -1.0403],\n",
            "         ...,\n",
            "         [ 2.4892,  6.9685,  5.2277,  ..., -0.9192, -0.9192, -0.9192],\n",
            "         [ 3.4428,  6.4214,  4.6579,  ..., -0.9093, -0.9093, -0.9093],\n",
            "         [ 3.3178,  7.0329,  4.6763,  ..., -0.8704, -0.8704, -0.8704]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.0086,  5.4944,  4.1113,  ..., -0.9482, -0.9482, -0.9482],\n",
            "         [ 4.1940,  5.9245,  4.2622,  ..., -0.8471, -0.8471, -0.8471],\n",
            "         [ 3.8905,  5.6019,  4.6735,  ..., -0.8091, -0.8091, -0.8091],\n",
            "         ...,\n",
            "         [ 2.4037,  3.5730,  0.7294,  ..., -0.2751, -0.2751, -0.2751],\n",
            "         [ 3.3473,  2.4815,  0.3186,  ..., -0.2933, -0.2933, -0.2933],\n",
            "         [ 3.9544,  3.5613,  1.5339,  ..., -0.3870, -0.3870, -0.3870]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 18, 20108])\n",
            "tensor([[[ 5.2216,  6.6537,  6.6127,  ..., -1.0357, -1.0357, -1.0357],\n",
            "         [ 5.1771,  6.6246,  6.2445,  ..., -0.9997, -0.9997, -0.9997],\n",
            "         [ 5.2475,  7.6741,  7.3848,  ..., -1.0653, -1.0653, -1.0653],\n",
            "         ...,\n",
            "         [ 2.9935,  6.6211,  6.0800,  ..., -0.7745, -0.7745, -0.7745],\n",
            "         [ 3.1405,  7.0253,  6.5576,  ..., -0.8226, -0.8226, -0.8226],\n",
            "         [ 2.7316,  5.7611,  6.2475,  ..., -0.7880, -0.7880, -0.7880]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 66, 20108])\n",
            "tensor([[[ 5.9408,  6.2355,  6.1631,  ..., -1.1627, -1.1627, -1.1627],\n",
            "         [ 4.5500,  8.0954,  7.4665,  ..., -1.1049, -1.1049, -1.1049],\n",
            "         [ 4.8277,  7.9627,  7.9882,  ..., -1.1079, -1.1079, -1.1079],\n",
            "         ...,\n",
            "         [ 7.6564,  6.4831,  7.2818,  ..., -1.1089, -1.1089, -1.1089],\n",
            "         [ 8.0000,  6.3627,  7.1200,  ..., -1.0727, -1.0727, -1.0727],\n",
            "         [ 8.2487,  6.2814,  7.1643,  ..., -1.0568, -1.0568, -1.0568]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 5.0250,  7.9463,  6.6609,  ..., -1.0857, -1.0857, -1.0857],\n",
            "         [ 1.3674,  7.8516,  5.2814,  ..., -0.8336, -0.8336, -0.8336],\n",
            "         [ 0.8595,  7.8430,  5.4081,  ..., -0.6810, -0.6810, -0.6810],\n",
            "         ...,\n",
            "         [ 2.0753,  7.0064,  6.2733,  ..., -0.5782, -0.5782, -0.5782],\n",
            "         [ 2.3463,  7.3292,  6.5158,  ..., -0.6654, -0.6654, -0.6654],\n",
            "         [ 2.8924,  7.6974,  6.9386,  ..., -0.7071, -0.7071, -0.7071]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 37, 20108])\n",
            "tensor([[[ 2.5087,  5.2292,  4.2270,  ..., -1.0824, -1.0824, -1.0824],\n",
            "         [ 2.6591,  5.0195,  4.1094,  ..., -1.0615, -1.0615, -1.0615],\n",
            "         [ 1.6340,  5.0060,  3.2413,  ..., -0.9651, -0.9651, -0.9651],\n",
            "         ...,\n",
            "         [ 5.0230,  7.3226,  6.4945,  ..., -0.7827, -0.7827, -0.7827],\n",
            "         [ 5.0403,  8.3551,  7.1283,  ..., -0.8529, -0.8529, -0.8529],\n",
            "         [ 4.7933,  7.7468,  6.5457,  ..., -0.9229, -0.9229, -0.9229]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 3.5543,  5.5724,  4.5967,  ..., -0.9048, -0.9048, -0.9048],\n",
            "         [ 2.7137,  5.9098,  4.4461,  ..., -0.8613, -0.8613, -0.8613],\n",
            "         [ 2.0337,  5.6652,  3.5855,  ..., -0.6727, -0.6727, -0.6727],\n",
            "         ...,\n",
            "         [-0.2296,  3.4198,  1.8194,  ..., -0.3824, -0.3824, -0.3824],\n",
            "         [-1.2320,  3.0896,  0.9970,  ..., -0.2622, -0.2622, -0.2622],\n",
            "         [-0.9694,  3.1378,  1.7771,  ..., -0.3389, -0.3389, -0.3389]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 2.8211,  5.8514,  3.9095,  ..., -1.0085, -1.0085, -1.0085],\n",
            "         [ 4.4955,  6.7017,  5.6835,  ..., -1.1132, -1.1132, -1.1132],\n",
            "         [ 3.0071,  5.9021,  4.9482,  ..., -1.0136, -1.0136, -1.0136],\n",
            "         ...,\n",
            "         [ 4.4004,  5.6380,  4.2665,  ..., -0.8915, -0.8915, -0.8915],\n",
            "         [ 4.9368,  6.8065,  5.2010,  ..., -0.9409, -0.9409, -0.9409],\n",
            "         [ 5.3394,  7.1513,  5.7493,  ..., -0.9581, -0.9581, -0.9581]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.2367,  5.4897,  4.6216,  ..., -1.1092, -1.1092, -1.1092],\n",
            "         [ 3.5390,  5.2831,  4.2740,  ..., -1.0850, -1.0850, -1.0850],\n",
            "         [ 3.3175,  5.7268,  4.3546,  ..., -1.0486, -1.0486, -1.0486],\n",
            "         ...,\n",
            "         [ 5.4967,  7.7693,  6.3626,  ..., -0.9270, -0.9270, -0.9270],\n",
            "         [ 5.1928,  8.5360,  6.6951,  ..., -0.9265, -0.9265, -0.9265],\n",
            "         [ 4.9357,  9.2084,  6.5883,  ..., -1.0066, -1.0066, -1.0066]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 4.4400,  5.5210,  5.2924,  ..., -0.9522, -0.9522, -0.9522],\n",
            "         [ 3.3170,  5.1592,  3.3009,  ..., -0.8731, -0.8731, -0.8731],\n",
            "         [ 2.6026,  5.5110,  4.1592,  ..., -1.0201, -1.0201, -1.0201],\n",
            "         [ 2.9597,  5.8858,  4.8410,  ..., -0.9649, -0.9649, -0.9649]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 4.2694,  4.8610,  2.8846,  ..., -0.5757, -0.5757, -0.5757],\n",
            "         [ 4.2398,  4.8915,  2.5554,  ..., -0.4851, -0.4851, -0.4851],\n",
            "         [ 4.0345,  4.8106,  2.6655,  ..., -0.4614, -0.4614, -0.4614],\n",
            "         ...,\n",
            "         [ 5.8034,  5.4186,  3.0146,  ..., -0.3903, -0.3903, -0.3903],\n",
            "         [ 5.8198,  4.6184,  2.1360,  ..., -0.3537, -0.3537, -0.3537],\n",
            "         [ 6.4914,  4.8281,  2.8454,  ..., -0.4032, -0.4032, -0.4032]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 64, 20108])\n",
            "tensor([[[ 6.0656,  6.7555,  6.7960,  ..., -1.1182, -1.1182, -1.1182],\n",
            "         [ 5.4872,  6.7103,  6.5979,  ..., -1.1417, -1.1417, -1.1417],\n",
            "         [ 5.0958,  6.4395,  6.9865,  ..., -1.0571, -1.0571, -1.0571],\n",
            "         ...,\n",
            "         [ 2.9357,  4.1314,  5.8155,  ..., -0.8924, -0.8924, -0.8924],\n",
            "         [ 2.8032,  4.1604,  5.3048,  ..., -0.8786, -0.8786, -0.8786],\n",
            "         [ 2.5465,  3.9067,  5.4794,  ..., -0.8735, -0.8735, -0.8735]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 263, 20108])\n",
            "tensor([[[ 6.4921,  8.1756,  8.0401,  ..., -1.0583, -1.0583, -1.0583],\n",
            "         [ 6.5885,  7.9783,  7.9427,  ..., -1.0772, -1.0772, -1.0772],\n",
            "         [ 5.5580,  8.3352,  8.0954,  ..., -1.0321, -1.0321, -1.0321],\n",
            "         ...,\n",
            "         [ 1.3470,  3.8513,  3.0638,  ..., -0.4725, -0.4725, -0.4725],\n",
            "         [ 1.3207,  4.0748,  3.0886,  ..., -0.4803, -0.4803, -0.4803],\n",
            "         [ 1.1772,  3.5121,  2.8152,  ..., -0.4765, -0.4765, -0.4765]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 147, 20108])\n",
            "tensor([[[ 3.2066,  5.3878,  3.7227,  ..., -1.0371, -1.0371, -1.0371],\n",
            "         [ 2.6152,  5.5645,  3.5860,  ..., -1.0266, -1.0266, -1.0266],\n",
            "         [ 3.1248,  5.1747,  3.0088,  ..., -0.9532, -0.9532, -0.9532],\n",
            "         ...,\n",
            "         [ 3.5296,  3.6497,  3.2246,  ..., -0.7201, -0.7201, -0.7201],\n",
            "         [ 3.4028,  4.1991,  3.7039,  ..., -0.7813, -0.7813, -0.7813],\n",
            "         [ 3.7137,  3.6464,  3.0287,  ..., -0.7871, -0.7871, -0.7871]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 40, 20108])\n",
            "tensor([[[ 4.5709,  6.6187,  5.8189,  ..., -0.9805, -0.9805, -0.9805],\n",
            "         [ 3.8383,  6.9260,  6.3439,  ..., -0.9950, -0.9950, -0.9950],\n",
            "         [ 4.8672,  7.0600,  6.9604,  ..., -1.0933, -1.0933, -1.0933],\n",
            "         ...,\n",
            "         [ 4.4583,  7.1149,  6.3689,  ..., -0.9892, -0.9892, -0.9892],\n",
            "         [ 4.9582,  6.7216,  6.7779,  ..., -1.0202, -1.0202, -1.0202],\n",
            "         [ 5.2926,  6.1023,  6.9805,  ..., -0.9863, -0.9863, -0.9863]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 6.2024,  7.4244,  6.8952,  ..., -1.0574, -1.0574, -1.0574],\n",
            "         [ 7.0572,  7.4394,  7.4436,  ..., -1.0620, -1.0620, -1.0620],\n",
            "         [ 6.2566,  7.8558,  7.4277,  ..., -1.0185, -1.0185, -1.0185],\n",
            "         ...,\n",
            "         [ 5.3012,  5.9405,  5.8457,  ..., -0.9706, -0.9706, -0.9706],\n",
            "         [ 4.5761,  6.0988,  5.0505,  ..., -0.7665, -0.7665, -0.7665],\n",
            "         [ 3.6864,  5.4639,  4.9594,  ..., -0.7461, -0.7461, -0.7461]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 5.4728,  8.3850,  8.6134,  ..., -0.9897, -0.9897, -0.9897],\n",
            "         [ 5.6123,  8.0179,  8.6866,  ..., -0.9967, -0.9967, -0.9967],\n",
            "         [ 6.6963,  8.2149,  8.9723,  ..., -0.9377, -0.9377, -0.9377],\n",
            "         ...,\n",
            "         [ 2.0721,  4.7076,  4.5048,  ..., -0.7958, -0.7958, -0.7958],\n",
            "         [ 1.1671,  5.0310,  4.8926,  ..., -0.7364, -0.7364, -0.7364],\n",
            "         [ 1.0952,  4.8747,  4.9542,  ..., -0.7029, -0.7029, -0.7029]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 4.5437,  6.0606,  4.7995,  ..., -1.0915, -1.0915, -1.0915],\n",
            "         [ 2.3740,  8.7134,  5.8334,  ..., -0.8379, -0.8379, -0.8379],\n",
            "         [ 3.8587,  8.7801,  5.8574,  ..., -0.9475, -0.9475, -0.9475],\n",
            "         ...,\n",
            "         [ 4.7614,  9.2389,  6.9020,  ..., -0.8441, -0.8441, -0.8441],\n",
            "         [ 4.4734,  9.6831,  7.4443,  ..., -0.9039, -0.9039, -0.9039],\n",
            "         [ 4.5842,  8.7889,  7.3033,  ..., -0.9252, -0.9252, -0.9252]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 87, 20108])\n",
            "tensor([[[ 4.8430,  6.6088,  5.5437,  ..., -1.0795, -1.0795, -1.0795],\n",
            "         [ 4.6596,  6.6888,  5.6828,  ..., -1.0766, -1.0766, -1.0766],\n",
            "         [ 4.4674,  6.2827,  5.6246,  ..., -1.0014, -1.0014, -1.0014],\n",
            "         ...,\n",
            "         [ 5.7913,  5.4710,  5.4875,  ..., -0.9255, -0.9255, -0.9255],\n",
            "         [ 6.1702,  5.7953,  5.7354,  ..., -0.9390, -0.9390, -0.9390],\n",
            "         [ 5.3484,  5.1846,  5.5963,  ..., -0.9483, -0.9483, -0.9483]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.8700,  4.5768,  2.4532,  ..., -0.5631, -0.5631, -0.5631],\n",
            "         [ 3.4629,  4.2694,  2.5066,  ..., -0.4743, -0.4743, -0.4743],\n",
            "         [ 3.0293,  4.2998,  2.3790,  ..., -0.3850, -0.3850, -0.3850],\n",
            "         ...,\n",
            "         [ 4.6573,  3.9691,  2.8528,  ..., -0.4149, -0.4149, -0.4149],\n",
            "         [ 5.0798,  4.9265,  2.4601,  ..., -0.3304, -0.3304, -0.3304],\n",
            "         [ 5.7286,  4.0998,  2.1670,  ..., -0.2860, -0.2860, -0.2860]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 5.3064,  5.7074,  3.0949,  ..., -0.5396, -0.5396, -0.5396],\n",
            "         [ 5.0763,  5.7700,  3.7825,  ..., -0.5671, -0.5671, -0.5671],\n",
            "         [ 6.6900,  4.1506,  2.1344,  ..., -0.4362, -0.4362, -0.4362],\n",
            "         ...,\n",
            "         [ 6.2141,  5.6712,  3.3252,  ..., -0.3832, -0.3832, -0.3832],\n",
            "         [ 6.0900,  4.3964,  2.2759,  ..., -0.3687, -0.3687, -0.3687],\n",
            "         [ 6.8687,  4.1866,  2.9337,  ..., -0.4564, -0.4564, -0.4564]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 3.8240,  5.9165,  4.8818,  ..., -1.0916, -1.0916, -1.0916],\n",
            "         [ 5.1541,  6.5266,  6.0380,  ..., -1.0258, -1.0258, -1.0258],\n",
            "         [ 4.9770,  6.7696,  6.7322,  ..., -1.0354, -1.0354, -1.0354],\n",
            "         ...,\n",
            "         [ 3.5674,  8.3285,  5.4898,  ..., -0.8602, -0.8602, -0.8602],\n",
            "         [ 3.5149,  7.9992,  5.2473,  ..., -0.8094, -0.8094, -0.8094],\n",
            "         [ 2.5405,  8.0845,  4.6167,  ..., -0.8036, -0.8036, -0.8036]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 154, 20108])\n",
            "tensor([[[ 3.2566,  6.5758,  4.2356,  ..., -0.7536, -0.7536, -0.7536],\n",
            "         [ 2.7227,  7.4096,  4.6590,  ..., -0.6537, -0.6537, -0.6537],\n",
            "         [ 3.0824,  7.5821,  4.6679,  ..., -0.6816, -0.6816, -0.6816],\n",
            "         ...,\n",
            "         [ 4.9843,  4.9037,  4.8193,  ..., -0.8732, -0.8732, -0.8732],\n",
            "         [ 4.9804,  4.3107,  4.4240,  ..., -0.8498, -0.8498, -0.8498],\n",
            "         [ 4.4135,  4.6521,  4.6935,  ..., -0.8582, -0.8582, -0.8582]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 4.5807,  6.5657,  4.0146,  ..., -0.6286, -0.6286, -0.6286],\n",
            "         [ 4.1426,  5.1776,  2.7771,  ..., -0.4915, -0.4915, -0.4915],\n",
            "         [ 4.9573,  5.0216,  2.8526,  ..., -0.4106, -0.4106, -0.4106],\n",
            "         ...,\n",
            "         [ 6.5149,  6.0004,  3.1067,  ..., -0.3015, -0.3015, -0.3015],\n",
            "         [ 6.5222,  6.0696,  3.4496,  ..., -0.3078, -0.3078, -0.3078],\n",
            "         [ 6.1603,  5.7497,  3.6467,  ..., -0.3330, -0.3330, -0.3330]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 6.7368,  5.2713,  3.6198,  ..., -0.6053, -0.6053, -0.6053],\n",
            "         [ 6.1178,  4.5316,  2.4295,  ..., -0.5796, -0.5796, -0.5796],\n",
            "         [ 5.4799,  3.9373,  1.9014,  ..., -0.5156, -0.5156, -0.5156],\n",
            "         ...,\n",
            "         [ 4.4918,  3.3265,  1.0202,  ..., -0.5593, -0.5593, -0.5593],\n",
            "         [ 5.0202,  4.4696,  2.1494,  ..., -0.6366, -0.6366, -0.6366],\n",
            "         [ 4.9225,  3.8348,  1.5590,  ..., -0.5435, -0.5435, -0.5435]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 7.0164,  7.7974,  6.6344,  ..., -1.0375, -1.0375, -1.0375],\n",
            "         [ 6.8889,  8.0064,  7.2762,  ..., -1.0986, -1.0986, -1.0986],\n",
            "         [ 6.4986,  7.5351,  6.9823,  ..., -1.0135, -1.0135, -1.0135],\n",
            "         ...,\n",
            "         [ 5.9874,  6.9421,  5.5607,  ..., -0.7570, -0.7570, -0.7570],\n",
            "         [ 4.9974,  6.2799,  5.4138,  ..., -0.7182, -0.7182, -0.7182],\n",
            "         [ 6.1831,  6.5596,  5.0585,  ..., -0.7151, -0.7151, -0.7151]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 53, 20108])\n",
            "tensor([[[ 2.5276,  5.0968,  4.1613,  ..., -1.0088, -1.0088, -1.0088],\n",
            "         [ 1.8996,  5.5285,  3.7922,  ..., -1.0213, -1.0213, -1.0213],\n",
            "         [ 2.1342,  5.8894,  3.6904,  ..., -1.0299, -1.0299, -1.0299],\n",
            "         ...,\n",
            "         [ 3.1651,  7.2316,  5.9860,  ..., -0.8776, -0.8776, -0.8776],\n",
            "         [ 3.2130,  6.9562,  5.7540,  ..., -0.8493, -0.8493, -0.8493],\n",
            "         [ 4.0989,  7.5332,  5.8529,  ..., -0.8909, -0.8909, -0.8909]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 37, 20108])\n",
            "tensor([[[ 5.2371,  7.7528,  6.8605,  ..., -1.0183, -1.0183, -1.0183],\n",
            "         [ 5.5328,  7.3304,  6.1406,  ..., -0.9344, -0.9344, -0.9344],\n",
            "         [ 5.0710,  6.6461,  5.2474,  ..., -0.9799, -0.9799, -0.9799],\n",
            "         ...,\n",
            "         [ 5.9602,  7.1264,  7.1837,  ..., -1.0410, -1.0410, -1.0410],\n",
            "         [ 5.9075,  6.7089,  6.7186,  ..., -1.0763, -1.0763, -1.0763],\n",
            "         [ 5.9403,  6.9901,  7.0687,  ..., -1.0955, -1.0955, -1.0955]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 2.7468,  5.4345,  4.1743,  ..., -1.0024, -1.0024, -1.0024],\n",
            "         [ 3.7330,  5.1361,  4.3105,  ..., -0.9312, -0.9312, -0.9312],\n",
            "         [ 4.7740,  6.4552,  6.5934,  ..., -1.0761, -1.0761, -1.0761],\n",
            "         ...,\n",
            "         [ 6.1520,  8.2474,  8.0823,  ..., -0.9847, -0.9847, -0.9847],\n",
            "         [ 5.1503,  7.3457,  7.1002,  ..., -1.0505, -1.0505, -1.0505],\n",
            "         [ 5.1456,  6.9705,  6.4590,  ..., -1.0905, -1.0905, -1.0905]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 125, 20108])\n",
            "tensor([[[ 4.2312,  6.2758,  5.6163,  ..., -1.0722, -1.0722, -1.0722],\n",
            "         [ 3.6370,  6.6477,  5.8678,  ..., -1.0689, -1.0689, -1.0689],\n",
            "         [ 2.7866,  6.1834,  5.2184,  ..., -0.9252, -0.9252, -0.9252],\n",
            "         ...,\n",
            "         [ 6.5035,  6.9112,  6.3468,  ..., -0.8501, -0.8501, -0.8501],\n",
            "         [ 6.6218,  8.1658,  7.4395,  ..., -0.9051, -0.9051, -0.9051],\n",
            "         [ 6.2694,  7.2184,  6.6705,  ..., -0.8667, -0.8667, -0.8667]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 94, 20108])\n",
            "tensor([[[ 2.9680,  6.1309,  4.9354,  ..., -1.0989, -1.0989, -1.0989],\n",
            "         [ 5.3174,  7.3289,  6.5970,  ..., -1.1780, -1.1780, -1.1780],\n",
            "         [ 5.5360,  7.6365,  6.8472,  ..., -1.1364, -1.1364, -1.1364],\n",
            "         ...,\n",
            "         [ 8.8775,  5.7195,  4.8867,  ..., -0.9357, -0.9357, -0.9357],\n",
            "         [ 8.7450,  6.1092,  5.2878,  ..., -0.9246, -0.9246, -0.9246],\n",
            "         [ 7.8501,  6.0580,  5.6450,  ..., -1.0988, -1.0988, -1.0988]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 33, 20108])\n",
            "tensor([[[ 4.2549,  5.2578,  3.7895,  ..., -1.0115, -1.0115, -1.0115],\n",
            "         [ 3.4997,  5.5367,  3.9818,  ..., -1.0487, -1.0487, -1.0487],\n",
            "         [ 3.9567,  5.4273,  4.2132,  ..., -1.0660, -1.0660, -1.0660],\n",
            "         ...,\n",
            "         [ 4.9798,  7.9491,  6.4633,  ..., -0.7278, -0.7278, -0.7278],\n",
            "         [ 4.8783,  8.0981,  6.9994,  ..., -0.7572, -0.7572, -0.7572],\n",
            "         [ 4.5614,  7.2463,  6.0505,  ..., -0.7178, -0.7178, -0.7178]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 6.4050,  7.1984,  8.1023,  ..., -1.0613, -1.0613, -1.0613],\n",
            "         [ 6.0742,  7.9143,  8.4045,  ..., -1.0646, -1.0646, -1.0646],\n",
            "         [ 6.1041,  8.3399,  9.0657,  ..., -1.0402, -1.0402, -1.0402],\n",
            "         ...,\n",
            "         [ 6.2928,  8.0174,  7.7204,  ..., -0.9924, -0.9924, -0.9924],\n",
            "         [ 5.3757,  7.9247,  7.5201,  ..., -0.9667, -0.9667, -0.9667],\n",
            "         [ 5.4848,  8.3014,  7.6401,  ..., -0.9911, -0.9911, -0.9911]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 3.9898,  4.3051,  2.4270,  ..., -0.5136, -0.5136, -0.5136],\n",
            "         [ 3.8459,  4.6606,  2.7892,  ..., -0.4834, -0.4834, -0.4834],\n",
            "         [ 3.4899,  4.4887,  2.2945,  ..., -0.4037, -0.4037, -0.4037],\n",
            "         ...,\n",
            "         [ 6.8386,  2.0029,  0.6688,  ..., -0.4421, -0.4421, -0.4421],\n",
            "         [ 6.8618,  2.0090,  0.5792,  ..., -0.4298, -0.4298, -0.4298],\n",
            "         [ 6.3816,  2.4543,  0.7808,  ..., -0.4501, -0.4501, -0.4501]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 58, 20108])\n",
            "tensor([[[ 5.0492,  6.9659,  6.1544,  ..., -1.1726, -1.1726, -1.1726],\n",
            "         [ 5.1122,  7.6546,  7.1883,  ..., -1.1280, -1.1280, -1.1280],\n",
            "         [ 5.4202,  7.3788,  6.7448,  ..., -1.0916, -1.0916, -1.0916],\n",
            "         ...,\n",
            "         [ 3.6415,  3.7164,  4.9003,  ..., -0.9294, -0.9294, -0.9294],\n",
            "         [ 4.6792,  5.4426,  6.7188,  ..., -1.0254, -1.0254, -1.0254],\n",
            "         [ 4.5448,  4.8479,  6.1183,  ..., -0.9723, -0.9723, -0.9723]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 4.6502,  7.4778,  6.6049,  ..., -1.1537, -1.1537, -1.1537],\n",
            "         [ 4.6816,  6.3035,  5.6684,  ..., -1.0263, -1.0263, -1.0263],\n",
            "         [ 3.9320,  5.7878,  4.3082,  ..., -0.9317, -0.9317, -0.9317],\n",
            "         ...,\n",
            "         [ 7.2879,  5.2327,  3.6572,  ..., -0.7469, -0.7469, -0.7469],\n",
            "         [ 6.9461,  3.9212,  3.0775,  ..., -0.7152, -0.7152, -0.7152],\n",
            "         [ 6.4565,  3.9247,  2.8988,  ..., -0.7299, -0.7299, -0.7299]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 96, 20108])\n",
            "tensor([[[ 2.0939,  4.9067,  3.2308,  ..., -0.9933, -0.9933, -0.9933],\n",
            "         [ 2.4258,  4.3841,  2.8362,  ..., -0.9705, -0.9705, -0.9705],\n",
            "         [ 2.2493,  5.7303,  3.8532,  ..., -0.9965, -0.9965, -0.9965],\n",
            "         ...,\n",
            "         [ 5.9046,  5.8776,  5.1860,  ..., -0.9326, -0.9326, -0.9326],\n",
            "         [ 6.2437,  6.2705,  5.5098,  ..., -0.9392, -0.9392, -0.9392],\n",
            "         [ 6.1575,  6.2380,  5.3094,  ..., -0.9502, -0.9502, -0.9502]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 26, 20108])\n",
            "tensor([[[ 3.1854,  4.6958,  2.6605,  ..., -0.5589, -0.5589, -0.5589],\n",
            "         [ 3.9791,  4.3525,  3.5560,  ..., -0.5745, -0.5745, -0.5745],\n",
            "         [ 4.4454,  3.3966,  2.4837,  ..., -0.5225, -0.5225, -0.5225],\n",
            "         ...,\n",
            "         [ 6.4637,  2.2400,  1.0061,  ..., -0.3814, -0.3814, -0.3814],\n",
            "         [ 6.4502,  1.6322,  0.5681,  ..., -0.3560, -0.3560, -0.3560],\n",
            "         [ 6.7156,  1.6843,  0.6132,  ..., -0.3483, -0.3483, -0.3483]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 7.4377,  8.0548,  7.7679,  ..., -1.1236, -1.1236, -1.1236],\n",
            "         [ 7.0224,  8.6601,  7.6782,  ..., -1.0395, -1.0395, -1.0395],\n",
            "         [ 7.2761,  8.7279,  8.6008,  ..., -1.0908, -1.0908, -1.0908],\n",
            "         [ 7.0944,  9.1537,  8.5328,  ..., -1.1274, -1.1274, -1.1274]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 103, 20108])\n",
            "tensor([[[ 7.4197,  8.2290,  6.8663,  ..., -1.0686, -1.0686, -1.0686],\n",
            "         [ 6.0197,  7.9749,  6.2116,  ..., -1.0503, -1.0503, -1.0503],\n",
            "         [ 3.6067,  7.1283,  5.6661,  ..., -0.8697, -0.8697, -0.8697],\n",
            "         ...,\n",
            "         [ 3.6002,  5.0800,  4.7720,  ..., -0.8059, -0.8059, -0.8059],\n",
            "         [ 3.5250,  4.9105,  4.8747,  ..., -0.8129, -0.8129, -0.8129],\n",
            "         [ 3.9247,  5.4490,  4.9073,  ..., -0.8226, -0.8226, -0.8226]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 5.9456,  5.6011,  4.2403,  ..., -0.8643, -0.8643, -0.8643],\n",
            "         [ 5.7706,  4.3047,  2.6400,  ..., -0.5679, -0.5679, -0.5679],\n",
            "         [ 4.0235,  4.4024,  1.8340,  ..., -0.6560, -0.6560, -0.6560]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 102, 20108])\n",
            "tensor([[[ 5.4494,  7.4531,  6.9166,  ..., -1.0645, -1.0645, -1.0645],\n",
            "         [ 5.8967,  8.3001,  8.3444,  ..., -0.9859, -0.9859, -0.9859],\n",
            "         [ 5.3833,  7.6972,  7.6664,  ..., -1.0307, -1.0307, -1.0307],\n",
            "         ...,\n",
            "         [ 3.5594,  4.8357,  5.1079,  ..., -0.9911, -0.9911, -0.9911],\n",
            "         [ 2.8151,  4.5657,  4.5112,  ..., -0.9920, -0.9920, -0.9920],\n",
            "         [ 3.7923,  4.9570,  4.8043,  ..., -1.0009, -1.0009, -1.0009]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 4.2622,  5.3348,  3.6240,  ..., -0.4984, -0.4984, -0.4984],\n",
            "         [ 4.5122,  5.1909,  3.1735,  ..., -0.3889, -0.3889, -0.3889],\n",
            "         [ 5.3318,  5.3849,  3.0355,  ..., -0.3638, -0.3638, -0.3638],\n",
            "         ...,\n",
            "         [ 4.4536,  2.7943,  0.7290,  ..., -0.3871, -0.3871, -0.3871],\n",
            "         [ 5.7121,  3.0686,  0.7672,  ..., -0.3751, -0.3751, -0.3751],\n",
            "         [ 5.7416,  3.1205,  1.1277,  ..., -0.4383, -0.4383, -0.4383]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.0218,  6.3688,  5.0134,  ..., -1.0950, -1.0950, -1.0950],\n",
            "         [ 3.1267,  5.8985,  4.6187,  ..., -1.0745, -1.0745, -1.0745],\n",
            "         [ 2.6607,  5.7260,  4.1637,  ..., -1.0448, -1.0448, -1.0448],\n",
            "         ...,\n",
            "         [ 3.7754,  9.0035,  6.1737,  ..., -0.6849, -0.6849, -0.6849],\n",
            "         [ 3.8361,  9.3622,  6.1288,  ..., -0.6564, -0.6564, -0.6564],\n",
            "         [ 3.6212,  9.3513,  6.9108,  ..., -0.7403, -0.7403, -0.7403]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 72, 20108])\n",
            "tensor([[[ 5.1641,  6.5140,  5.9006,  ..., -1.1599, -1.1599, -1.1599],\n",
            "         [ 3.8042,  5.8199,  5.3488,  ..., -1.1203, -1.1203, -1.1203],\n",
            "         [ 5.5043,  6.7539,  6.2125,  ..., -1.0541, -1.0541, -1.0541],\n",
            "         ...,\n",
            "         [ 5.7005,  5.3571,  6.2208,  ..., -0.8585, -0.8585, -0.8585],\n",
            "         [ 5.3535,  4.6450,  5.9557,  ..., -0.8218, -0.8218, -0.8218],\n",
            "         [ 5.5158,  4.9979,  5.9228,  ..., -0.8047, -0.8047, -0.8047]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 2.0465,  5.1368,  4.4029,  ..., -1.0699, -1.0699, -1.0699],\n",
            "         [ 1.8091,  4.9390,  3.3970,  ..., -1.0075, -1.0075, -1.0075],\n",
            "         [ 1.4246,  4.3385,  3.4397,  ..., -0.9814, -0.9814, -0.9814],\n",
            "         ...,\n",
            "         [ 3.2064,  9.1894,  6.2409,  ..., -0.9327, -0.9327, -0.9327],\n",
            "         [ 3.4849,  7.7646,  6.0251,  ..., -0.9870, -0.9870, -0.9870],\n",
            "         [ 3.5854,  7.6237,  6.1156,  ..., -1.0598, -1.0598, -1.0598]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.2053,  7.8205,  5.7292,  ..., -0.9100, -0.9100, -0.9100],\n",
            "         [ 0.7867,  7.7923,  5.0241,  ..., -0.6762, -0.6762, -0.6762],\n",
            "         [ 0.2007,  7.2245,  4.9586,  ..., -0.5694, -0.5694, -0.5694],\n",
            "         ...,\n",
            "         [ 3.8600,  8.0108,  6.5540,  ..., -0.7780, -0.7780, -0.7780],\n",
            "         [ 3.4358,  7.8396,  6.5783,  ..., -0.7567, -0.7567, -0.7567],\n",
            "         [ 2.7640,  7.0125,  6.0042,  ..., -0.6546, -0.6546, -0.6546]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 46, 20108])\n",
            "tensor([[[ 4.7017,  5.9547,  5.4514,  ..., -1.0985, -1.0985, -1.0985],\n",
            "         [ 2.9537,  5.2716,  4.3284,  ..., -1.0318, -1.0318, -1.0318],\n",
            "         [ 3.1787,  4.8776,  4.2686,  ..., -1.0313, -1.0313, -1.0313],\n",
            "         ...,\n",
            "         [ 5.0969,  6.2692,  5.4437,  ..., -0.7753, -0.7753, -0.7753],\n",
            "         [ 5.1526,  5.9491,  5.5063,  ..., -0.7837, -0.7837, -0.7837],\n",
            "         [ 4.7658,  5.8298,  5.6622,  ..., -0.7304, -0.7304, -0.7304]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 5.3765,  7.9558,  7.4581,  ..., -1.0341, -1.0341, -1.0341],\n",
            "         [ 4.7941,  7.5842,  7.5920,  ..., -1.0669, -1.0669, -1.0669],\n",
            "         [ 4.5817,  7.5898,  6.8818,  ..., -1.1585, -1.1585, -1.1585],\n",
            "         ...,\n",
            "         [ 8.5231,  8.8901,  9.4982,  ..., -0.9339, -0.9339, -0.9339],\n",
            "         [ 8.3701,  9.3268,  9.4307,  ..., -0.9038, -0.9038, -0.9038],\n",
            "         [ 8.4192,  8.4527,  9.1134,  ..., -0.9212, -0.9212, -0.9212]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 6.9924,  7.2836,  6.6396,  ..., -0.9721, -0.9721, -0.9721],\n",
            "         [ 6.6088,  8.7092,  8.0254,  ..., -0.9999, -0.9999, -0.9999],\n",
            "         [ 7.3704,  8.7330,  8.5626,  ..., -0.9987, -0.9987, -0.9987],\n",
            "         ...,\n",
            "         [ 4.3236,  6.5255,  5.8856,  ..., -0.9171, -0.9171, -0.9171],\n",
            "         [ 3.9056,  6.9749,  6.4731,  ..., -0.8742, -0.8742, -0.8742],\n",
            "         [ 4.0533,  6.0445,  5.8716,  ..., -0.8527, -0.8527, -0.8527]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 8.3339,  8.7605,  8.4055,  ..., -1.0047, -1.0047, -1.0047],\n",
            "         [ 7.5608,  8.2981,  8.1508,  ..., -0.9515, -0.9515, -0.9515],\n",
            "         [ 7.7663,  8.3351,  8.0510,  ..., -0.9953, -0.9953, -0.9953]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 5.3319,  5.5330,  5.2994,  ..., -1.0528, -1.0528, -1.0528],\n",
            "         [ 6.1670,  6.9334,  5.8507,  ..., -1.0477, -1.0477, -1.0477],\n",
            "         [ 5.0855,  6.5447,  5.4898,  ..., -1.0235, -1.0235, -1.0235],\n",
            "         ...,\n",
            "         [ 5.3024,  7.6312,  6.1467,  ..., -0.9304, -0.9304, -0.9304],\n",
            "         [ 6.1975,  6.8125,  5.9369,  ..., -1.0484, -1.0484, -1.0484],\n",
            "         [ 6.7811,  6.9689,  6.9115,  ..., -1.0973, -1.0973, -1.0973]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 5.6923,  6.5344,  6.4222,  ..., -1.1215, -1.1215, -1.1215],\n",
            "         [ 5.5745,  7.1777,  6.6398,  ..., -1.1090, -1.1090, -1.1090],\n",
            "         [ 4.2631,  6.5165,  6.3733,  ..., -1.0229, -1.0229, -1.0229]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 343, 20108])\n",
            "tensor([[[ 5.4748,  7.1923,  6.2433,  ..., -1.1954, -1.1954, -1.1954],\n",
            "         [ 6.2520,  6.9691,  6.9870,  ..., -1.0712, -1.0712, -1.0712],\n",
            "         [ 4.7069,  6.4939,  7.2930,  ..., -1.0447, -1.0447, -1.0447],\n",
            "         ...,\n",
            "         [ 2.4541,  4.4245,  5.6761,  ..., -0.7558, -0.7558, -0.7558],\n",
            "         [ 1.9519,  3.2165,  4.9054,  ..., -0.7300, -0.7300, -0.7300],\n",
            "         [ 1.8283,  3.7291,  4.8257,  ..., -0.7256, -0.7256, -0.7256]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 8.1044, 10.0704,  8.6593,  ..., -0.8896, -0.8896, -0.8896],\n",
            "         [ 4.6768,  7.9704,  6.4724,  ..., -0.9775, -0.9775, -0.9775],\n",
            "         [ 6.6533,  7.2236,  6.6162,  ..., -1.0125, -1.0125, -1.0125],\n",
            "         ...,\n",
            "         [ 5.5777,  6.5938,  4.6271,  ..., -0.8098, -0.8098, -0.8098],\n",
            "         [ 5.2712,  6.3458,  4.3904,  ..., -0.7843, -0.7843, -0.7843],\n",
            "         [ 5.0825,  6.6077,  4.5623,  ..., -0.8155, -0.8155, -0.8155]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 2.8183,  5.5427,  4.0132,  ..., -1.0797, -1.0797, -1.0797],\n",
            "         [ 4.9671,  7.2064,  6.2581,  ..., -1.1426, -1.1426, -1.1426],\n",
            "         [ 5.2000,  7.2622,  7.0233,  ..., -1.0555, -1.0555, -1.0555],\n",
            "         ...,\n",
            "         [ 8.0172,  5.7220,  5.4804,  ..., -0.8786, -0.8786, -0.8786],\n",
            "         [ 7.9861,  5.3931,  5.4017,  ..., -0.8557, -0.8557, -0.8557],\n",
            "         [ 8.2979,  5.3162,  5.2598,  ..., -0.8458, -0.8458, -0.8458]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 132, 20108])\n",
            "tensor([[[ 1.3750,  6.0989,  4.5247,  ..., -0.7965, -0.7965, -0.7965],\n",
            "         [ 0.5076,  5.2503,  3.7339,  ..., -0.6618, -0.6618, -0.6618],\n",
            "         [ 0.7627,  5.9292,  4.1522,  ..., -0.7639, -0.7639, -0.7639],\n",
            "         ...,\n",
            "         [ 2.4007,  5.0008,  3.4887,  ..., -0.5573, -0.5573, -0.5573],\n",
            "         [ 2.9228,  5.0863,  3.4523,  ..., -0.5039, -0.5039, -0.5039],\n",
            "         [ 2.5940,  5.2468,  3.5832,  ..., -0.5102, -0.5102, -0.5102]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 190, 20108])\n",
            "tensor([[[ 4.2112,  7.3692,  6.0812,  ..., -1.1442, -1.1442, -1.1442],\n",
            "         [ 5.6880,  7.7226,  6.5070,  ..., -1.1499, -1.1499, -1.1499],\n",
            "         [ 5.9526,  8.4411,  7.5886,  ..., -1.1393, -1.1393, -1.1393],\n",
            "         ...,\n",
            "         [ 5.2746,  2.8924,  3.0866,  ..., -0.8754, -0.8754, -0.8754],\n",
            "         [ 4.7696,  2.2571,  2.9740,  ..., -0.8741, -0.8741, -0.8741],\n",
            "         [ 4.2733,  2.2183,  2.8913,  ..., -0.8369, -0.8369, -0.8369]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 3.8409,  5.2965,  2.6837,  ..., -0.5283, -0.5283, -0.5283],\n",
            "         [ 3.2380,  4.7098,  2.8780,  ..., -0.4183, -0.4183, -0.4183],\n",
            "         [ 3.2151,  4.5174,  2.6010,  ..., -0.4744, -0.4744, -0.4744],\n",
            "         ...,\n",
            "         [ 7.1998,  1.8152,  0.5154,  ..., -0.3339, -0.3339, -0.3339],\n",
            "         [ 7.2169,  1.3717,  0.3383,  ..., -0.3172, -0.3172, -0.3172],\n",
            "         [ 6.9374,  1.0768,  0.2506,  ..., -0.3383, -0.3383, -0.3383]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 70, 20108])\n",
            "tensor([[[ 3.0243,  5.4897,  4.0771,  ..., -1.0199, -1.0199, -1.0199],\n",
            "         [ 2.8731,  6.2603,  4.2113,  ..., -0.9255, -0.9255, -0.9255],\n",
            "         [ 2.7402,  5.5179,  2.9938,  ..., -0.7923, -0.7923, -0.7923],\n",
            "         ...,\n",
            "         [ 5.6018,  6.9610,  6.2335,  ..., -0.9949, -0.9949, -0.9949],\n",
            "         [ 6.4544,  7.0100,  6.4069,  ..., -1.0333, -1.0333, -1.0333],\n",
            "         [ 6.0137,  7.1338,  6.4198,  ..., -1.0682, -1.0682, -1.0682]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 105, 20108])\n",
            "tensor([[[ 5.6301,  7.9333,  5.6379,  ..., -0.9480, -0.9480, -0.9480],\n",
            "         [ 5.5062,  7.7250,  6.0514,  ..., -1.0140, -1.0140, -1.0140],\n",
            "         [ 4.4432,  7.6945,  5.9710,  ..., -0.9694, -0.9694, -0.9694],\n",
            "         ...,\n",
            "         [ 5.4754,  3.0679,  2.9203,  ..., -0.8578, -0.8578, -0.8578],\n",
            "         [ 5.0661,  3.1622,  2.8029,  ..., -0.8964, -0.8964, -0.8964],\n",
            "         [ 5.3304,  3.7299,  3.1968,  ..., -0.8857, -0.8857, -0.8857]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 2.4098,  5.4588,  3.8005,  ..., -1.0239, -1.0239, -1.0239],\n",
            "         [ 2.5535,  5.4502,  4.0094,  ..., -1.0589, -1.0589, -1.0589],\n",
            "         [ 1.9848,  4.9553,  3.5348,  ..., -0.9698, -0.9698, -0.9698],\n",
            "         [ 2.1794,  5.1236,  3.1029,  ..., -1.0314, -1.0314, -1.0314]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 68, 20108])\n",
            "tensor([[[ 3.2564,  6.3113,  4.6279,  ..., -1.0576, -1.0576, -1.0576],\n",
            "         [ 2.5994,  5.6450,  4.2825,  ..., -1.0226, -1.0226, -1.0226],\n",
            "         [ 2.6517,  6.5497,  5.2795,  ..., -1.1118, -1.1118, -1.1118],\n",
            "         ...,\n",
            "         [ 5.3979,  6.2304,  6.6292,  ..., -0.7912, -0.7912, -0.7912],\n",
            "         [ 5.6900,  6.3354,  6.1563,  ..., -0.8064, -0.8064, -0.8064],\n",
            "         [ 5.4828,  6.3008,  6.2910,  ..., -0.8022, -0.8022, -0.8022]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 2.8823,  4.7378,  2.8940,  ..., -0.6063, -0.6063, -0.6063],\n",
            "         [ 4.5614,  4.8678,  2.4397,  ..., -0.4302, -0.4302, -0.4302],\n",
            "         [ 5.6685,  5.2939,  2.8693,  ..., -0.4109, -0.4109, -0.4109],\n",
            "         ...,\n",
            "         [ 6.5346,  2.5871,  1.2677,  ..., -0.3811, -0.3811, -0.3811],\n",
            "         [ 6.0691,  2.7265,  1.9397,  ..., -0.3895, -0.3895, -0.3895],\n",
            "         [ 6.0161,  2.3706,  1.4049,  ..., -0.4000, -0.4000, -0.4000]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 113, 20108])\n",
            "tensor([[[ 1.9586,  5.0029,  3.6722,  ..., -0.9341, -0.9341, -0.9341],\n",
            "         [ 1.4510,  5.3597,  4.9969,  ..., -0.9325, -0.9325, -0.9325],\n",
            "         [ 1.2090,  5.8398,  4.1160,  ..., -0.8635, -0.8635, -0.8635],\n",
            "         ...,\n",
            "         [ 4.0516,  5.3897,  4.1584,  ..., -0.7304, -0.7304, -0.7304],\n",
            "         [ 4.2388,  5.0761,  4.0538,  ..., -0.7516, -0.7516, -0.7516],\n",
            "         [ 3.1618,  4.4673,  3.2821,  ..., -0.6666, -0.6666, -0.6666]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 5.7643,  5.9041,  3.8388,  ..., -0.4302, -0.4302, -0.4302],\n",
            "         [ 6.0232,  5.0500,  2.9597,  ..., -0.4299, -0.4299, -0.4299],\n",
            "         [ 5.6788,  3.7284,  1.7355,  ..., -0.3891, -0.3891, -0.3891],\n",
            "         ...,\n",
            "         [ 5.2166,  2.7318,  0.5403,  ..., -0.4078, -0.4078, -0.4078],\n",
            "         [ 5.7181,  2.9599,  1.4001,  ..., -0.4833, -0.4833, -0.4833],\n",
            "         [ 6.0692,  3.4684,  1.2779,  ..., -0.5505, -0.5505, -0.5505]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 3.3684,  6.2045,  5.0150,  ..., -1.1409, -1.1409, -1.1409],\n",
            "         [ 1.7484,  5.6807,  3.5429,  ..., -1.0047, -1.0047, -1.0047],\n",
            "         [ 3.9059,  7.3912,  5.4720,  ..., -1.1690, -1.1690, -1.1690],\n",
            "         ...,\n",
            "         [ 7.6319,  6.1668,  5.5348,  ..., -0.8695, -0.8695, -0.8695],\n",
            "         [ 6.9780,  5.7527,  4.8890,  ..., -0.8464, -0.8464, -0.8464],\n",
            "         [ 6.7371,  6.4359,  5.5552,  ..., -0.9288, -0.9288, -0.9288]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 3.9097,  4.3599,  2.7505,  ..., -0.6133, -0.6133, -0.6133],\n",
            "         [ 3.0902,  4.4575,  2.6914,  ..., -0.4947, -0.4947, -0.4947],\n",
            "         [ 3.0799,  4.8046,  2.6405,  ..., -0.5058, -0.5058, -0.5058],\n",
            "         ...,\n",
            "         [ 5.3807,  4.5033,  2.0542,  ..., -0.3545, -0.3545, -0.3545],\n",
            "         [ 6.0193,  4.8612,  2.6875,  ..., -0.3716, -0.3716, -0.3716],\n",
            "         [ 5.6832,  4.6764,  2.8648,  ..., -0.3859, -0.3859, -0.3859]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 45, 20108])\n",
            "tensor([[[ 4.6828,  7.4530,  6.6451,  ..., -1.1096, -1.1096, -1.1096],\n",
            "         [ 4.1035,  7.2199,  6.3908,  ..., -1.0822, -1.0822, -1.0822],\n",
            "         [ 4.3335,  7.9122,  6.4256,  ..., -1.1278, -1.1278, -1.1278],\n",
            "         ...,\n",
            "         [ 4.0097,  5.8637,  5.6526,  ..., -0.8903, -0.8903, -0.8903],\n",
            "         [ 4.3577,  7.1931,  6.7054,  ..., -0.9036, -0.9036, -0.9036],\n",
            "         [ 4.6803,  6.7182,  6.9142,  ..., -0.9398, -0.9398, -0.9398]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 55, 20108])\n",
            "tensor([[[ 3.7096,  5.8443,  4.7302,  ..., -1.1304, -1.1304, -1.1304],\n",
            "         [ 2.6500,  5.1176,  4.0353,  ..., -1.0355, -1.0355, -1.0355],\n",
            "         [ 2.4537,  5.0616,  3.9760,  ..., -1.0616, -1.0616, -1.0616],\n",
            "         ...,\n",
            "         [ 5.3979,  6.9722,  6.1733,  ..., -0.8654, -0.8654, -0.8654],\n",
            "         [ 5.3622,  6.6813,  5.9264,  ..., -0.8698, -0.8698, -0.8698],\n",
            "         [ 5.4192,  5.9715,  5.2929,  ..., -0.8553, -0.8553, -0.8553]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 2.5243,  6.3220,  4.0961,  ..., -0.8789, -0.8789, -0.8789],\n",
            "         [ 3.0998,  7.7283,  5.7052,  ..., -0.7997, -0.7997, -0.7997],\n",
            "         [ 1.7419,  7.2295,  6.0085,  ..., -0.8291, -0.8291, -0.8291],\n",
            "         ...,\n",
            "         [ 4.6081,  9.0029,  7.7714,  ..., -0.9248, -0.9248, -0.9248],\n",
            "         [ 4.0150,  9.5160,  7.8918,  ..., -0.8907, -0.8907, -0.8907],\n",
            "         [ 4.1744, 10.0347,  7.5221,  ..., -0.8693, -0.8693, -0.8693]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 86, 20108])\n",
            "tensor([[[ 3.3843,  5.3538,  4.4147,  ..., -1.0199, -1.0199, -1.0199],\n",
            "         [ 4.2626,  7.0552,  5.4646,  ..., -0.9567, -0.9567, -0.9567],\n",
            "         [ 5.4047,  6.7896,  5.7361,  ..., -1.0065, -1.0065, -1.0065],\n",
            "         ...,\n",
            "         [ 6.9136,  4.7281,  3.3437,  ..., -0.7923, -0.7923, -0.7923],\n",
            "         [ 6.1811,  4.4930,  3.1106,  ..., -0.7967, -0.7967, -0.7967],\n",
            "         [ 6.3297,  4.3058,  2.8183,  ..., -0.7960, -0.7960, -0.7960]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.5692,  4.5244,  2.5750,  ..., -0.4969, -0.4969, -0.4969],\n",
            "         [ 4.0563,  4.8545,  2.6999,  ..., -0.5371, -0.5371, -0.5371],\n",
            "         [ 4.1180,  5.0381,  2.6931,  ..., -0.4607, -0.4607, -0.4607],\n",
            "         ...,\n",
            "         [ 5.9320,  4.8167,  2.6326,  ..., -0.4124, -0.4124, -0.4124],\n",
            "         [ 6.0853,  5.5216,  3.0964,  ..., -0.3929, -0.3929, -0.3929],\n",
            "         [ 6.3815,  4.3528,  2.7675,  ..., -0.4015, -0.4015, -0.4015]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 5.0253,  6.7659,  5.6314,  ..., -1.0079, -1.0079, -1.0079],\n",
            "         [ 5.4464,  6.7886,  6.8492,  ..., -1.0574, -1.0574, -1.0574],\n",
            "         [ 5.3886,  6.5997,  6.6335,  ..., -0.8948, -0.8948, -0.8948],\n",
            "         ...,\n",
            "         [ 4.1725,  7.7455,  7.5836,  ..., -0.8788, -0.8788, -0.8788],\n",
            "         [ 3.2292,  6.5441,  7.1469,  ..., -0.8583, -0.8583, -0.8583],\n",
            "         [ 2.7600,  6.0800,  6.2160,  ..., -0.8819, -0.8819, -0.8819]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 4.7221,  6.1876,  3.4477,  ..., -0.6125, -0.6125, -0.6125],\n",
            "         [ 4.1254,  5.3245,  3.1755,  ..., -0.5500, -0.5500, -0.5500],\n",
            "         [ 3.8457,  4.7528,  2.6958,  ..., -0.4338, -0.4338, -0.4338],\n",
            "         ...,\n",
            "         [ 6.2648,  5.2049,  3.2393,  ..., -0.3866, -0.3866, -0.3866],\n",
            "         [ 5.9562,  4.7256,  2.8874,  ..., -0.3523, -0.3523, -0.3523],\n",
            "         [ 6.4165,  4.2723,  2.2657,  ..., -0.3319, -0.3319, -0.3319]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.9605,  5.2158,  2.7445,  ..., -0.5692, -0.5692, -0.5692],\n",
            "         [ 3.1929,  4.4725,  1.9019,  ..., -0.4329, -0.4329, -0.4329],\n",
            "         [ 3.6802,  4.6714,  2.7728,  ..., -0.4657, -0.4657, -0.4657],\n",
            "         ...,\n",
            "         [ 5.5068,  4.3749,  1.5657,  ..., -0.2330, -0.2330, -0.2330],\n",
            "         [ 5.7761,  4.1382,  1.8577,  ..., -0.2488, -0.2488, -0.2488],\n",
            "         [ 5.7075,  3.3400,  1.7964,  ..., -0.3254, -0.3254, -0.3254]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 65, 20108])\n",
            "tensor([[[ 5.3010,  7.0541,  6.7462,  ..., -1.1411, -1.1411, -1.1411],\n",
            "         [ 5.9489,  7.1404,  7.2561,  ..., -1.0983, -1.0983, -1.0983],\n",
            "         [ 5.9367,  6.9161,  6.9465,  ..., -1.0317, -1.0317, -1.0317],\n",
            "         ...,\n",
            "         [ 7.5106,  5.6232,  6.0548,  ..., -1.0752, -1.0752, -1.0752],\n",
            "         [ 7.2215,  5.1449,  5.3241,  ..., -1.0796, -1.0796, -1.0796],\n",
            "         [ 7.9257,  5.2334,  5.2533,  ..., -1.0421, -1.0421, -1.0421]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 2.4392,  5.0817,  3.5558,  ..., -0.9231, -0.9231, -0.9231],\n",
            "         [ 1.8144,  5.4855,  4.1462,  ..., -0.9521, -0.9521, -0.9521],\n",
            "         [ 3.0353,  5.9125,  3.8914,  ..., -1.0135, -1.0135, -1.0135],\n",
            "         ...,\n",
            "         [ 4.8782,  7.1789,  6.8007,  ..., -0.8607, -0.8607, -0.8607],\n",
            "         [ 5.4541,  8.2250,  7.2148,  ..., -0.8914, -0.8914, -0.8914],\n",
            "         [ 4.0379,  8.4485,  7.4701,  ..., -0.8782, -0.8782, -0.8782]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 1.6820,  5.2928,  3.0436,  ..., -0.8876, -0.8876, -0.8876],\n",
            "         [ 2.4162,  6.7164,  4.5995,  ..., -0.8507, -0.8507, -0.8507],\n",
            "         [ 2.5574,  6.8120,  4.9108,  ..., -0.7950, -0.7950, -0.7950],\n",
            "         ...,\n",
            "         [ 3.7690,  8.5807,  5.6598,  ..., -0.7831, -0.7831, -0.7831],\n",
            "         [ 3.9247,  7.8264,  5.4260,  ..., -0.7733, -0.7733, -0.7733],\n",
            "         [ 3.6697,  7.6609,  5.3937,  ..., -0.7696, -0.7696, -0.7696]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 63, 20108])\n",
            "tensor([[[ 6.8851,  7.7715,  6.7010,  ..., -1.0982, -1.0982, -1.0982],\n",
            "         [ 7.8682,  9.0608,  8.9238,  ..., -1.0671, -1.0671, -1.0671],\n",
            "         [ 6.7812,  7.4604,  7.7188,  ..., -1.1022, -1.1022, -1.1022],\n",
            "         ...,\n",
            "         [ 1.3882,  2.8763,  3.7508,  ..., -0.7703, -0.7703, -0.7703],\n",
            "         [ 1.6542,  3.0046,  3.4481,  ..., -0.7469, -0.7469, -0.7469],\n",
            "         [ 1.3283,  2.8294,  3.3397,  ..., -0.7122, -0.7122, -0.7122]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 56, 20108])\n",
            "tensor([[[ 2.4733,  3.0468,  2.6171,  ..., -0.9781, -0.9781, -0.9781],\n",
            "         [ 2.4561,  4.0038,  2.6030,  ..., -0.9397, -0.9397, -0.9397],\n",
            "         [ 2.5626,  4.7434,  3.0006,  ..., -0.9182, -0.9182, -0.9182],\n",
            "         ...,\n",
            "         [ 3.7918,  4.8555,  4.0588,  ..., -0.8461, -0.8461, -0.8461],\n",
            "         [ 3.8451,  4.9840,  3.9907,  ..., -0.8948, -0.8948, -0.8948],\n",
            "         [ 3.8688,  4.8258,  3.5177,  ..., -0.8838, -0.8838, -0.8838]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.6733,  6.8779,  5.4814,  ..., -1.1538, -1.1538, -1.1538],\n",
            "         [ 5.2536,  6.7637,  6.1429,  ..., -1.1217, -1.1217, -1.1217],\n",
            "         [ 4.5726,  6.6545,  6.7723,  ..., -1.1372, -1.1372, -1.1372],\n",
            "         ...,\n",
            "         [ 5.4576,  8.5707,  6.9635,  ..., -0.9032, -0.9032, -0.9032],\n",
            "         [ 5.7711,  7.8396,  5.6504,  ..., -0.9197, -0.9197, -0.9197],\n",
            "         [ 5.3901,  8.0276,  6.1417,  ..., -0.9548, -0.9548, -0.9548]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 128, 20108])\n",
            "tensor([[[ 1.8877,  5.6906,  3.9026,  ..., -0.9697, -0.9697, -0.9697],\n",
            "         [ 2.5536,  5.7544,  4.6103,  ..., -1.0093, -1.0093, -1.0093],\n",
            "         [ 3.7983,  6.8077,  5.6142,  ..., -1.1387, -1.1387, -1.1387],\n",
            "         ...,\n",
            "         [ 4.2337,  4.1259,  3.5331,  ..., -0.7205, -0.7205, -0.7205],\n",
            "         [ 4.4941,  3.8567,  3.5088,  ..., -0.6757, -0.6757, -0.6757],\n",
            "         [ 3.9718,  3.5054,  3.4741,  ..., -0.6554, -0.6554, -0.6554]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 3.4999,  5.8130,  4.0530,  ..., -1.1059, -1.1059, -1.1059],\n",
            "         [ 3.4192,  7.5491,  5.1409,  ..., -0.9974, -0.9974, -0.9974],\n",
            "         [ 3.8308,  8.2754,  6.4239,  ..., -0.8559, -0.8559, -0.8559],\n",
            "         ...,\n",
            "         [ 2.4538,  5.1563,  3.6661,  ..., -0.6866, -0.6866, -0.6866],\n",
            "         [ 3.5498,  5.7414,  4.5908,  ..., -0.7663, -0.7663, -0.7663],\n",
            "         [ 3.2399,  5.3110,  4.5220,  ..., -0.6950, -0.6950, -0.6950]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 98, 20108])\n",
            "tensor([[[ 2.0567,  5.0568,  3.6033,  ..., -0.9555, -0.9555, -0.9555],\n",
            "         [ 3.8216,  6.8033,  4.5912,  ..., -0.9477, -0.9477, -0.9477],\n",
            "         [ 4.0644,  6.2413,  3.8267,  ..., -0.8397, -0.8397, -0.8397],\n",
            "         ...,\n",
            "         [ 5.9222,  8.2902,  7.3813,  ..., -0.9077, -0.9077, -0.9077],\n",
            "         [ 5.1012,  7.4072,  6.5293,  ..., -0.8468, -0.8468, -0.8468],\n",
            "         [ 5.4834,  7.2567,  6.6406,  ..., -0.8685, -0.8685, -0.8685]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 80, 20108])\n",
            "tensor([[[ 5.4386,  7.7773,  6.0350,  ..., -0.9238, -0.9238, -0.9238],\n",
            "         [ 4.5486,  7.9083,  5.6547,  ..., -0.9373, -0.9373, -0.9373],\n",
            "         [ 4.6859,  7.8718,  5.5656,  ..., -0.9098, -0.9098, -0.9098],\n",
            "         ...,\n",
            "         [ 5.5604,  5.4684,  3.5584,  ..., -0.8424, -0.8424, -0.8424],\n",
            "         [ 5.2752,  5.6435,  3.4837,  ..., -0.8300, -0.8300, -0.8300],\n",
            "         [ 4.7963,  5.2317,  3.4731,  ..., -0.8077, -0.8077, -0.8077]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 4.8306,  6.1321,  4.9809,  ..., -1.1546, -1.1546, -1.1546],\n",
            "         [ 4.0129,  6.2579,  5.3418,  ..., -1.0449, -1.0449, -1.0449],\n",
            "         [ 3.9598,  5.4024,  4.4825,  ..., -1.0315, -1.0315, -1.0315],\n",
            "         [ 4.1218,  5.2333,  3.6980,  ..., -1.0593, -1.0593, -1.0593],\n",
            "         [ 3.9082,  5.2863,  4.1542,  ..., -1.0641, -1.0641, -1.0641],\n",
            "         [ 4.3146,  4.6826,  3.4441,  ..., -1.0388, -1.0388, -1.0388]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 54, 20108])\n",
            "tensor([[[ 5.6320,  5.2853,  3.2049,  ..., -0.4173, -0.4173, -0.4173],\n",
            "         [ 5.6440,  3.2913,  1.5332,  ..., -0.3632, -0.3632, -0.3632],\n",
            "         [ 5.6758,  3.0837,  1.3724,  ..., -0.3749, -0.3749, -0.3749],\n",
            "         ...,\n",
            "         [ 8.5662,  5.0560,  3.7625,  ..., -0.8168, -0.8168, -0.8168],\n",
            "         [ 8.5305,  5.0727,  3.7631,  ..., -0.7716, -0.7716, -0.7716],\n",
            "         [ 8.5926,  4.6086,  3.5054,  ..., -0.7717, -0.7717, -0.7717]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 100, 20108])\n",
            "tensor([[[ 6.1208,  6.9769,  6.7678,  ..., -1.0811, -1.0811, -1.0811],\n",
            "         [ 5.7045,  7.1095,  6.6278,  ..., -1.0672, -1.0672, -1.0672],\n",
            "         [ 6.2955,  7.9050,  6.7160,  ..., -0.9951, -0.9951, -0.9951],\n",
            "         ...,\n",
            "         [ 2.8451,  3.5977,  5.1058,  ..., -0.8514, -0.8514, -0.8514],\n",
            "         [ 3.0849,  4.1424,  5.1595,  ..., -0.8665, -0.8665, -0.8665],\n",
            "         [ 2.5167,  3.5628,  4.6355,  ..., -0.7893, -0.7893, -0.7893]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 2.3757,  5.5212,  4.1549,  ..., -1.0227, -1.0227, -1.0227],\n",
            "         [ 1.9083,  3.9874,  2.9221,  ..., -0.9398, -0.9398, -0.9398],\n",
            "         [ 1.0743,  4.6780,  2.5169,  ..., -0.8079, -0.8079, -0.8079],\n",
            "         ...,\n",
            "         [ 1.0672,  5.4631,  3.0256,  ..., -0.6215, -0.6215, -0.6215],\n",
            "         [ 0.7463,  5.4930,  3.4602,  ..., -0.5788, -0.5788, -0.5788],\n",
            "         [ 0.7522,  5.6449,  3.6773,  ..., -0.6238, -0.6238, -0.6238]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 84, 20108])\n",
            "tensor([[[ 6.1183,  7.2335,  6.7689,  ..., -1.1190, -1.1190, -1.1190],\n",
            "         [ 4.5997,  5.9456,  6.1796,  ..., -1.0369, -1.0369, -1.0369],\n",
            "         [ 3.6686,  6.1666,  5.6664,  ..., -0.9704, -0.9704, -0.9704],\n",
            "         ...,\n",
            "         [ 5.7749,  5.6705,  5.4177,  ..., -0.8753, -0.8753, -0.8753],\n",
            "         [ 5.2673,  4.7805,  5.0159,  ..., -0.8951, -0.8951, -0.8951],\n",
            "         [ 5.5627,  5.0598,  4.9102,  ..., -0.8968, -0.8968, -0.8968]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 65, 20108])\n",
            "tensor([[[ 2.9577,  4.5274,  3.9138,  ..., -1.0125, -1.0125, -1.0125],\n",
            "         [ 1.2512,  5.5685,  4.1945,  ..., -0.8206, -0.8206, -0.8206],\n",
            "         [ 2.2361,  7.5146,  4.7671,  ..., -0.7989, -0.7989, -0.7989],\n",
            "         ...,\n",
            "         [ 2.0720,  5.9060,  4.0174,  ..., -0.6841, -0.6841, -0.6841],\n",
            "         [ 0.8666,  5.4957,  3.3183,  ..., -0.5575, -0.5575, -0.5575],\n",
            "         [ 1.6062,  5.4433,  3.6511,  ..., -0.6800, -0.6800, -0.6800]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 166, 20108])\n",
            "tensor([[[ 4.3239,  7.0674,  6.3398,  ..., -1.1270, -1.1270, -1.1270],\n",
            "         [ 3.7113,  6.7907,  5.7232,  ..., -1.1555, -1.1555, -1.1555],\n",
            "         [ 3.1662,  6.4371,  5.6594,  ..., -1.0835, -1.0835, -1.0835],\n",
            "         ...,\n",
            "         [ 2.2420,  6.5864,  3.5700,  ..., -0.8032, -0.8032, -0.8032],\n",
            "         [ 2.3156,  5.9747,  2.8709,  ..., -0.7805, -0.7805, -0.7805],\n",
            "         [ 2.2868,  5.8194,  3.1260,  ..., -0.7847, -0.7847, -0.7847]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 3.7786,  5.0240,  3.1321,  ..., -0.6183, -0.6183, -0.6183],\n",
            "         [ 4.8358,  3.2251,  2.1407,  ..., -0.4648, -0.4648, -0.4648],\n",
            "         [ 5.6192,  4.3209,  3.7398,  ..., -0.6118, -0.6118, -0.6118],\n",
            "         [ 5.4990,  2.6967,  1.6224,  ..., -0.4046, -0.4046, -0.4046],\n",
            "         [ 5.5323,  4.0018,  2.4783,  ..., -0.4913, -0.4913, -0.4913]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 5.4234,  5.2953,  3.3955,  ..., -0.4057, -0.4057, -0.4057],\n",
            "         [ 5.2497,  4.5029,  2.6844,  ..., -0.3558, -0.3558, -0.3558],\n",
            "         [ 4.9312,  3.9029,  2.1865,  ..., -0.4064, -0.4064, -0.4064],\n",
            "         ...,\n",
            "         [ 4.8581,  2.7729,  1.2047,  ..., -0.4302, -0.4302, -0.4302],\n",
            "         [ 4.5641,  3.1147,  0.9373,  ..., -0.3823, -0.3823, -0.3823],\n",
            "         [ 4.4557,  3.0077,  1.0257,  ..., -0.4223, -0.4223, -0.4223]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 2.6066,  5.0955,  3.8931,  ..., -0.9885, -0.9885, -0.9885],\n",
            "         [ 2.1962,  4.7378,  3.3489,  ..., -0.8823, -0.8823, -0.8823],\n",
            "         [ 1.6058,  4.8500,  3.7745,  ..., -0.9444, -0.9444, -0.9444],\n",
            "         ...,\n",
            "         [ 4.1623,  9.8618,  5.8816,  ..., -0.8336, -0.8336, -0.8336],\n",
            "         [ 3.6641, 10.0307,  6.1897,  ..., -0.7949, -0.7949, -0.7949],\n",
            "         [ 3.5991, 10.2473,  6.0169,  ..., -0.7424, -0.7424, -0.7424]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 150, 20108])\n",
            "tensor([[[ 5.3766,  5.9724,  4.5977,  ..., -0.5029, -0.5029, -0.5029],\n",
            "         [ 4.6162,  4.7381,  4.5321,  ..., -0.8076, -0.8076, -0.8076],\n",
            "         [ 5.3907,  5.5781,  5.5963,  ..., -0.8716, -0.8716, -0.8716],\n",
            "         ...,\n",
            "         [ 1.1426,  3.1967,  3.0728,  ..., -0.7241, -0.7241, -0.7241],\n",
            "         [ 1.6907,  3.1205,  3.1805,  ..., -0.7451, -0.7451, -0.7451],\n",
            "         [ 1.8272,  3.3697,  3.0953,  ..., -0.7160, -0.7160, -0.7160]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 4.0369,  5.2508,  4.6785,  ..., -1.0597, -1.0597, -1.0597],\n",
            "         [ 3.9009,  6.0322,  4.6317,  ..., -0.9717, -0.9717, -0.9717],\n",
            "         [ 2.4644,  5.6718,  3.7552,  ..., -0.8684, -0.8684, -0.8684],\n",
            "         [ 2.3848,  7.0263,  4.3243,  ..., -0.7950, -0.7950, -0.7950],\n",
            "         [ 2.9025,  7.2603,  5.2334,  ..., -0.7544, -0.7544, -0.7544],\n",
            "         [ 3.3593,  6.7706,  5.2240,  ..., -0.6691, -0.6691, -0.6691]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 6.5236,  9.1478,  8.7402,  ..., -1.0199, -1.0199, -1.0199],\n",
            "         [ 6.0281,  7.9817,  7.3999,  ..., -1.0398, -1.0398, -1.0398],\n",
            "         [ 6.7012,  8.3672,  8.3717,  ..., -1.0220, -1.0220, -1.0220],\n",
            "         ...,\n",
            "         [ 7.0216,  7.5384,  6.6484,  ..., -1.0007, -1.0007, -1.0007],\n",
            "         [ 6.0981,  7.0982,  6.4270,  ..., -0.8978, -0.8978, -0.8978],\n",
            "         [ 5.7223,  6.9519,  6.3723,  ..., -0.8821, -0.8821, -0.8821]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 1.5157,  5.0710,  2.7966,  ..., -0.8008, -0.8008, -0.8008],\n",
            "         [ 1.8469,  4.7371,  3.4476,  ..., -0.8388, -0.8388, -0.8388],\n",
            "         [ 1.0681,  4.7073,  3.0327,  ..., -0.8218, -0.8218, -0.8218],\n",
            "         ...,\n",
            "         [ 3.9984,  5.3194,  2.6921,  ..., -0.7403, -0.7403, -0.7403],\n",
            "         [ 3.4557,  5.3999,  3.3410,  ..., -0.8009, -0.8009, -0.8009],\n",
            "         [ 3.3714,  5.2190,  2.9444,  ..., -0.7403, -0.7403, -0.7403]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 92, 20108])\n",
            "tensor([[[ 3.0273,  6.0452,  4.8409,  ..., -1.1409, -1.1409, -1.1409],\n",
            "         [ 3.0185,  7.2392,  5.6984,  ..., -0.9928, -0.9928, -0.9928],\n",
            "         [ 2.8457,  6.9790,  5.5443,  ..., -1.0361, -1.0361, -1.0361],\n",
            "         ...,\n",
            "         [ 5.7811,  6.1323,  5.7347,  ..., -0.9893, -0.9893, -0.9893],\n",
            "         [ 5.9042,  5.9492,  5.6242,  ..., -0.9618, -0.9618, -0.9618],\n",
            "         [ 5.7652,  6.5311,  5.8282,  ..., -0.9749, -0.9749, -0.9749]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 2.9649,  5.7534,  3.1704,  ..., -0.5940, -0.5940, -0.5940],\n",
            "         [ 4.4999,  5.0144,  2.4450,  ..., -0.4762, -0.4762, -0.4762],\n",
            "         [ 4.0270,  4.3706,  2.2715,  ..., -0.4766, -0.4766, -0.4766],\n",
            "         ...,\n",
            "         [ 6.6344,  4.4551,  2.9540,  ..., -0.3827, -0.3827, -0.3827],\n",
            "         [ 6.2548,  3.8688,  2.2268,  ..., -0.3621, -0.3621, -0.3621],\n",
            "         [ 6.2956,  3.3223,  1.8368,  ..., -0.3414, -0.3414, -0.3414]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 107, 20108])\n",
            "tensor([[[ 2.8349,  4.9920,  3.7225,  ..., -0.9569, -0.9569, -0.9569],\n",
            "         [ 4.6199,  7.2914,  6.1424,  ..., -1.0319, -1.0319, -1.0319],\n",
            "         [ 4.2797,  6.3537,  5.9239,  ..., -0.9939, -0.9939, -0.9939],\n",
            "         ...,\n",
            "         [ 4.6409,  3.5524,  4.3741,  ..., -0.9768, -0.9768, -0.9768],\n",
            "         [ 3.4926,  3.4108,  4.0473,  ..., -0.9382, -0.9382, -0.9382],\n",
            "         [ 4.2167,  5.0273,  5.3738,  ..., -1.0022, -1.0022, -1.0022]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 5.9275,  6.0179,  6.6744,  ..., -1.0541, -1.0541, -1.0541],\n",
            "         [ 7.4955,  7.3126,  7.8027,  ..., -1.0479, -1.0479, -1.0479],\n",
            "         [ 6.7954,  8.0850,  8.2741,  ..., -0.9910, -0.9910, -0.9910],\n",
            "         ...,\n",
            "         [ 7.2783,  7.5822,  8.1030,  ..., -1.0096, -1.0096, -1.0096],\n",
            "         [ 7.2229,  7.8515,  8.1179,  ..., -1.0533, -1.0533, -1.0533],\n",
            "         [ 6.3513,  8.4260,  7.9211,  ..., -0.9853, -0.9853, -0.9853]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 33, 20108])\n",
            "tensor([[[ 2.8652,  4.7906,  3.9104,  ..., -1.0696, -1.0696, -1.0696],\n",
            "         [ 3.0776,  5.7167,  4.0342,  ..., -0.9787, -0.9787, -0.9787],\n",
            "         [ 3.1591,  5.9404,  4.2139,  ..., -0.9894, -0.9894, -0.9894],\n",
            "         ...,\n",
            "         [ 4.1186,  6.7964,  6.5124,  ..., -0.7347, -0.7347, -0.7347],\n",
            "         [ 4.5972,  6.8346,  6.6179,  ..., -0.8115, -0.8115, -0.8115],\n",
            "         [ 4.4282,  6.8750,  6.0456,  ..., -0.8670, -0.8670, -0.8670]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 2.2639,  5.3509,  4.1922,  ..., -1.0705, -1.0705, -1.0705],\n",
            "         [ 2.6383,  4.5977,  3.0979,  ..., -0.9607, -0.9607, -0.9607],\n",
            "         [ 1.8939,  4.7543,  2.8992,  ..., -0.9077, -0.9077, -0.9077],\n",
            "         [ 2.0008,  4.5396,  2.6200,  ..., -0.8665, -0.8665, -0.8665],\n",
            "         [ 2.2717,  6.4191,  3.9466,  ..., -0.8030, -0.8030, -0.8030],\n",
            "         [ 3.9219,  8.0274,  5.9608,  ..., -0.8788, -0.8788, -0.8788]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 2.1243,  4.8949,  4.0854,  ..., -0.9906, -0.9906, -0.9906],\n",
            "         [ 4.1981,  6.6978,  5.9844,  ..., -1.0642, -1.0642, -1.0642],\n",
            "         [ 4.9587,  6.5254,  6.9524,  ..., -1.1263, -1.1263, -1.1263],\n",
            "         ...,\n",
            "         [ 4.9200,  5.4232,  5.0116,  ..., -0.9079, -0.9079, -0.9079],\n",
            "         [ 4.9877,  5.8952,  5.1287,  ..., -0.9343, -0.9343, -0.9343],\n",
            "         [ 4.1661,  4.8583,  4.2951,  ..., -0.9052, -0.9052, -0.9052]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 2.7473,  6.2456,  5.1357,  ..., -1.0378, -1.0378, -1.0378],\n",
            "         [ 4.4833,  6.9122,  6.3345,  ..., -1.1542, -1.1542, -1.1542],\n",
            "         [ 5.7949,  6.9594,  6.4081,  ..., -1.1344, -1.1344, -1.1344],\n",
            "         ...,\n",
            "         [ 7.1917,  4.7765,  4.3241,  ..., -0.8735, -0.8735, -0.8735],\n",
            "         [ 6.2846,  4.7290,  4.5221,  ..., -0.8910, -0.8910, -0.8910],\n",
            "         [ 5.5195,  3.9177,  4.3459,  ..., -0.8769, -0.8769, -0.8769]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 30, 20108])\n",
            "tensor([[[ 2.9779,  7.1377,  4.9102,  ..., -0.8186, -0.8186, -0.8186],\n",
            "         [ 2.3774,  6.2999,  4.5906,  ..., -0.8381, -0.8381, -0.8381],\n",
            "         [ 1.8557,  6.1569,  4.3434,  ..., -0.6428, -0.6428, -0.6428],\n",
            "         ...,\n",
            "         [ 4.9017,  6.4572,  5.3250,  ..., -0.7487, -0.7487, -0.7487],\n",
            "         [ 4.0596,  6.7049,  6.1710,  ..., -0.8197, -0.8197, -0.8197],\n",
            "         [ 3.6456,  6.5338,  5.7263,  ..., -0.7923, -0.7923, -0.7923]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 18, 20108])\n",
            "tensor([[[ 4.4316,  6.4895,  5.7513,  ..., -1.0467, -1.0467, -1.0467],\n",
            "         [ 5.3284,  6.5780,  6.7187,  ..., -1.0666, -1.0666, -1.0666],\n",
            "         [ 5.5908,  6.5074,  6.9901,  ..., -1.0084, -1.0084, -1.0084],\n",
            "         ...,\n",
            "         [ 6.0948,  8.3091,  7.5388,  ..., -1.1916, -1.1916, -1.1916],\n",
            "         [ 5.9109,  7.9788,  7.4244,  ..., -1.0806, -1.0806, -1.0806],\n",
            "         [ 6.3425,  8.3538,  7.4842,  ..., -1.0727, -1.0727, -1.0727]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 4.8142,  6.5019,  6.1371,  ..., -1.0965, -1.0965, -1.0965],\n",
            "         [ 4.9004,  7.2412,  6.7472,  ..., -1.0947, -1.0947, -1.0947],\n",
            "         [ 4.6429,  7.1843,  7.1005,  ..., -1.1265, -1.1265, -1.1265],\n",
            "         ...,\n",
            "         [ 3.6533,  7.6793,  6.6080,  ..., -0.9786, -0.9786, -0.9786],\n",
            "         [ 3.4812,  7.1054,  5.8875,  ..., -0.9468, -0.9468, -0.9468],\n",
            "         [ 3.5064,  7.1478,  5.8245,  ..., -0.9964, -0.9964, -0.9964]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 94, 20108])\n",
            "tensor([[[ 4.4627,  6.7881,  5.9452,  ..., -1.0319, -1.0319, -1.0319],\n",
            "         [ 4.6235,  6.2409,  6.4747,  ..., -0.9551, -0.9551, -0.9551],\n",
            "         [ 4.6816,  7.7346,  7.2557,  ..., -1.0073, -1.0073, -1.0073],\n",
            "         ...,\n",
            "         [ 5.2710,  4.9034,  5.7366,  ..., -0.9540, -0.9540, -0.9540],\n",
            "         [ 6.6625,  7.2717,  6.7369,  ..., -1.0254, -1.0254, -1.0254],\n",
            "         [ 6.2713,  5.9695,  5.8206,  ..., -1.0621, -1.0621, -1.0621]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 4.9137,  5.1778,  3.9938,  ..., -0.8493, -0.8493, -0.8493],\n",
            "         [ 3.6418,  4.9994,  2.8211,  ..., -0.6735, -0.6735, -0.6735],\n",
            "         [ 4.0427,  7.1677,  4.4375,  ..., -0.8006, -0.8006, -0.8006],\n",
            "         ...,\n",
            "         [ 4.3531,  6.7566,  4.0032,  ..., -0.8005, -0.8005, -0.8005],\n",
            "         [ 4.5589,  6.5918,  4.0834,  ..., -0.7797, -0.7797, -0.7797],\n",
            "         [ 5.0464,  6.4267,  3.9051,  ..., -0.7318, -0.7318, -0.7318]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 34, 20108])\n",
            "tensor([[[ 4.8412,  6.7267,  6.0863,  ..., -1.0693, -1.0693, -1.0693],\n",
            "         [ 5.7164,  7.1111,  7.0333,  ..., -1.0420, -1.0420, -1.0420],\n",
            "         [ 5.2830,  6.3602,  6.8347,  ..., -1.0881, -1.0881, -1.0881],\n",
            "         ...,\n",
            "         [ 4.7941,  3.2839,  3.5793,  ..., -0.8216, -0.8216, -0.8216],\n",
            "         [ 4.6007,  3.3929,  3.7708,  ..., -0.8333, -0.8333, -0.8333],\n",
            "         [ 4.5626,  3.3885,  3.2785,  ..., -0.7899, -0.7899, -0.7899]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 65, 20108])\n",
            "tensor([[[ 6.3784,  8.4867,  8.1945,  ..., -0.9973, -0.9973, -0.9973],\n",
            "         [ 3.9179,  6.2935,  6.2133,  ..., -1.0362, -1.0362, -1.0362],\n",
            "         [ 4.6107,  6.9764,  6.6700,  ..., -1.0340, -1.0340, -1.0340],\n",
            "         ...,\n",
            "         [ 4.3065,  6.6520,  6.7087,  ..., -0.9076, -0.9076, -0.9076],\n",
            "         [ 4.6220,  6.9735,  6.8459,  ..., -0.8996, -0.8996, -0.8996],\n",
            "         [ 5.0746,  7.7169,  7.3546,  ..., -0.8676, -0.8676, -0.8676]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 5.2729,  5.9599,  3.9570,  ..., -0.5804, -0.5804, -0.5804],\n",
            "         [ 5.0940,  4.4222,  2.8233,  ..., -0.4771, -0.4771, -0.4771],\n",
            "         [ 4.5412,  4.0243,  2.2805,  ..., -0.3770, -0.3770, -0.3770],\n",
            "         ...,\n",
            "         [ 4.6169,  3.2649,  0.7743,  ..., -0.3918, -0.3918, -0.3918],\n",
            "         [ 5.2617,  2.8341,  0.8555,  ..., -0.4976, -0.4976, -0.4976],\n",
            "         [ 5.0866,  2.6711,  0.6917,  ..., -0.4322, -0.4322, -0.4322]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 50, 20108])\n",
            "tensor([[[ 4.5332,  7.7277,  7.2704,  ..., -1.0824, -1.0824, -1.0824],\n",
            "         [ 3.9920,  7.8749,  7.0168,  ..., -1.0438, -1.0438, -1.0438],\n",
            "         [ 3.8351,  7.3487,  6.5364,  ..., -1.1051, -1.1051, -1.1051],\n",
            "         ...,\n",
            "         [ 4.0525,  5.9508,  4.7451,  ..., -0.7216, -0.7216, -0.7216],\n",
            "         [ 3.3780,  6.5253,  4.7179,  ..., -0.6849, -0.6849, -0.6849],\n",
            "         [ 4.3103,  6.8193,  5.3373,  ..., -0.7941, -0.7941, -0.7941]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 47, 20108])\n",
            "tensor([[[ 4.6928,  7.2148,  6.1481,  ..., -1.1444, -1.1444, -1.1444],\n",
            "         [ 4.4224,  6.6786,  6.1741,  ..., -1.1255, -1.1255, -1.1255],\n",
            "         [ 4.3906,  6.7150,  5.8287,  ..., -1.0885, -1.0885, -1.0885],\n",
            "         ...,\n",
            "         [ 7.9643,  8.1489,  7.1867,  ..., -0.9922, -0.9922, -0.9922],\n",
            "         [ 7.4142,  7.9447,  7.2582,  ..., -0.9481, -0.9481, -0.9481],\n",
            "         [ 6.9414,  8.2773,  7.2631,  ..., -0.9411, -0.9411, -0.9411]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 97, 20108])\n",
            "tensor([[[ 4.0091,  5.4759,  5.0040,  ..., -1.1251, -1.1251, -1.1251],\n",
            "         [ 3.9350,  6.1484,  5.3379,  ..., -1.1153, -1.1153, -1.1153],\n",
            "         [ 4.7322,  6.3019,  5.3877,  ..., -1.0812, -1.0812, -1.0812],\n",
            "         ...,\n",
            "         [ 6.5772,  4.9122,  5.6964,  ..., -1.0170, -1.0170, -1.0170],\n",
            "         [ 6.4595,  4.4111,  5.5161,  ..., -0.9661, -0.9661, -0.9661],\n",
            "         [ 6.5023,  4.1590,  5.1132,  ..., -0.9904, -0.9904, -0.9904]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 55, 20108])\n",
            "tensor([[[ 4.7663,  6.4686,  6.1459,  ..., -1.1483, -1.1483, -1.1483],\n",
            "         [ 4.7567,  7.0962,  6.3096,  ..., -1.0170, -1.0170, -1.0170],\n",
            "         [ 4.0352,  8.0582,  6.4663,  ..., -0.9432, -0.9432, -0.9432],\n",
            "         ...,\n",
            "         [ 8.1759,  5.7975,  4.7668,  ..., -0.7979, -0.7979, -0.7979],\n",
            "         [ 7.3533,  5.4728,  4.8744,  ..., -0.8746, -0.8746, -0.8746],\n",
            "         [ 7.8746,  4.6579,  4.4745,  ..., -0.8608, -0.8608, -0.8608]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 3.5188,  6.2611,  4.9223,  ..., -1.0667, -1.0667, -1.0667],\n",
            "         [ 2.6000,  5.6997,  4.6090,  ..., -1.1074, -1.1074, -1.1074],\n",
            "         [ 2.1734,  5.6087,  3.8371,  ..., -1.0558, -1.0558, -1.0558],\n",
            "         ...,\n",
            "         [ 4.8334,  9.5120,  7.9341,  ..., -0.8746, -0.8746, -0.8746],\n",
            "         [ 4.3916,  9.5702,  8.0613,  ..., -0.8379, -0.8379, -0.8379],\n",
            "         [ 4.9403,  8.5734,  7.5711,  ..., -0.9191, -0.9191, -0.9191]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 122, 20108])\n",
            "tensor([[[ 5.6719,  7.1323,  6.9552,  ..., -1.1097, -1.1097, -1.1097],\n",
            "         [ 4.9902,  6.6520,  6.9017,  ..., -1.1543, -1.1543, -1.1543],\n",
            "         [ 4.6863,  6.4117,  6.4404,  ..., -1.1178, -1.1178, -1.1178],\n",
            "         ...,\n",
            "         [ 2.6321,  3.9490,  4.1176,  ..., -0.8101, -0.8101, -0.8101],\n",
            "         [ 1.9827,  3.5173,  3.6408,  ..., -0.6943, -0.6943, -0.6943],\n",
            "         [ 5.7002,  5.0401,  5.6671,  ..., -0.9017, -0.9017, -0.9017]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 71, 20108])\n",
            "tensor([[[ 5.2396,  8.2425,  7.5295,  ..., -1.1494, -1.1494, -1.1494],\n",
            "         [ 5.7077,  7.9392,  7.4440,  ..., -1.1400, -1.1400, -1.1400],\n",
            "         [ 6.4522,  8.7376,  8.0671,  ..., -1.0796, -1.0796, -1.0796],\n",
            "         ...,\n",
            "         [ 7.7400,  7.4021,  7.2221,  ..., -1.0240, -1.0240, -1.0240],\n",
            "         [ 7.9218,  7.4632,  7.3506,  ..., -1.0191, -1.0191, -1.0191],\n",
            "         [ 7.4556,  7.8124,  7.5940,  ..., -1.0078, -1.0078, -1.0078]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 5.7411,  5.9169,  3.7857,  ..., -0.4313, -0.4313, -0.4313],\n",
            "         [ 5.7921,  4.3011,  2.7017,  ..., -0.6409, -0.6409, -0.6409],\n",
            "         [ 7.4219,  4.9053,  2.9615,  ..., -0.5447, -0.5447, -0.5447],\n",
            "         ...,\n",
            "         [ 6.4014,  4.6428,  2.0687,  ..., -0.4070, -0.4070, -0.4070],\n",
            "         [ 6.9613,  3.9473,  1.5335,  ..., -0.4968, -0.4968, -0.4968],\n",
            "         [ 7.2124,  4.6517,  1.8800,  ..., -0.4372, -0.4372, -0.4372]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 4.9951,  6.8204,  6.1143,  ..., -1.1402, -1.1402, -1.1402],\n",
            "         [ 5.6543,  7.1022,  7.1818,  ..., -1.1257, -1.1257, -1.1257],\n",
            "         [ 5.4656,  7.5067,  6.8230,  ..., -1.0054, -1.0054, -1.0054],\n",
            "         ...,\n",
            "         [ 5.3987,  5.8709,  4.7014,  ..., -0.8871, -0.8871, -0.8871],\n",
            "         [ 5.2210,  5.2728,  4.3621,  ..., -0.8764, -0.8764, -0.8764],\n",
            "         [ 5.2413,  5.0276,  4.3127,  ..., -0.8814, -0.8814, -0.8814]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.7555,  6.3011,  4.0466,  ..., -0.6643, -0.6643, -0.6643],\n",
            "         [ 4.5889,  5.2839,  3.4707,  ..., -0.5027, -0.5027, -0.5027],\n",
            "         [ 5.0550,  6.3778,  3.8159,  ..., -0.4504, -0.4504, -0.4504],\n",
            "         ...,\n",
            "         [ 7.0792,  2.1002,  0.3203,  ..., -0.3074, -0.3074, -0.3074],\n",
            "         [ 6.7591,  1.8436,  0.6175,  ..., -0.3069, -0.3069, -0.3069],\n",
            "         [ 6.2334,  1.2797, -0.1426,  ..., -0.1933, -0.1933, -0.1933]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 48, 20108])\n",
            "tensor([[[ 2.4960,  4.4270,  3.9357,  ..., -0.9469, -0.9469, -0.9469],\n",
            "         [ 2.4808,  4.9502,  3.4689,  ..., -1.0422, -1.0422, -1.0422],\n",
            "         [ 1.9197,  4.8814,  3.2509,  ..., -0.9748, -0.9748, -0.9748],\n",
            "         ...,\n",
            "         [ 3.4449,  5.4029,  4.6422,  ..., -0.8422, -0.8422, -0.8422],\n",
            "         [ 5.1470,  6.0468,  5.4140,  ..., -0.8264, -0.8264, -0.8264],\n",
            "         [ 4.3810,  5.5034,  5.0537,  ..., -0.8744, -0.8744, -0.8744]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 43, 20108])\n",
            "tensor([[[ 4.2549,  5.7920,  5.5847,  ..., -1.0923, -1.0923, -1.0923],\n",
            "         [ 3.9097,  5.9103,  5.5496,  ..., -1.0563, -1.0563, -1.0563],\n",
            "         [ 3.0609,  5.7963,  5.2827,  ..., -1.0389, -1.0389, -1.0389],\n",
            "         ...,\n",
            "         [ 5.8049,  6.0741,  5.8427,  ..., -1.0178, -1.0178, -1.0178],\n",
            "         [ 5.9534,  6.2864,  6.3047,  ..., -1.0464, -1.0464, -1.0464],\n",
            "         [ 6.5476,  6.6247,  6.1762,  ..., -1.0498, -1.0498, -1.0498]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.1903,  6.1518,  4.6440,  ..., -1.1309, -1.1309, -1.1309],\n",
            "         [ 2.1948,  6.0062,  4.1380,  ..., -1.0530, -1.0530, -1.0530],\n",
            "         [ 1.5833,  5.5143,  4.1094,  ..., -1.0305, -1.0305, -1.0305],\n",
            "         ...,\n",
            "         [ 1.0893,  6.5848,  4.3835,  ..., -0.8874, -0.8874, -0.8874],\n",
            "         [ 0.5672,  6.5591,  4.1413,  ..., -0.8001, -0.8001, -0.8001],\n",
            "         [ 1.3388,  7.7451,  6.0918,  ..., -0.9320, -0.9320, -0.9320]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 3.4016,  5.1147,  2.9947,  ..., -0.5655, -0.5655, -0.5655],\n",
            "         [ 3.3507,  4.1991,  1.8526,  ..., -0.4146, -0.4146, -0.4146],\n",
            "         [ 2.9682,  4.5372,  2.7284,  ..., -0.4648, -0.4648, -0.4648],\n",
            "         ...,\n",
            "         [ 5.8228,  3.9275,  2.3082,  ..., -0.3655, -0.3655, -0.3655],\n",
            "         [ 6.0279,  3.7147,  2.7624,  ..., -0.4111, -0.4111, -0.4111],\n",
            "         [ 6.2060,  3.6563,  2.9340,  ..., -0.4302, -0.4302, -0.4302]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 95, 20108])\n",
            "tensor([[[ 6.8591,  6.6819,  6.4822,  ..., -1.0919, -1.0919, -1.0919],\n",
            "         [ 6.1079,  6.2720,  6.1827,  ..., -1.0551, -1.0551, -1.0551],\n",
            "         [ 5.3813,  5.5190,  6.1079,  ..., -1.0283, -1.0283, -1.0283],\n",
            "         ...,\n",
            "         [ 6.4760,  5.4477,  6.4972,  ..., -0.8129, -0.8129, -0.8129],\n",
            "         [ 6.5463,  5.2114,  6.3719,  ..., -0.7778, -0.7778, -0.7778],\n",
            "         [ 5.8614,  5.4005,  6.3353,  ..., -0.8255, -0.8255, -0.8255]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 6.7886,  7.9505,  7.5405,  ..., -1.0028, -1.0028, -1.0028],\n",
            "         [ 7.0785,  7.9032,  7.9839,  ..., -1.1015, -1.1015, -1.1015],\n",
            "         [ 6.5831,  8.0554,  7.7392,  ..., -1.0583, -1.0583, -1.0583],\n",
            "         ...,\n",
            "         [ 5.6076,  6.8893,  6.3256,  ..., -1.1452, -1.1452, -1.1452],\n",
            "         [ 5.2681,  6.2329,  6.0568,  ..., -1.0161, -1.0161, -1.0161],\n",
            "         [ 4.5186,  5.7415,  5.9170,  ..., -0.9173, -0.9173, -0.9173]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 149, 20108])\n",
            "tensor([[[ 3.1413,  5.6228,  4.6789,  ..., -1.0650, -1.0650, -1.0650],\n",
            "         [ 2.8716,  5.6144,  3.4157,  ..., -1.0765, -1.0765, -1.0765],\n",
            "         [ 2.3083,  5.0910,  3.3495,  ..., -1.0213, -1.0213, -1.0213],\n",
            "         ...,\n",
            "         [ 5.3928,  3.6348,  3.8008,  ..., -0.8615, -0.8615, -0.8615],\n",
            "         [ 5.0115,  3.5679,  3.6567,  ..., -0.8451, -0.8451, -0.8451],\n",
            "         [ 4.6336,  3.1793,  3.1496,  ..., -0.8349, -0.8349, -0.8349]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 452, 20108])\n",
            "tensor([[[ 6.9403,  8.4171,  7.7902,  ..., -1.0694, -1.0694, -1.0694],\n",
            "         [ 6.2040,  8.0937,  8.2513,  ..., -0.9673, -0.9673, -0.9673],\n",
            "         [ 5.6215,  7.7661,  7.4867,  ..., -1.0204, -1.0204, -1.0204],\n",
            "         ...,\n",
            "         [ 1.3450,  1.4793,  1.9229,  ..., -0.4473, -0.4473, -0.4473],\n",
            "         [ 1.9225,  1.2185,  1.5709,  ..., -0.4088, -0.4088, -0.4088],\n",
            "         [ 1.4515,  1.2789,  1.5533,  ..., -0.3737, -0.3737, -0.3737]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 55, 20108])\n",
            "tensor([[[ 2.2724,  5.1709,  3.9630,  ..., -1.0376, -1.0376, -1.0376],\n",
            "         [ 1.7755,  5.5279,  3.5379,  ..., -1.0570, -1.0570, -1.0570],\n",
            "         [ 1.3746,  5.0466,  3.3270,  ..., -1.0253, -1.0253, -1.0253],\n",
            "         ...,\n",
            "         [ 3.5922,  5.2309,  4.0192,  ..., -0.9509, -0.9509, -0.9509],\n",
            "         [ 3.7731,  5.4145,  3.9081,  ..., -0.9111, -0.9111, -0.9111],\n",
            "         [ 4.0902,  5.0059,  3.8177,  ..., -0.9401, -0.9401, -0.9401]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 59, 20108])\n",
            "tensor([[[ 6.7278,  7.3453,  6.5186,  ..., -0.9339, -0.9339, -0.9339],\n",
            "         [ 7.6213,  7.5267,  7.3365,  ..., -0.9816, -0.9816, -0.9816],\n",
            "         [ 7.1558,  6.8102,  6.1417,  ..., -1.0102, -1.0102, -1.0102],\n",
            "         ...,\n",
            "         [ 4.8018,  4.6694,  5.2353,  ..., -0.9745, -0.9745, -0.9745],\n",
            "         [ 4.6148,  4.5438,  4.9131,  ..., -0.9690, -0.9690, -0.9690],\n",
            "         [ 4.4765,  4.9513,  5.6158,  ..., -0.9725, -0.9725, -0.9725]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 3.9361,  4.9663,  4.1106,  ..., -0.8612, -0.8612, -0.8612],\n",
            "         [ 4.1521,  4.9852,  4.1045,  ..., -0.7124, -0.7124, -0.7124],\n",
            "         [ 4.7883,  3.6060,  2.3339,  ..., -0.6023, -0.6023, -0.6023],\n",
            "         [ 5.0776,  3.4064,  1.7728,  ..., -0.6079, -0.6079, -0.6079],\n",
            "         [ 4.6905,  2.7972,  0.6579,  ..., -0.4811, -0.4811, -0.4811],\n",
            "         [ 5.3501,  2.7668,  0.5929,  ..., -0.5577, -0.5577, -0.5577]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 26, 20108])\n",
            "tensor([[[ 3.4087,  5.5635,  3.4456,  ..., -0.5893, -0.5893, -0.5893],\n",
            "         [ 3.2242,  4.7416,  2.3622,  ..., -0.4744, -0.4744, -0.4744],\n",
            "         [ 4.0609,  4.6844,  2.5031,  ..., -0.4732, -0.4732, -0.4732],\n",
            "         ...,\n",
            "         [ 5.7148,  4.7131,  2.3132,  ..., -0.3215, -0.3215, -0.3215],\n",
            "         [ 5.4368,  5.2262,  2.4719,  ..., -0.3791, -0.3791, -0.3791],\n",
            "         [ 6.0992,  5.2450,  2.9395,  ..., -0.3529, -0.3529, -0.3529]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 33, 20108])\n",
            "tensor([[[ 6.7933,  8.3422,  7.7973,  ..., -1.1050, -1.1050, -1.1050],\n",
            "         [ 5.1155,  6.5178,  6.2621,  ..., -1.1096, -1.1096, -1.1096],\n",
            "         [ 4.6344,  6.8831,  6.4174,  ..., -1.1178, -1.1178, -1.1178],\n",
            "         ...,\n",
            "         [ 3.3847,  6.0592,  6.6053,  ..., -0.7848, -0.7848, -0.7848],\n",
            "         [ 2.8950,  5.9097,  6.0986,  ..., -0.7865, -0.7865, -0.7865],\n",
            "         [ 4.5247,  5.9224,  6.7265,  ..., -0.9323, -0.9323, -0.9323]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 6.0700,  6.3283,  4.5062,  ..., -0.5436, -0.5436, -0.5436],\n",
            "         [ 5.2290,  4.2241,  2.5288,  ..., -0.4456, -0.4456, -0.4456],\n",
            "         [ 5.2118,  3.8223,  1.9181,  ..., -0.4442, -0.4442, -0.4442],\n",
            "         ...,\n",
            "         [ 4.8527,  3.8817,  1.4328,  ..., -0.4171, -0.4171, -0.4171],\n",
            "         [ 4.4587,  3.7591,  1.7932,  ..., -0.4908, -0.4908, -0.4908],\n",
            "         [ 4.9572,  3.8433,  1.3667,  ..., -0.3666, -0.3666, -0.3666]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 3.4548,  6.4928,  6.3167,  ..., -1.0872, -1.0872, -1.0872],\n",
            "         [ 1.4714,  5.4038,  4.7031,  ..., -0.8818, -0.8818, -0.8818],\n",
            "         [ 1.6681,  6.3136,  5.3299,  ..., -0.8689, -0.8689, -0.8689],\n",
            "         ...,\n",
            "         [ 2.0165,  5.9190,  5.8697,  ..., -0.7320, -0.7320, -0.7320],\n",
            "         [ 2.9313,  6.3280,  6.9868,  ..., -0.8027, -0.8027, -0.8027],\n",
            "         [ 2.3916,  6.1052,  6.1931,  ..., -0.7570, -0.7570, -0.7570]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 2.6511,  5.5232,  4.4015,  ..., -1.0831, -1.0831, -1.0831],\n",
            "         [ 2.3947,  6.0123,  4.2129,  ..., -1.0829, -1.0829, -1.0829],\n",
            "         [ 1.9897,  5.1077,  2.9819,  ..., -1.0426, -1.0426, -1.0426],\n",
            "         [ 2.2210,  5.2382,  3.5981,  ..., -1.0698, -1.0698, -1.0698],\n",
            "         [ 3.8874,  7.9000,  5.4064,  ..., -1.0795, -1.0795, -1.0795]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 56, 20108])\n",
            "tensor([[[ 4.9770,  6.5212,  5.7957,  ..., -1.0567, -1.0567, -1.0567],\n",
            "         [ 5.1282,  6.9226,  7.3995,  ..., -1.1014, -1.1014, -1.1014],\n",
            "         [ 5.2697,  5.9724,  6.5649,  ..., -0.9693, -0.9693, -0.9693],\n",
            "         ...,\n",
            "         [ 3.8613,  3.2195,  4.6882,  ..., -0.9069, -0.9069, -0.9069],\n",
            "         [ 3.2891,  3.2881,  4.4229,  ..., -0.8471, -0.8471, -0.8471],\n",
            "         [ 3.0930,  3.6647,  3.6730,  ..., -0.7932, -0.7932, -0.7932]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 5.4729,  7.3726,  6.8959,  ..., -1.1918, -1.1918, -1.1918],\n",
            "         [ 5.2484,  6.7575,  6.5711,  ..., -1.0968, -1.0968, -1.0968],\n",
            "         [ 5.0562,  6.6240,  6.4735,  ..., -1.0177, -1.0177, -1.0177],\n",
            "         ...,\n",
            "         [ 5.1128,  5.9715,  6.0650,  ..., -1.0905, -1.0905, -1.0905],\n",
            "         [ 5.4547,  6.0739,  5.9656,  ..., -1.0628, -1.0628, -1.0628],\n",
            "         [ 5.7158,  5.7357,  6.0484,  ..., -1.0839, -1.0839, -1.0839]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 1.9876,  5.0486,  3.7597,  ..., -1.0184, -1.0184, -1.0184],\n",
            "         [ 1.9570,  4.7771,  3.2803,  ..., -0.9809, -0.9809, -0.9809],\n",
            "         [ 0.9562,  4.5086,  3.3210,  ..., -0.9669, -0.9669, -0.9669],\n",
            "         ...,\n",
            "         [ 2.2529,  4.8279,  2.9275,  ..., -0.9205, -0.9205, -0.9205],\n",
            "         [ 3.3180,  7.8908,  4.9617,  ..., -0.9325, -0.9325, -0.9325],\n",
            "         [ 3.0616,  7.1942,  5.0315,  ..., -1.0544, -1.0544, -1.0544]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 56, 20108])\n",
            "tensor([[[ 4.3909,  7.2979,  6.2448,  ..., -1.1424, -1.1424, -1.1424],\n",
            "         [ 4.1717,  7.0031,  6.4099,  ..., -1.0232, -1.0232, -1.0232],\n",
            "         [ 5.2657,  7.0390,  6.6673,  ..., -1.0970, -1.0970, -1.0970],\n",
            "         ...,\n",
            "         [ 2.8098,  4.8458,  3.7209,  ..., -0.6462, -0.6462, -0.6462],\n",
            "         [ 2.8108,  4.6999,  3.7684,  ..., -0.6330, -0.6330, -0.6330],\n",
            "         [ 2.6729,  4.0954,  3.1359,  ..., -0.6353, -0.6353, -0.6353]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 5.3146,  6.1095,  5.9250,  ..., -1.1510, -1.1510, -1.1510],\n",
            "         [ 5.3181,  6.4545,  6.7064,  ..., -1.1016, -1.1016, -1.1016],\n",
            "         [ 5.1123,  6.6929,  7.6177,  ..., -1.0718, -1.0718, -1.0718],\n",
            "         ...,\n",
            "         [ 7.6265,  7.9319,  7.7850,  ..., -1.1030, -1.1030, -1.1030],\n",
            "         [ 7.1562,  7.7968,  7.5944,  ..., -1.0195, -1.0195, -1.0195],\n",
            "         [ 7.3890,  7.7143,  7.3253,  ..., -1.0766, -1.0766, -1.0766]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 5.9577,  7.5508,  7.3675,  ..., -1.0356, -1.0356, -1.0356],\n",
            "         [ 5.0613,  7.1545,  6.9207,  ..., -1.0389, -1.0389, -1.0389],\n",
            "         [ 3.9423,  7.1563,  6.1171,  ..., -0.9577, -0.9577, -0.9577],\n",
            "         ...,\n",
            "         [ 3.6409,  6.7045,  6.4687,  ..., -1.0365, -1.0365, -1.0365],\n",
            "         [ 3.9611,  6.7780,  6.5888,  ..., -1.0118, -1.0118, -1.0118],\n",
            "         [ 4.0027,  6.8948,  7.0917,  ..., -1.0029, -1.0029, -1.0029]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 3.6519,  6.3016,  5.7791,  ..., -1.0264, -1.0264, -1.0264],\n",
            "         [ 2.9017,  5.9606,  5.2659,  ..., -0.9153, -0.9153, -0.9153],\n",
            "         [ 3.1004,  5.5155,  4.9122,  ..., -0.9646, -0.9646, -0.9646],\n",
            "         ...,\n",
            "         [ 3.4933,  6.7965,  6.4224,  ..., -0.9069, -0.9069, -0.9069],\n",
            "         [ 3.3539,  6.9302,  6.3517,  ..., -0.8823, -0.8823, -0.8823],\n",
            "         [ 3.7531,  7.1009,  6.9642,  ..., -0.9468, -0.9468, -0.9468]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.8900,  5.2847,  3.1038,  ..., -0.6249, -0.6249, -0.6249],\n",
            "         [ 2.7332,  4.4543,  2.2706,  ..., -0.4504, -0.4504, -0.4504],\n",
            "         [ 2.7252,  4.3134,  2.4700,  ..., -0.3762, -0.3762, -0.3762],\n",
            "         ...,\n",
            "         [ 5.7397,  4.7361,  3.0103,  ..., -0.4107, -0.4107, -0.4107],\n",
            "         [ 5.6305,  5.0570,  2.8032,  ..., -0.3397, -0.3397, -0.3397],\n",
            "         [ 5.8732,  3.1770,  1.9699,  ..., -0.4167, -0.4167, -0.4167]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.8065,  7.8456,  5.5974,  ..., -0.9532, -0.9532, -0.9532],\n",
            "         [ 4.4367,  8.2973,  5.8139,  ..., -0.9150, -0.9150, -0.9150],\n",
            "         [ 4.8101,  7.9528,  5.9129,  ..., -0.9379, -0.9379, -0.9379],\n",
            "         ...,\n",
            "         [ 3.8660,  4.5121,  3.1526,  ..., -0.8524, -0.8524, -0.8524],\n",
            "         [ 3.5419,  4.6185,  3.5343,  ..., -0.8899, -0.8899, -0.8899],\n",
            "         [ 3.3309,  4.6728,  3.0748,  ..., -0.8601, -0.8601, -0.8601]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 3.6017,  4.7653,  3.3880,  ..., -0.6771, -0.6771, -0.6771],\n",
            "         [ 4.7118,  3.9999,  3.0214,  ..., -0.5260, -0.5260, -0.5260],\n",
            "         [ 4.5569,  3.3943,  2.4655,  ..., -0.4956, -0.4956, -0.4956],\n",
            "         ...,\n",
            "         [ 4.4201,  3.1309,  1.2645,  ..., -0.3292, -0.3292, -0.3292],\n",
            "         [ 4.4365,  3.6722,  1.6553,  ..., -0.2617, -0.2617, -0.2617],\n",
            "         [ 5.0858,  3.6933,  1.4844,  ..., -0.2806, -0.2806, -0.2806]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 51, 20108])\n",
            "tensor([[[ 2.4160,  6.8787,  5.9411,  ..., -1.0575, -1.0575, -1.0575],\n",
            "         [ 1.8521,  7.9302,  6.1341,  ..., -0.9007, -0.9007, -0.9007],\n",
            "         [ 3.0644,  8.7423,  6.3898,  ..., -1.0034, -1.0034, -1.0034],\n",
            "         ...,\n",
            "         [ 1.2198,  6.0071,  5.1469,  ..., -0.8110, -0.8110, -0.8110],\n",
            "         [ 1.0845,  6.0678,  4.9021,  ..., -0.8339, -0.8339, -0.8339],\n",
            "         [ 2.6580,  5.7837,  4.9331,  ..., -0.8921, -0.8921, -0.8921]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 3.6345,  4.5626,  2.2893,  ..., -0.5238, -0.5238, -0.5238],\n",
            "         [ 3.4673,  4.3041,  2.0814,  ..., -0.4628, -0.4628, -0.4628],\n",
            "         [ 3.5960,  4.1222,  2.2169,  ..., -0.4275, -0.4275, -0.4275],\n",
            "         ...,\n",
            "         [ 5.5708,  2.3277,  1.6830,  ..., -0.4153, -0.4153, -0.4153],\n",
            "         [ 5.7527,  3.0911,  1.8249,  ..., -0.4087, -0.4087, -0.4087],\n",
            "         [ 6.0643,  3.5469,  2.4519,  ..., -0.4446, -0.4446, -0.4446]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 6.4047,  8.4138,  8.6075,  ..., -0.9797, -0.9797, -0.9797],\n",
            "         [ 5.2244,  7.9542,  7.0088,  ..., -1.0032, -1.0032, -1.0032],\n",
            "         [ 5.0172,  7.8396,  6.9489,  ..., -1.0782, -1.0782, -1.0782],\n",
            "         ...,\n",
            "         [ 5.9722,  5.3755,  4.6867,  ..., -0.9350, -0.9350, -0.9350],\n",
            "         [ 5.2983,  5.0711,  3.8750,  ..., -0.8888, -0.8888, -0.8888],\n",
            "         [ 4.6713,  4.7247,  3.9850,  ..., -0.8710, -0.8710, -0.8710]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 17, 20108])\n",
            "tensor([[[ 3.4642,  5.0752,  2.9522,  ..., -0.5137, -0.5137, -0.5137],\n",
            "         [ 4.4000,  4.3938,  2.5575,  ..., -0.4658, -0.4658, -0.4658],\n",
            "         [ 4.6116,  3.8707,  1.7646,  ..., -0.2296, -0.2296, -0.2296],\n",
            "         ...,\n",
            "         [ 5.6314,  0.6794, -1.0885,  ..., -0.2138, -0.2138, -0.2138],\n",
            "         [ 6.3596,  1.2687, -0.6921,  ..., -0.2688, -0.2688, -0.2688],\n",
            "         [ 5.9153,  0.4233, -1.1046,  ..., -0.2531, -0.2531, -0.2531]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 57, 20108])\n",
            "tensor([[[ 4.6620,  7.2450,  6.6824,  ..., -1.1365, -1.1365, -1.1365],\n",
            "         [ 4.7123,  6.4823,  5.3725,  ..., -0.9286, -0.9286, -0.9286],\n",
            "         [ 4.9358,  7.6109,  6.7026,  ..., -0.9763, -0.9763, -0.9763],\n",
            "         ...,\n",
            "         [ 5.7247,  3.7071,  4.4558,  ..., -0.9670, -0.9670, -0.9670],\n",
            "         [ 4.9491,  3.5259,  3.6376,  ..., -0.9327, -0.9327, -0.9327],\n",
            "         [ 5.1082,  3.6641,  3.2088,  ..., -0.9292, -0.9292, -0.9292]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 118, 20108])\n",
            "tensor([[[ 4.8987,  7.5953,  6.6375,  ..., -1.0701, -1.0701, -1.0701],\n",
            "         [ 5.7537,  8.2757,  7.7262,  ..., -1.0872, -1.0872, -1.0872],\n",
            "         [ 4.7814,  8.1130,  6.8717,  ..., -0.9873, -0.9873, -0.9873],\n",
            "         ...,\n",
            "         [ 5.4927,  5.4769,  5.2085,  ..., -0.8490, -0.8490, -0.8490],\n",
            "         [ 5.7418,  5.8426,  5.6263,  ..., -0.8886, -0.8886, -0.8886],\n",
            "         [ 5.9412,  5.5943,  5.2317,  ..., -0.8953, -0.8953, -0.8953]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 53, 20108])\n",
            "tensor([[[ 7.4229,  9.5357,  8.5638,  ..., -1.0464, -1.0464, -1.0464],\n",
            "         [ 7.5443,  9.6112,  8.8769,  ..., -0.8755, -0.8755, -0.8755],\n",
            "         [ 5.1758,  8.7032,  6.8673,  ..., -0.9425, -0.9425, -0.9425],\n",
            "         ...,\n",
            "         [ 4.1384,  5.5424,  5.1258,  ..., -0.8617, -0.8617, -0.8617],\n",
            "         [ 4.1608,  5.9020,  5.1984,  ..., -0.8562, -0.8562, -0.8562],\n",
            "         [ 3.8609,  5.6551,  4.7371,  ..., -0.8432, -0.8432, -0.8432]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 29, 20108])\n",
            "tensor([[[ 3.2811,  4.3364,  2.2034,  ..., -0.5198, -0.5198, -0.5198],\n",
            "         [ 2.6686,  4.4237,  2.5683,  ..., -0.4823, -0.4823, -0.4823],\n",
            "         [ 3.9567,  4.7560,  2.5176,  ..., -0.4137, -0.4137, -0.4137],\n",
            "         ...,\n",
            "         [ 9.2061,  5.0015,  3.7420,  ..., -0.6931, -0.6931, -0.6931],\n",
            "         [ 9.4379,  4.9447,  3.5301,  ..., -0.6546, -0.6546, -0.6546],\n",
            "         [ 9.4084,  4.4128,  3.2828,  ..., -0.6727, -0.6727, -0.6727]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 1.9872,  4.6084,  2.9114,  ..., -0.8657, -0.8657, -0.8657],\n",
            "         [ 3.4713,  6.5407,  5.1250,  ..., -0.9028, -0.9028, -0.9028],\n",
            "         [ 3.8534,  5.7875,  5.1787,  ..., -0.8497, -0.8497, -0.8497],\n",
            "         ...,\n",
            "         [ 5.0088,  7.0056,  7.4310,  ..., -0.9480, -0.9480, -0.9480],\n",
            "         [ 4.1438,  6.7836,  6.4649,  ..., -0.9378, -0.9378, -0.9378],\n",
            "         [ 4.6709,  6.2302,  6.1123,  ..., -0.9331, -0.9331, -0.9331]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 2.0495,  5.2780,  4.0476,  ..., -0.8028, -0.8028, -0.8028],\n",
            "         [ 1.7669,  5.5822,  4.1470,  ..., -0.8705, -0.8705, -0.8705],\n",
            "         [ 4.7483,  7.1176,  6.6281,  ..., -1.0145, -1.0145, -1.0145],\n",
            "         ...,\n",
            "         [ 2.6297,  8.9150,  6.6693,  ..., -0.7711, -0.7711, -0.7711],\n",
            "         [ 2.7151,  9.6778,  7.2243,  ..., -0.7291, -0.7291, -0.7291],\n",
            "         [ 2.7873,  9.4266,  7.1015,  ..., -0.7924, -0.7924, -0.7924]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 5.4374,  6.9378,  6.2334,  ..., -0.9264, -0.9264, -0.9264],\n",
            "         [ 4.5207,  4.7144,  3.2923,  ..., -0.6269, -0.6269, -0.6269],\n",
            "         [ 5.3728,  5.9274,  5.7999,  ..., -0.8396, -0.8396, -0.8396],\n",
            "         ...,\n",
            "         [ 3.1166,  5.9684,  7.0249,  ..., -0.8727, -0.8727, -0.8727],\n",
            "         [ 3.4615,  6.5345,  7.2004,  ..., -0.9263, -0.9263, -0.9263],\n",
            "         [ 3.2359,  6.0668,  6.6712,  ..., -0.9268, -0.9268, -0.9268]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 198, 20108])\n",
            "tensor([[[ 3.4231,  5.1953,  4.4678,  ..., -1.0736, -1.0736, -1.0736],\n",
            "         [ 2.2504,  5.2716,  4.3350,  ..., -1.0681, -1.0681, -1.0681],\n",
            "         [ 3.3230,  5.0635,  3.8007,  ..., -1.0945, -1.0945, -1.0945],\n",
            "         ...,\n",
            "         [ 1.4854,  3.3184,  3.3352,  ..., -0.8670, -0.8670, -0.8670],\n",
            "         [ 2.7957,  3.6786,  3.9445,  ..., -0.9348, -0.9348, -0.9348],\n",
            "         [ 2.0905,  3.3591,  3.7006,  ..., -0.9191, -0.9191, -0.9191]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 146, 20108])\n",
            "tensor([[[ 6.2726,  7.2701,  7.0292,  ..., -1.1422, -1.1422, -1.1422],\n",
            "         [ 4.8832,  5.7823,  5.8483,  ..., -1.0178, -1.0178, -1.0178],\n",
            "         [ 5.5985,  5.6971,  5.4830,  ..., -1.0468, -1.0468, -1.0468],\n",
            "         ...,\n",
            "         [ 6.4109,  5.2976,  4.0960,  ..., -0.9344, -0.9344, -0.9344],\n",
            "         [ 6.8600,  4.7437,  4.0836,  ..., -0.9349, -0.9349, -0.9349],\n",
            "         [ 8.1782,  5.4092,  4.6628,  ..., -0.8953, -0.8953, -0.8953]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 5.1731,  6.8196,  6.3462,  ..., -1.1850, -1.1850, -1.1850],\n",
            "         [ 4.9573,  6.8724,  6.4407,  ..., -1.1751, -1.1751, -1.1751],\n",
            "         [ 4.8450,  6.5963,  6.0964,  ..., -1.1601, -1.1601, -1.1601],\n",
            "         ...,\n",
            "         [ 4.6827,  5.0897,  5.2704,  ..., -0.9368, -0.9368, -0.9368],\n",
            "         [ 3.6471,  4.6159,  4.6854,  ..., -0.8928, -0.8928, -0.8928],\n",
            "         [ 4.1095,  4.0766,  4.5434,  ..., -0.8653, -0.8653, -0.8653]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 4.7332,  6.3498,  5.2734,  ..., -1.0202, -1.0202, -1.0202],\n",
            "         [ 4.8006,  6.8695,  5.8400,  ..., -1.0739, -1.0739, -1.0739],\n",
            "         [ 5.5639,  7.1322,  6.2174,  ..., -1.1159, -1.1159, -1.1159]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 2.5896,  5.3406,  3.8801,  ..., -1.0377, -1.0377, -1.0377],\n",
            "         [ 1.9952,  5.2005,  3.7069,  ..., -0.9959, -0.9959, -0.9959],\n",
            "         [ 2.3370,  5.3434,  3.3282,  ..., -0.9725, -0.9725, -0.9725],\n",
            "         ...,\n",
            "         [ 4.0015, 10.0766,  7.2639,  ..., -0.8330, -0.8330, -0.8330],\n",
            "         [ 4.3624,  9.1790,  7.3207,  ..., -0.8321, -0.8321, -0.8321],\n",
            "         [ 3.6641,  8.5089,  7.2495,  ..., -0.8381, -0.8381, -0.8381]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 5.4777,  4.8595,  3.1573,  ..., -0.5984, -0.5984, -0.5984],\n",
            "         [ 5.3982,  4.2976,  2.9735,  ..., -0.6226, -0.6226, -0.6226],\n",
            "         [ 5.4996,  3.4528,  2.3788,  ..., -0.4316, -0.4316, -0.4316],\n",
            "         ...,\n",
            "         [ 6.3323,  1.5983,  0.1097,  ..., -0.3599, -0.3599, -0.3599],\n",
            "         [ 5.4613,  1.4205, -0.0510,  ..., -0.3839, -0.3839, -0.3839],\n",
            "         [ 5.7052,  1.4882,  0.1292,  ..., -0.4165, -0.4165, -0.4165]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 3.8913,  5.4117,  4.6682,  ..., -1.0944, -1.0944, -1.0944],\n",
            "         [ 2.9081,  5.4030,  4.4279,  ..., -1.0830, -1.0830, -1.0830],\n",
            "         [ 2.7944,  5.7212,  4.3125,  ..., -1.0834, -1.0834, -1.0834],\n",
            "         ...,\n",
            "         [ 5.2398,  9.0463,  7.0973,  ..., -0.9674, -0.9674, -0.9674],\n",
            "         [ 5.5018,  8.8695,  6.9822,  ..., -0.9299, -0.9299, -0.9299],\n",
            "         [ 4.8154,  8.6718,  7.1966,  ..., -0.9897, -0.9897, -0.9897]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 36, 20108])\n",
            "tensor([[[ 5.2303,  7.8930,  7.2088,  ..., -1.0746, -1.0746, -1.0746],\n",
            "         [ 5.1849,  7.2576,  7.0977,  ..., -1.0656, -1.0656, -1.0656],\n",
            "         [ 4.8784,  6.8416,  7.2125,  ..., -1.0425, -1.0425, -1.0425],\n",
            "         ...,\n",
            "         [ 5.7198,  6.5107,  5.6515,  ..., -0.9364, -0.9364, -0.9364],\n",
            "         [ 5.7057,  6.7243,  5.4350,  ..., -0.9062, -0.9062, -0.9062],\n",
            "         [ 5.4853,  6.8176,  5.5512,  ..., -0.8806, -0.8806, -0.8806]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 6.7508,  8.7593,  8.7487,  ..., -1.0505, -1.0505, -1.0505],\n",
            "         [ 6.6475,  8.2521,  8.7614,  ..., -0.9759, -0.9759, -0.9759],\n",
            "         [ 5.4866,  7.9151,  7.8908,  ..., -0.9767, -0.9767, -0.9767],\n",
            "         ...,\n",
            "         [ 5.6069,  7.3159,  6.6761,  ..., -1.0211, -1.0211, -1.0211],\n",
            "         [ 5.8179,  8.1135,  7.2587,  ..., -1.0393, -1.0393, -1.0393],\n",
            "         [ 5.5692,  7.1676,  6.4688,  ..., -1.0919, -1.0919, -1.0919]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 90, 20108])\n",
            "tensor([[[ 4.9986,  6.6329,  5.7252,  ..., -1.0916, -1.0916, -1.0916],\n",
            "         [ 4.8753,  6.1395,  5.4467,  ..., -1.1071, -1.1071, -1.1071],\n",
            "         [ 3.8820,  6.3156,  5.2255,  ..., -1.1190, -1.1190, -1.1190],\n",
            "         ...,\n",
            "         [ 1.7523,  3.7628,  3.2738,  ..., -0.7722, -0.7722, -0.7722],\n",
            "         [ 1.9136,  3.1873,  2.3084,  ..., -0.8154, -0.8154, -0.8154],\n",
            "         [ 2.3852,  3.7164,  2.7593,  ..., -0.8947, -0.8947, -0.8947]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 263, 20108])\n",
            "tensor([[[ 2.4802,  4.9418,  3.4592,  ..., -1.0336, -1.0336, -1.0336],\n",
            "         [ 3.4847,  5.8031,  4.3938,  ..., -1.0553, -1.0553, -1.0553],\n",
            "         [ 2.9975,  5.4465,  3.6637,  ..., -1.0142, -1.0142, -1.0142],\n",
            "         ...,\n",
            "         [ 3.2466,  2.3967,  2.4669,  ..., -0.8499, -0.8499, -0.8499],\n",
            "         [ 3.5491,  2.9672,  2.9374,  ..., -0.9082, -0.9082, -0.9082],\n",
            "         [ 3.6560,  3.3420,  3.1697,  ..., -0.9271, -0.9271, -0.9271]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 57, 20108])\n",
            "tensor([[[ 5.9661,  6.6159,  6.0624,  ..., -0.9614, -0.9614, -0.9614],\n",
            "         [ 6.7273,  7.6295,  7.1908,  ..., -0.9338, -0.9338, -0.9338],\n",
            "         [ 7.4625,  8.3252,  7.8729,  ..., -1.0455, -1.0455, -1.0455],\n",
            "         ...,\n",
            "         [ 5.5738,  5.8615,  5.9800,  ..., -1.0437, -1.0437, -1.0437],\n",
            "         [ 5.4823,  6.0690,  5.8763,  ..., -1.0460, -1.0460, -1.0460],\n",
            "         [ 5.8984,  5.7863,  5.8552,  ..., -1.0496, -1.0496, -1.0496]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 7.5148,  7.9840,  8.3659,  ..., -1.0377, -1.0377, -1.0377],\n",
            "         [ 5.8750,  7.8688,  7.2924,  ..., -1.0431, -1.0431, -1.0431],\n",
            "         [ 6.2948,  7.6091,  7.6454,  ..., -1.0504, -1.0504, -1.0504],\n",
            "         ...,\n",
            "         [ 5.3779,  7.3277,  7.4931,  ..., -0.9460, -0.9460, -0.9460],\n",
            "         [ 5.8555,  7.9703,  7.5776,  ..., -0.9085, -0.9085, -0.9085],\n",
            "         [ 6.9034,  8.2497,  7.3507,  ..., -0.8614, -0.8614, -0.8614]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 115, 20108])\n",
            "tensor([[[ 3.2195,  5.8317,  4.6614,  ..., -0.8644, -0.8644, -0.8644],\n",
            "         [ 2.3186,  5.6446,  3.9836,  ..., -0.9691, -0.9691, -0.9691],\n",
            "         [ 1.7815,  5.0427,  3.6979,  ..., -0.8854, -0.8854, -0.8854],\n",
            "         ...,\n",
            "         [ 3.5431,  5.3009,  4.7915,  ..., -0.7006, -0.7006, -0.7006],\n",
            "         [ 3.5228,  4.9767,  4.6039,  ..., -0.6948, -0.6948, -0.6948],\n",
            "         [ 3.7677,  4.7382,  4.4442,  ..., -0.6988, -0.6988, -0.6988]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 4.7057,  7.0546,  5.8112,  ..., -1.0421, -1.0421, -1.0421],\n",
            "         [ 5.3313,  7.4293,  6.7094,  ..., -1.0950, -1.0950, -1.0950],\n",
            "         [ 6.1335,  6.5120,  5.6065,  ..., -0.9323, -0.9323, -0.9323],\n",
            "         ...,\n",
            "         [ 7.1952,  5.1418,  4.2704,  ..., -0.7497, -0.7497, -0.7497],\n",
            "         [ 7.1383,  4.8464,  3.9219,  ..., -0.7525, -0.7525, -0.7525],\n",
            "         [ 7.0189,  3.9511,  2.9129,  ..., -0.5988, -0.5988, -0.5988]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 156, 20108])\n",
            "tensor([[[ 2.7039,  6.3208,  4.8388,  ..., -1.0472, -1.0472, -1.0472],\n",
            "         [ 2.9337,  5.9271,  3.9841,  ..., -1.0314, -1.0314, -1.0314],\n",
            "         [ 2.2263,  5.3687,  3.8358,  ..., -1.0345, -1.0345, -1.0345],\n",
            "         ...,\n",
            "         [ 3.8706,  4.8210,  4.4086,  ..., -0.6974, -0.6974, -0.6974],\n",
            "         [ 3.7957,  4.8787,  4.7053,  ..., -0.6345, -0.6345, -0.6345],\n",
            "         [ 3.4900,  4.5670,  4.8509,  ..., -0.6191, -0.6191, -0.6191]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 5.5156,  5.5881,  3.5435,  ..., -0.4035, -0.4035, -0.4035],\n",
            "         [ 5.1145,  5.0634,  2.8425,  ..., -0.4002, -0.4002, -0.4002],\n",
            "         [ 4.8039,  4.8452,  2.0119,  ..., -0.3646, -0.3646, -0.3646],\n",
            "         ...,\n",
            "         [ 4.7174,  2.0926,  0.6061,  ..., -0.4547, -0.4547, -0.4547],\n",
            "         [ 4.7970,  2.6833,  0.7068,  ..., -0.5021, -0.5021, -0.5021],\n",
            "         [ 4.4871,  3.0479,  1.0161,  ..., -0.5039, -0.5039, -0.5039]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 17, 20108])\n",
            "tensor([[[ 2.4199,  5.8647,  4.7617,  ..., -0.9917, -0.9917, -0.9917],\n",
            "         [ 4.9631,  7.1495,  6.5863,  ..., -1.1183, -1.1183, -1.1183],\n",
            "         [ 5.5592,  6.3497,  6.5806,  ..., -1.1145, -1.1145, -1.1145],\n",
            "         ...,\n",
            "         [ 4.3562,  5.2365,  6.1531,  ..., -0.9800, -0.9800, -0.9800],\n",
            "         [ 3.9501,  5.3659,  5.9345,  ..., -0.9178, -0.9178, -0.9178],\n",
            "         [ 4.8496,  6.4740,  5.8228,  ..., -0.8398, -0.8398, -0.8398]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 4.7545,  6.2880,  6.1224,  ..., -1.1440, -1.1440, -1.1440],\n",
            "         [ 4.9479,  6.4206,  6.6262,  ..., -1.0720, -1.0720, -1.0720],\n",
            "         [ 5.6528,  7.0581,  7.0496,  ..., -1.1152, -1.1152, -1.1152],\n",
            "         ...,\n",
            "         [ 4.6362,  5.1557,  6.1296,  ..., -1.0547, -1.0547, -1.0547],\n",
            "         [ 4.0627,  4.9177,  6.1148,  ..., -0.9673, -0.9673, -0.9673],\n",
            "         [ 3.9617,  4.9326,  5.7510,  ..., -1.0472, -1.0472, -1.0472]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 4.5150,  7.5076,  6.2535,  ..., -1.1182, -1.1182, -1.1182],\n",
            "         [ 3.6178,  6.4149,  4.8665,  ..., -1.0664, -1.0664, -1.0664],\n",
            "         [ 2.8859,  7.1762,  5.5983,  ..., -0.8695, -0.8695, -0.8695],\n",
            "         ...,\n",
            "         [ 4.9359,  6.6818,  6.3188,  ..., -0.8460, -0.8460, -0.8460],\n",
            "         [ 4.4942,  6.1893,  5.7210,  ..., -0.8293, -0.8293, -0.8293],\n",
            "         [ 3.9999,  6.4082,  5.8512,  ..., -0.7697, -0.7697, -0.7697]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 63, 20108])\n",
            "tensor([[[ 7.5351,  8.1378,  7.6725,  ..., -1.1542, -1.1542, -1.1542],\n",
            "         [ 7.0349,  8.0186,  7.4901,  ..., -1.1639, -1.1639, -1.1639],\n",
            "         [ 7.0011,  8.0652,  7.6606,  ..., -1.1296, -1.1296, -1.1296],\n",
            "         ...,\n",
            "         [ 6.4661,  7.0678,  6.8602,  ..., -0.9770, -0.9770, -0.9770],\n",
            "         [ 6.3478,  6.3766,  6.4270,  ..., -0.9522, -0.9522, -0.9522],\n",
            "         [ 6.1794,  6.7757,  6.5577,  ..., -1.0077, -1.0077, -1.0077]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 2.4814,  5.6900,  4.4232,  ..., -1.0584, -1.0584, -1.0584],\n",
            "         [ 2.7056,  4.6675,  3.3763,  ..., -1.0530, -1.0530, -1.0530],\n",
            "         [ 2.1477,  5.6605,  3.6701,  ..., -0.9745, -0.9745, -0.9745],\n",
            "         [ 1.7625,  6.5529,  4.5422,  ..., -0.9329, -0.9329, -0.9329],\n",
            "         [ 1.1565,  8.5525,  4.6963,  ..., -0.7653, -0.7653, -0.7653]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 4.9751,  6.6960,  3.8107,  ..., -0.6314, -0.6314, -0.6314],\n",
            "         [ 3.9798,  5.2460,  3.1497,  ..., -0.5326, -0.5326, -0.5326],\n",
            "         [ 4.2115,  4.8314,  2.9032,  ..., -0.4829, -0.4829, -0.4829],\n",
            "         ...,\n",
            "         [ 6.8513,  1.9919,  0.1419,  ..., -0.3857, -0.3857, -0.3857],\n",
            "         [ 6.6898,  1.7733,  0.1471,  ..., -0.2886, -0.2886, -0.2886],\n",
            "         [ 6.3878,  1.2276, -0.4638,  ..., -0.3484, -0.3484, -0.3484]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 99, 20108])\n",
            "tensor([[[ 4.2873,  4.8831,  4.1683,  ..., -1.0839, -1.0839, -1.0839],\n",
            "         [ 3.9829,  5.4500,  4.4005,  ..., -1.1256, -1.1256, -1.1256],\n",
            "         [ 3.9217,  4.9589,  3.8996,  ..., -1.0218, -1.0218, -1.0218],\n",
            "         ...,\n",
            "         [ 2.3503,  3.5281,  3.5394,  ..., -0.6709, -0.6709, -0.6709],\n",
            "         [ 3.0989,  3.9286,  4.0440,  ..., -0.7857, -0.7857, -0.7857],\n",
            "         [ 2.8143,  3.3238,  3.1373,  ..., -0.6798, -0.6798, -0.6798]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 6.0324,  7.4316,  6.8107,  ..., -1.0983, -1.0983, -1.0983],\n",
            "         [ 3.0562,  6.3965,  5.3844,  ..., -0.9995, -0.9995, -0.9995],\n",
            "         [ 2.8743,  5.7223,  4.6564,  ..., -0.8850, -0.8850, -0.8850],\n",
            "         ...,\n",
            "         [ 1.5759,  4.7537,  4.0401,  ..., -0.7654, -0.7654, -0.7654],\n",
            "         [ 2.2634,  5.1487,  4.4014,  ..., -0.7691, -0.7691, -0.7691],\n",
            "         [ 1.5689,  5.4704,  4.5959,  ..., -0.7837, -0.7837, -0.7837]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 43, 20108])\n",
            "tensor([[[ 4.9708,  6.0927,  3.6653,  ..., -0.5965, -0.5965, -0.5965],\n",
            "         [ 4.1128,  5.0613,  2.5397,  ..., -0.4821, -0.4821, -0.4821],\n",
            "         [ 3.9194,  4.5209,  2.8579,  ..., -0.4929, -0.4929, -0.4929],\n",
            "         ...,\n",
            "         [ 4.5851, -0.3367, -1.6557,  ..., -0.3850, -0.3850, -0.3850],\n",
            "         [ 5.3154, -0.4257, -1.7345,  ..., -0.3621, -0.3621, -0.3621],\n",
            "         [ 5.4187, -0.5011, -1.7878,  ..., -0.3754, -0.3754, -0.3754]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 4.8004,  6.2143,  3.7148,  ..., -0.6396, -0.6396, -0.6396],\n",
            "         [ 4.4855,  5.1280,  2.5026,  ..., -0.4903, -0.4903, -0.4903],\n",
            "         [ 5.4929,  5.6453,  3.2464,  ..., -0.4701, -0.4701, -0.4701],\n",
            "         ...,\n",
            "         [ 6.6039,  3.8396,  1.3572,  ..., -0.3645, -0.3645, -0.3645],\n",
            "         [ 6.4168,  3.1789,  1.4480,  ..., -0.3547, -0.3547, -0.3547],\n",
            "         [ 5.9120,  3.5815,  1.4943,  ..., -0.4540, -0.4540, -0.4540]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 4.8491,  6.5971,  5.4275,  ..., -1.1180, -1.1180, -1.1180],\n",
            "         [ 5.3135,  6.8163,  6.5276,  ..., -1.1477, -1.1477, -1.1477],\n",
            "         [ 4.3211,  6.6919,  6.5216,  ..., -1.0140, -1.0140, -1.0140],\n",
            "         ...,\n",
            "         [ 6.2099,  7.1944,  7.2346,  ..., -0.9202, -0.9202, -0.9202],\n",
            "         [ 6.4724,  7.1351,  7.1946,  ..., -0.9616, -0.9616, -0.9616],\n",
            "         [ 6.3118,  6.8514,  7.0979,  ..., -1.0050, -1.0050, -1.0050]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 110, 20108])\n",
            "tensor([[[ 2.0848,  4.9299,  4.0873,  ..., -0.9602, -0.9602, -0.9602],\n",
            "         [ 4.2645,  8.0161,  6.1646,  ..., -0.9635, -0.9635, -0.9635],\n",
            "         [ 3.0323,  7.5148,  5.0359,  ..., -0.7671, -0.7671, -0.7671],\n",
            "         ...,\n",
            "         [ 2.6113,  3.5445,  1.4348,  ..., -0.4669, -0.4669, -0.4669],\n",
            "         [ 1.8197,  3.3199,  1.4833,  ..., -0.4237, -0.4237, -0.4237],\n",
            "         [ 2.1038,  3.6850,  1.4031,  ..., -0.4638, -0.4638, -0.4638]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 34, 20108])\n",
            "tensor([[[ 2.0136,  4.3249,  2.9486,  ..., -1.0132, -1.0132, -1.0132],\n",
            "         [ 2.1595,  5.4306,  3.5917,  ..., -1.0086, -1.0086, -1.0086],\n",
            "         [ 2.4272,  5.5191,  3.5441,  ..., -1.0618, -1.0618, -1.0618],\n",
            "         ...,\n",
            "         [ 4.0759,  9.1919,  6.9547,  ..., -0.7709, -0.7709, -0.7709],\n",
            "         [ 4.5112,  9.6060,  7.4924,  ..., -0.7736, -0.7736, -0.7736],\n",
            "         [ 4.7005,  9.2087,  7.6996,  ..., -0.7695, -0.7695, -0.7695]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 4.6314,  7.3193,  6.2547,  ..., -1.1141, -1.1141, -1.1141],\n",
            "         [ 3.8684,  6.6725,  5.5694,  ..., -1.0367, -1.0367, -1.0367],\n",
            "         [ 4.9000,  6.9557,  5.7381,  ..., -1.0171, -1.0171, -1.0171],\n",
            "         ...,\n",
            "         [ 6.3525,  7.9431,  6.7055,  ..., -1.0558, -1.0558, -1.0558],\n",
            "         [ 5.2454,  7.2698,  6.8282,  ..., -1.0397, -1.0397, -1.0397],\n",
            "         [ 5.0304,  7.2761,  6.7035,  ..., -0.9934, -0.9934, -0.9934]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 106, 20108])\n",
            "tensor([[[ 6.6587,  7.7536,  7.0440,  ..., -1.0835, -1.0835, -1.0835],\n",
            "         [ 4.6247,  6.8115,  5.5830,  ..., -0.9753, -0.9753, -0.9753],\n",
            "         [ 6.0721,  7.1001,  6.3421,  ..., -0.9837, -0.9837, -0.9837],\n",
            "         ...,\n",
            "         [ 6.4132,  4.3960,  3.1987,  ..., -0.8006, -0.8006, -0.8006],\n",
            "         [ 6.2152,  5.6005,  3.9177,  ..., -0.8133, -0.8133, -0.8133],\n",
            "         [ 5.2193,  6.5338,  4.1410,  ..., -0.8172, -0.8172, -0.8172]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 42, 20108])\n",
            "tensor([[[ 4.8731,  6.4154,  6.2050,  ..., -1.1505, -1.1505, -1.1505],\n",
            "         [ 4.8202,  6.6024,  7.0596,  ..., -1.1272, -1.1272, -1.1272],\n",
            "         [ 4.7420,  6.8998,  7.9748,  ..., -1.1054, -1.1054, -1.1054],\n",
            "         ...,\n",
            "         [ 5.3846,  7.5476,  6.7920,  ..., -0.9086, -0.9086, -0.9086],\n",
            "         [ 5.6374,  7.3535,  6.7825,  ..., -0.9539, -0.9539, -0.9539],\n",
            "         [ 4.6295,  6.6444,  6.1593,  ..., -0.8857, -0.8857, -0.8857]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 52, 20108])\n",
            "tensor([[[ 3.5857,  5.7640,  4.4936,  ..., -1.0470, -1.0470, -1.0470],\n",
            "         [ 3.7165,  4.8500,  4.0112,  ..., -1.0662, -1.0662, -1.0662],\n",
            "         [ 4.4857,  7.4319,  6.2916,  ..., -1.1307, -1.1307, -1.1307],\n",
            "         ...,\n",
            "         [ 7.4797,  8.2804,  8.0374,  ..., -0.8971, -0.8971, -0.8971],\n",
            "         [ 7.8668,  8.3066,  8.0719,  ..., -0.9282, -0.9282, -0.9282],\n",
            "         [ 6.4254,  7.8421,  6.9989,  ..., -0.8969, -0.8969, -0.8969]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 118, 20108])\n",
            "tensor([[[ 3.2167,  5.7226,  4.6456,  ..., -1.0847, -1.0847, -1.0847],\n",
            "         [ 3.5222,  6.3773,  4.9267,  ..., -1.1204, -1.1204, -1.1204],\n",
            "         [ 4.3513,  6.7804,  5.4561,  ..., -1.1335, -1.1335, -1.1335],\n",
            "         ...,\n",
            "         [ 5.1549,  5.0468,  4.8599,  ..., -0.8853, -0.8853, -0.8853],\n",
            "         [ 5.2852,  5.5732,  5.6123,  ..., -0.8951, -0.8951, -0.8951],\n",
            "         [ 5.4334,  5.2760,  5.2003,  ..., -0.8510, -0.8510, -0.8510]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 5.9353,  7.4931,  6.9553,  ..., -1.0579, -1.0579, -1.0579],\n",
            "         [ 6.0895,  7.0108,  6.7653,  ..., -1.0851, -1.0851, -1.0851],\n",
            "         [ 6.5308,  7.7490,  7.6190,  ..., -1.0173, -1.0173, -1.0173],\n",
            "         ...,\n",
            "         [ 6.9045,  8.1505,  7.9409,  ..., -1.0909, -1.0909, -1.0909],\n",
            "         [ 7.2951,  8.3601,  8.0346,  ..., -1.1464, -1.1464, -1.1464],\n",
            "         [ 7.6358,  8.3559,  7.8436,  ..., -1.0780, -1.0780, -1.0780]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 136, 20108])\n",
            "tensor([[[ 2.4618,  3.7262,  3.0845,  ..., -1.0024, -1.0024, -1.0024],\n",
            "         [ 1.2448,  4.9363,  3.0426,  ..., -0.8034, -0.8034, -0.8034],\n",
            "         [ 2.8560,  7.0472,  5.1169,  ..., -0.8295, -0.8295, -0.8295],\n",
            "         ...,\n",
            "         [ 5.1869,  5.1668,  4.7673,  ..., -0.9853, -0.9853, -0.9853],\n",
            "         [ 5.4765,  5.6358,  4.8516,  ..., -0.9852, -0.9852, -0.9852],\n",
            "         [ 4.9973,  5.7543,  4.7330,  ..., -1.0107, -1.0107, -1.0107]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 17, 20108])\n",
            "tensor([[[ 3.9157,  4.7422,  2.5547,  ..., -0.5324, -0.5324, -0.5324],\n",
            "         [ 3.4348,  4.5962,  2.7718,  ..., -0.5030, -0.5030, -0.5030],\n",
            "         [ 2.9789,  4.8430,  2.8130,  ..., -0.4378, -0.4378, -0.4378],\n",
            "         ...,\n",
            "         [ 5.2359,  1.2763, -0.6340,  ..., -0.2256, -0.2256, -0.2256],\n",
            "         [ 4.5739,  0.9397, -1.0475,  ..., -0.1276, -0.1276, -0.1276],\n",
            "         [ 4.7993,  0.6264, -1.1647,  ..., -0.0952, -0.0952, -0.0952]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 150, 20108])\n",
            "tensor([[[ 3.8108,  5.1831,  3.8840,  ..., -1.0642, -1.0642, -1.0642],\n",
            "         [ 3.7736,  5.8010,  4.1785,  ..., -1.0077, -1.0077, -1.0077],\n",
            "         [ 3.9991,  6.2607,  4.2509,  ..., -0.9556, -0.9556, -0.9556],\n",
            "         ...,\n",
            "         [ 6.4484,  5.7720,  5.7880,  ..., -0.9516, -0.9516, -0.9516],\n",
            "         [ 6.1561,  5.3806,  5.6007,  ..., -0.9593, -0.9593, -0.9593],\n",
            "         [ 6.9505,  5.9727,  5.9975,  ..., -0.9692, -0.9692, -0.9692]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 5.2840,  5.8756,  3.3143,  ..., -0.5916, -0.5916, -0.5916],\n",
            "         [ 4.3607,  4.6710,  2.8077,  ..., -0.4793, -0.4793, -0.4793],\n",
            "         [ 3.3948,  4.9990,  2.6845,  ..., -0.4633, -0.4633, -0.4633],\n",
            "         [ 5.5133,  3.7122,  1.3546,  ..., -0.3433, -0.3433, -0.3433]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 50, 20108])\n",
            "tensor([[[ 5.9960,  6.9347,  6.9777,  ..., -1.1048, -1.1048, -1.1048],\n",
            "         [ 5.2361,  7.0686,  7.2047,  ..., -1.1159, -1.1159, -1.1159],\n",
            "         [ 5.8364,  6.2558,  6.5848,  ..., -1.0986, -1.0986, -1.0986],\n",
            "         ...,\n",
            "         [ 5.5963,  5.6364,  4.9161,  ..., -0.8582, -0.8582, -0.8582],\n",
            "         [ 5.2428,  5.6810,  4.4624,  ..., -0.7941, -0.7941, -0.7941],\n",
            "         [ 6.6539,  5.6553,  5.0779,  ..., -0.8928, -0.8928, -0.8928]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 39, 20108])\n",
            "tensor([[[ 2.7398,  6.0064,  4.4309,  ..., -1.0251, -1.0251, -1.0251],\n",
            "         [ 4.8709,  6.7891,  6.0005,  ..., -1.1080, -1.1080, -1.1080],\n",
            "         [ 4.0084,  6.0211,  5.3663,  ..., -1.0439, -1.0439, -1.0439],\n",
            "         ...,\n",
            "         [ 6.5780,  6.3553,  6.5058,  ..., -1.0982, -1.0982, -1.0982],\n",
            "         [ 6.7963,  6.4675,  6.5912,  ..., -1.1207, -1.1207, -1.1207],\n",
            "         [ 6.3683,  5.7523,  5.9658,  ..., -1.0821, -1.0821, -1.0821]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 6.7741,  8.8871,  9.3016,  ..., -1.0911, -1.0911, -1.0911],\n",
            "         [ 6.7999,  9.4643,  9.2227,  ..., -1.0473, -1.0473, -1.0473],\n",
            "         [ 6.0040,  8.4778,  8.0377,  ..., -1.1335, -1.1335, -1.1335],\n",
            "         ...,\n",
            "         [ 7.0410,  8.8675,  8.2682,  ..., -1.0756, -1.0756, -1.0756],\n",
            "         [ 6.1848,  9.0646,  8.5238,  ..., -1.0063, -1.0063, -1.0063],\n",
            "         [ 6.4278,  9.0730,  7.6525,  ..., -1.0154, -1.0154, -1.0154]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 424, 20108])\n",
            "tensor([[[ 6.5090,  8.6150,  8.1881,  ..., -1.0191, -1.0191, -1.0191],\n",
            "         [ 6.8478,  8.0059,  8.2935,  ..., -0.9995, -0.9995, -0.9995],\n",
            "         [ 7.2620,  8.7442,  8.4375,  ..., -1.0349, -1.0349, -1.0349],\n",
            "         ...,\n",
            "         [ 2.0971,  3.1271,  2.1911,  ..., -0.5399, -0.5399, -0.5399],\n",
            "         [ 2.1978,  3.2748,  2.0524,  ..., -0.5480, -0.5480, -0.5480],\n",
            "         [ 1.7712,  3.4243,  1.8393,  ..., -0.5173, -0.5173, -0.5173]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 6.1435,  5.2271,  3.6818,  ..., -0.8266, -0.8266, -0.8266],\n",
            "         [ 6.5361,  6.0511,  4.5177,  ..., -0.8716, -0.8716, -0.8716],\n",
            "         [ 5.6371,  4.8708,  3.0313,  ..., -0.6926, -0.6926, -0.6926],\n",
            "         ...,\n",
            "         [ 5.9221,  3.9493,  2.1637,  ..., -0.6114, -0.6114, -0.6114],\n",
            "         [ 5.4205,  3.4216,  1.8091,  ..., -0.5962, -0.5962, -0.5962],\n",
            "         [ 6.1231,  3.6404,  1.9492,  ..., -0.5879, -0.5879, -0.5879]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.4916,  6.7910,  5.3896,  ..., -0.9540, -0.9540, -0.9540],\n",
            "         [ 4.1511,  6.9149,  5.9681,  ..., -1.0639, -1.0639, -1.0639],\n",
            "         [ 4.9304,  6.9994,  6.3430,  ..., -1.0534, -1.0534, -1.0534],\n",
            "         ...,\n",
            "         [ 5.1412,  7.0291,  6.5021,  ..., -1.0709, -1.0709, -1.0709],\n",
            "         [ 5.5072,  7.3946,  6.9212,  ..., -1.0537, -1.0537, -1.0537],\n",
            "         [ 5.1406,  6.9340,  6.6559,  ..., -1.0628, -1.0628, -1.0628]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 43, 20108])\n",
            "tensor([[[ 4.9968,  6.6133,  4.1563,  ..., -0.6105, -0.6105, -0.6105],\n",
            "         [ 4.8214,  5.0825,  3.4809,  ..., -0.5957, -0.5957, -0.5957],\n",
            "         [ 6.1493,  5.0279,  3.8020,  ..., -0.7217, -0.7217, -0.7217],\n",
            "         ...,\n",
            "         [ 5.2702,  5.9381,  6.5158,  ..., -0.7385, -0.7385, -0.7385],\n",
            "         [ 4.7256,  6.2306,  6.3415,  ..., -0.6468, -0.6468, -0.6468],\n",
            "         [ 4.6193,  6.3917,  6.6537,  ..., -0.6556, -0.6556, -0.6556]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.1323,  5.0637,  2.3751,  ..., -0.5099, -0.5099, -0.5099],\n",
            "         [ 3.6859,  4.8040,  2.6744,  ..., -0.4698, -0.4698, -0.4698],\n",
            "         [ 2.7048,  4.6146,  2.4693,  ..., -0.4239, -0.4239, -0.4239],\n",
            "         ...,\n",
            "         [ 6.0396,  3.8833,  2.0476,  ..., -0.3084, -0.3084, -0.3084],\n",
            "         [ 5.8324,  3.5786,  2.1125,  ..., -0.3234, -0.3234, -0.3234],\n",
            "         [ 5.8763,  3.4634,  1.6739,  ..., -0.2757, -0.2757, -0.2757]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 4.3257,  6.4619,  5.8957,  ..., -1.0631, -1.0631, -1.0631],\n",
            "         [ 4.3672,  6.7949,  6.3288,  ..., -1.0139, -1.0139, -1.0139],\n",
            "         [ 4.1023,  7.0229,  6.7934,  ..., -0.9948, -0.9948, -0.9948],\n",
            "         ...,\n",
            "         [ 4.2028,  6.7931,  5.5024,  ..., -0.8168, -0.8168, -0.8168],\n",
            "         [ 4.0030,  6.3917,  5.0766,  ..., -0.8467, -0.8467, -0.8467],\n",
            "         [ 4.0380,  5.9464,  4.7756,  ..., -0.8384, -0.8384, -0.8384]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 487, 20108])\n",
            "tensor([[[ 4.2098,  5.7224,  5.0435,  ..., -0.9377, -0.9377, -0.9377],\n",
            "         [ 5.6667,  6.8820,  6.9065,  ..., -1.0793, -1.0793, -1.0793],\n",
            "         [ 5.7229,  6.9378,  7.6141,  ..., -1.0308, -1.0308, -1.0308],\n",
            "         ...,\n",
            "         [ 0.1566,  2.8537,  1.7967,  ..., -0.4898, -0.4898, -0.4898],\n",
            "         [ 0.0691,  2.4156,  1.5523,  ..., -0.4977, -0.4977, -0.4977],\n",
            "         [ 0.1786,  2.4759,  1.6848,  ..., -0.4980, -0.4980, -0.4980]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 90, 20108])\n",
            "tensor([[[ 4.4624,  7.0936,  6.5926,  ..., -1.1177, -1.1177, -1.1177],\n",
            "         [ 3.7621,  7.2617,  5.6870,  ..., -1.1552, -1.1552, -1.1552],\n",
            "         [ 5.7804,  8.3295,  7.1799,  ..., -1.2050, -1.2050, -1.2050],\n",
            "         ...,\n",
            "         [ 3.5549,  5.5021,  4.1411,  ..., -0.8365, -0.8365, -0.8365],\n",
            "         [ 3.9561,  7.6377,  4.9116,  ..., -0.8597, -0.8597, -0.8597],\n",
            "         [ 3.4276,  7.1133,  4.3684,  ..., -0.8177, -0.8177, -0.8177]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 90, 20108])\n",
            "tensor([[[ 2.9159,  6.0318,  4.3300,  ..., -1.0839, -1.0839, -1.0839],\n",
            "         [ 4.1243,  6.1448,  5.7546,  ..., -1.1036, -1.1036, -1.1036],\n",
            "         [ 4.2541,  7.5268,  6.2233,  ..., -0.9937, -0.9937, -0.9937],\n",
            "         ...,\n",
            "         [ 3.6223,  3.1550,  3.3261,  ..., -0.7905, -0.7905, -0.7905],\n",
            "         [ 3.3041,  3.0220,  3.4065,  ..., -0.7907, -0.7907, -0.7907],\n",
            "         [ 3.0846,  2.7106,  2.8686,  ..., -0.6959, -0.6959, -0.6959]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 1.7637,  4.1069,  3.2416,  ..., -0.9960, -0.9960, -0.9960],\n",
            "         [ 1.0754,  4.6579,  3.4412,  ..., -0.8475, -0.8475, -0.8475],\n",
            "         [ 3.6230,  8.0384,  6.3724,  ..., -1.0501, -1.0501, -1.0501],\n",
            "         ...,\n",
            "         [ 1.8162,  6.4353,  6.3497,  ..., -0.8375, -0.8375, -0.8375],\n",
            "         [ 1.6886,  6.7293,  6.2714,  ..., -0.7785, -0.7785, -0.7785],\n",
            "         [ 2.0738,  6.0550,  6.2702,  ..., -0.7663, -0.7663, -0.7663]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 97, 20108])\n",
            "tensor([[[ 6.0706,  8.4775,  6.8440,  ..., -1.0947, -1.0947, -1.0947],\n",
            "         [ 4.8843,  7.1561,  5.6068,  ..., -1.0472, -1.0472, -1.0472],\n",
            "         [ 4.9334,  6.8096,  5.0428,  ..., -1.0474, -1.0474, -1.0474],\n",
            "         ...,\n",
            "         [ 5.6680,  6.5988,  6.2235,  ..., -0.8669, -0.8669, -0.8669],\n",
            "         [ 5.3415,  6.6495,  5.9855,  ..., -0.8642, -0.8642, -0.8642],\n",
            "         [ 4.7478,  5.9847,  5.4584,  ..., -0.8072, -0.8072, -0.8072]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 2.2222,  3.7775,  3.1813,  ..., -0.9437, -0.9437, -0.9437],\n",
            "         [ 4.6421,  6.0834,  5.7984,  ..., -1.0707, -1.0707, -1.0707],\n",
            "         [ 4.9410,  6.8416,  7.0397,  ..., -1.0739, -1.0739, -1.0739],\n",
            "         ...,\n",
            "         [ 3.9241,  4.4912,  5.8851,  ..., -0.9173, -0.9173, -0.9173],\n",
            "         [ 3.4250,  4.4313,  5.4976,  ..., -0.9101, -0.9101, -0.9101],\n",
            "         [ 2.9631,  3.9407,  4.5583,  ..., -0.7888, -0.7888, -0.7888]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 111, 20108])\n",
            "tensor([[[ 8.1501,  8.9024,  8.2827,  ..., -1.0350, -1.0350, -1.0350],\n",
            "         [ 7.9794,  9.4137,  8.6102,  ..., -0.9871, -0.9871, -0.9871],\n",
            "         [ 7.3424,  9.2384,  9.6817,  ..., -0.9562, -0.9562, -0.9562],\n",
            "         ...,\n",
            "         [ 3.4355,  3.7088,  3.4636,  ..., -0.8346, -0.8346, -0.8346],\n",
            "         [ 3.3500,  3.5899,  3.3565,  ..., -0.8273, -0.8273, -0.8273],\n",
            "         [ 2.9593,  3.2509,  2.8880,  ..., -0.7768, -0.7768, -0.7768]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 2.9420,  6.6334,  4.7655,  ..., -1.0183, -1.0183, -1.0183],\n",
            "         [ 2.8889,  6.1395,  4.2030,  ..., -1.0091, -1.0091, -1.0091],\n",
            "         [ 2.6002,  6.8723,  4.0911,  ..., -1.0390, -1.0390, -1.0390],\n",
            "         ...,\n",
            "         [ 3.1815,  6.9005,  5.2241,  ..., -0.8812, -0.8812, -0.8812],\n",
            "         [ 3.3157,  7.1838,  5.1992,  ..., -1.0104, -1.0104, -1.0104],\n",
            "         [ 3.2726,  7.4074,  5.9694,  ..., -0.9447, -0.9447, -0.9447]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 5.0771,  6.4849,  5.5162,  ..., -1.1062, -1.1062, -1.1062],\n",
            "         [ 4.3937,  6.0236,  5.3148,  ..., -0.9659, -0.9659, -0.9659],\n",
            "         [ 3.7256,  6.9168,  5.2950,  ..., -0.8234, -0.8234, -0.8234],\n",
            "         ...,\n",
            "         [ 6.9532,  8.7627,  7.5874,  ..., -1.0289, -1.0289, -1.0289],\n",
            "         [ 7.4231,  9.0172,  7.9292,  ..., -1.0441, -1.0441, -1.0441],\n",
            "         [ 7.8520,  8.1822,  7.5947,  ..., -1.0645, -1.0645, -1.0645]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 374, 20108])\n",
            "tensor([[[ 7.3167,  7.7656,  7.7620,  ..., -1.0426, -1.0426, -1.0426],\n",
            "         [ 5.8571,  7.3663,  7.1891,  ..., -1.0953, -1.0953, -1.0953],\n",
            "         [ 5.6576,  6.9862,  7.2046,  ..., -1.0755, -1.0755, -1.0755],\n",
            "         ...,\n",
            "         [ 3.2246,  2.3139,  2.8326,  ..., -0.6167, -0.6167, -0.6167],\n",
            "         [ 3.9342,  3.7293,  4.0107,  ..., -0.7003, -0.7003, -0.7003],\n",
            "         [ 3.0351,  3.8151,  3.7962,  ..., -0.6131, -0.6131, -0.6131]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 6.9682,  8.1851,  7.3434,  ..., -1.1387, -1.1387, -1.1387],\n",
            "         [ 5.3098,  7.1748,  6.7289,  ..., -1.1634, -1.1634, -1.1634],\n",
            "         [ 5.0122,  7.3253,  8.0734,  ..., -1.1327, -1.1327, -1.1327],\n",
            "         ...,\n",
            "         [ 3.6575,  5.0961,  6.0279,  ..., -0.9716, -0.9716, -0.9716],\n",
            "         [ 4.3121,  4.6452,  5.9124,  ..., -0.9384, -0.9384, -0.9384],\n",
            "         [ 3.8887,  4.8591,  5.9628,  ..., -1.0114, -1.0114, -1.0114]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 341, 20108])\n",
            "tensor([[[ 2.4534,  5.3213,  4.1268,  ..., -1.0372, -1.0372, -1.0372],\n",
            "         [ 3.1513,  6.0299,  4.7770,  ..., -1.0567, -1.0567, -1.0567],\n",
            "         [ 4.4634,  6.6953,  5.6308,  ..., -0.9806, -0.9806, -0.9806],\n",
            "         ...,\n",
            "         [ 2.2929,  3.7631,  2.9124,  ..., -0.5029, -0.5029, -0.5029],\n",
            "         [ 2.2687,  3.3783,  2.6638,  ..., -0.5053, -0.5053, -0.5053],\n",
            "         [ 2.6122,  4.0411,  3.1744,  ..., -0.4979, -0.4979, -0.4979]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 87, 20108])\n",
            "tensor([[[ 2.5261,  5.1555,  4.3800,  ..., -1.0401, -1.0401, -1.0401],\n",
            "         [ 2.1754,  5.4684,  4.5004,  ..., -0.9973, -0.9973, -0.9973],\n",
            "         [ 1.7021,  6.3884,  4.8766,  ..., -0.8237, -0.8237, -0.8237],\n",
            "         ...,\n",
            "         [ 4.0102,  6.2422,  4.7408,  ..., -0.6925, -0.6925, -0.6925],\n",
            "         [ 4.1611,  6.4238,  4.8942,  ..., -0.7106, -0.7106, -0.7106],\n",
            "         [ 3.3925,  6.0842,  4.7386,  ..., -0.6754, -0.6754, -0.6754]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 2.9861,  5.6897,  4.8897,  ..., -1.0281, -1.0281, -1.0281],\n",
            "         [ 2.2105,  5.7546,  4.5479,  ..., -1.0044, -1.0044, -1.0044],\n",
            "         [ 4.2103,  7.3530,  5.5156,  ..., -0.9384, -0.9384, -0.9384],\n",
            "         ...,\n",
            "         [ 5.9472,  8.0052,  6.5404,  ..., -0.9453, -0.9453, -0.9453],\n",
            "         [ 5.4115,  7.4581,  6.0265,  ..., -0.8985, -0.8985, -0.8985],\n",
            "         [ 5.4595,  7.1124,  5.7566,  ..., -0.9256, -0.9256, -0.9256]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 4.5831,  5.5635,  3.2862,  ..., -0.6811, -0.6811, -0.6811],\n",
            "         [ 4.6033,  4.8130,  3.1528,  ..., -0.5449, -0.5449, -0.5449],\n",
            "         [ 3.7361,  4.4169,  2.3348,  ..., -0.4903, -0.4903, -0.4903],\n",
            "         ...,\n",
            "         [ 3.9148,  4.3584,  2.6159,  ..., -0.2113, -0.2113, -0.2113],\n",
            "         [ 4.6891,  4.6420,  3.0489,  ..., -0.3165, -0.3165, -0.3165],\n",
            "         [ 5.0071,  4.3639,  2.4103,  ..., -0.3379, -0.3379, -0.3379]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 5.5949,  6.1396,  3.8872,  ..., -0.4163, -0.4163, -0.4163],\n",
            "         [ 5.4694,  3.0118,  1.3242,  ..., -0.3826, -0.3826, -0.3826],\n",
            "         [ 6.0837,  3.7574,  2.0049,  ..., -0.3937, -0.3937, -0.3937],\n",
            "         ...,\n",
            "         [ 4.4859,  3.0560,  1.3523,  ..., -0.3379, -0.3379, -0.3379],\n",
            "         [ 4.0349,  2.6143,  0.5907,  ..., -0.3856, -0.3856, -0.3856],\n",
            "         [ 6.3990,  3.1575,  1.4534,  ..., -0.4178, -0.4178, -0.4178]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 6.3084,  6.6457,  4.4110,  ..., -0.5785, -0.5785, -0.5785],\n",
            "         [ 6.7835,  5.4322,  3.0789,  ..., -0.6015, -0.6015, -0.6015],\n",
            "         [ 6.3594,  3.7769,  1.5269,  ..., -0.4765, -0.4765, -0.4765],\n",
            "         ...,\n",
            "         [ 5.7593,  2.7748,  0.4456,  ..., -0.4763, -0.4763, -0.4763],\n",
            "         [ 5.9485,  3.1092,  0.6134,  ..., -0.4632, -0.4632, -0.4632],\n",
            "         [ 5.6641,  2.8709,  0.6373,  ..., -0.4245, -0.4245, -0.4245]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 46, 20108])\n",
            "tensor([[[ 3.0376,  5.1922,  2.9841,  ..., -0.6733, -0.6733, -0.6733],\n",
            "         [ 3.0338,  4.7003,  3.1513,  ..., -0.4998, -0.4998, -0.4998],\n",
            "         [ 3.8272,  4.2925,  3.8235,  ..., -0.5243, -0.5243, -0.5243],\n",
            "         ...,\n",
            "         [ 5.2452,  2.9001,  1.1931,  ..., -0.5441, -0.5441, -0.5441],\n",
            "         [ 6.8836,  3.9134,  2.8104,  ..., -0.6920, -0.6920, -0.6920],\n",
            "         [ 6.9924,  4.3567,  3.3455,  ..., -0.7219, -0.7219, -0.7219]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.5770,  5.4133,  4.5193,  ..., -0.8119, -0.8119, -0.8119],\n",
            "         [ 4.4151,  5.9884,  5.1980,  ..., -0.9109, -0.9109, -0.9109],\n",
            "         [ 4.8588,  7.6061,  5.9823,  ..., -0.9350, -0.9350, -0.9350],\n",
            "         ...,\n",
            "         [ 3.5647,  8.3825,  5.4314,  ..., -0.7867, -0.7867, -0.7867],\n",
            "         [ 3.7999,  8.1326,  5.0730,  ..., -0.7809, -0.7809, -0.7809],\n",
            "         [ 5.1683,  7.6473,  5.8630,  ..., -0.9170, -0.9170, -0.9170]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 3.4269,  5.7209,  4.2082,  ..., -1.0718, -1.0718, -1.0718],\n",
            "         [ 3.0735,  6.5135,  4.5020,  ..., -1.1025, -1.1025, -1.1025],\n",
            "         [ 2.8446,  6.6287,  4.8887,  ..., -1.1108, -1.1108, -1.1108],\n",
            "         ...,\n",
            "         [ 6.4235,  7.5287,  7.5963,  ..., -1.1352, -1.1352, -1.1352],\n",
            "         [ 7.1309,  7.8760,  7.6070,  ..., -1.1634, -1.1634, -1.1634],\n",
            "         [ 6.6145,  6.7969,  6.8720,  ..., -1.1353, -1.1353, -1.1353]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 147, 20108])\n",
            "tensor([[[ 2.8094,  5.8074,  4.2653,  ..., -1.0370, -1.0370, -1.0370],\n",
            "         [ 1.9369,  5.7486,  3.8615,  ..., -1.0095, -1.0095, -1.0095],\n",
            "         [ 1.3397,  5.2609,  3.6113,  ..., -0.9430, -0.9430, -0.9430],\n",
            "         ...,\n",
            "         [ 2.2111,  3.4851,  3.3227,  ..., -0.7561, -0.7561, -0.7561],\n",
            "         [ 2.8139,  4.4148,  3.9040,  ..., -0.8590, -0.8590, -0.8590],\n",
            "         [ 2.9943,  3.5011,  3.3892,  ..., -0.8861, -0.8861, -0.8861]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 4.5434,  6.7888,  5.6291,  ..., -1.0806, -1.0806, -1.0806],\n",
            "         [ 4.1960,  6.3256,  5.7917,  ..., -1.0920, -1.0920, -1.0920],\n",
            "         [ 4.0687,  5.8662,  5.0603,  ..., -1.0380, -1.0380, -1.0380],\n",
            "         ...,\n",
            "         [ 6.7770,  5.3817,  4.9291,  ..., -0.8477, -0.8477, -0.8477],\n",
            "         [ 6.0870,  4.8775,  4.5203,  ..., -0.8798, -0.8798, -0.8798],\n",
            "         [ 5.8373,  4.7865,  4.5314,  ..., -0.8737, -0.8737, -0.8737]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 135, 20108])\n",
            "tensor([[[ 5.9845,  5.8587,  5.3183,  ..., -1.0154, -1.0154, -1.0154],\n",
            "         [ 5.8736,  7.2917,  6.0091,  ..., -0.9986, -0.9986, -0.9986],\n",
            "         [ 5.2530,  6.9765,  6.0544,  ..., -0.9721, -0.9721, -0.9721],\n",
            "         ...,\n",
            "         [ 5.4319,  4.8286,  4.7486,  ..., -0.9276, -0.9276, -0.9276],\n",
            "         [ 5.4578,  4.4448,  3.9729,  ..., -0.9077, -0.9077, -0.9077],\n",
            "         [ 5.9545,  5.2331,  4.4158,  ..., -0.9094, -0.9094, -0.9094]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 5.4190,  5.7050,  3.8288,  ..., -0.8262, -0.8262, -0.8262],\n",
            "         [ 4.9270,  4.9904,  3.0465,  ..., -0.7418, -0.7418, -0.7418],\n",
            "         [ 2.7564,  6.1201,  3.7084,  ..., -0.6991, -0.6991, -0.6991],\n",
            "         ...,\n",
            "         [ 4.2679,  7.2267,  7.4595,  ..., -0.9491, -0.9491, -0.9491],\n",
            "         [ 4.0295,  7.6370,  7.5360,  ..., -1.0236, -1.0236, -1.0236],\n",
            "         [ 4.3319,  6.8710,  7.0970,  ..., -1.0368, -1.0368, -1.0368]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 6.5104,  8.6595,  7.4789,  ..., -1.1612, -1.1612, -1.1612],\n",
            "         [ 7.9936,  8.6009,  8.1095,  ..., -1.1064, -1.1064, -1.1064],\n",
            "         [ 7.7134,  9.0199,  8.8387,  ..., -1.1305, -1.1305, -1.1305],\n",
            "         ...,\n",
            "         [ 4.4921,  6.6046,  7.0346,  ..., -0.9136, -0.9136, -0.9136],\n",
            "         [ 4.9904,  6.4716,  7.5298,  ..., -0.8424, -0.8424, -0.8424],\n",
            "         [ 5.4225,  6.5598,  6.5257,  ..., -0.7529, -0.7529, -0.7529]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 75, 20108])\n",
            "tensor([[[ 3.1173,  6.1018,  4.5470,  ..., -1.0903, -1.0903, -1.0903],\n",
            "         [ 3.2961,  5.8902,  4.6633,  ..., -1.1049, -1.1049, -1.1049],\n",
            "         [ 2.3835,  5.7817,  3.8859,  ..., -1.0010, -1.0010, -1.0010],\n",
            "         ...,\n",
            "         [ 4.4278,  8.5875,  8.1122,  ..., -0.9643, -0.9643, -0.9643],\n",
            "         [ 4.8624,  8.8853,  8.3434,  ..., -0.9347, -0.9347, -0.9347],\n",
            "         [ 4.3063,  9.0850,  8.0545,  ..., -0.9348, -0.9348, -0.9348]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.7423,  5.4974,  4.6659,  ..., -0.9821, -0.9821, -0.9821],\n",
            "         [ 3.8112,  5.4740,  4.9504,  ..., -1.0059, -1.0059, -1.0059],\n",
            "         [ 4.1720,  6.4524,  5.7141,  ..., -1.0484, -1.0484, -1.0484],\n",
            "         ...,\n",
            "         [ 4.6003,  7.7624,  6.4474,  ..., -0.8887, -0.8887, -0.8887],\n",
            "         [ 3.9926,  7.8349,  6.0244,  ..., -0.8952, -0.8952, -0.8952],\n",
            "         [ 4.5075,  7.9327,  6.3225,  ..., -0.9116, -0.9116, -0.9116]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 6.1475,  8.4423,  8.5070,  ..., -1.0160, -1.0160, -1.0160],\n",
            "         [ 4.8336,  7.4095,  7.4112,  ..., -1.0499, -1.0499, -1.0499],\n",
            "         [ 5.0176,  7.3089,  6.7164,  ..., -1.1169, -1.1169, -1.1169],\n",
            "         ...,\n",
            "         [ 3.2975,  6.1531,  6.3805,  ..., -0.9134, -0.9134, -0.9134],\n",
            "         [ 3.5647,  7.5025,  7.5629,  ..., -0.9074, -0.9074, -0.9074],\n",
            "         [ 3.9221,  7.3591,  7.0527,  ..., -0.9106, -0.9106, -0.9106]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 2.6806,  4.2902,  3.7819,  ..., -1.0030, -1.0030, -1.0030],\n",
            "         [ 2.5165,  4.3474,  3.1378,  ..., -0.9436, -0.9436, -0.9436],\n",
            "         [ 2.5988,  5.9547,  4.2566,  ..., -0.8301, -0.8301, -0.8301],\n",
            "         ...,\n",
            "         [ 2.8439,  5.8455,  3.8892,  ..., -0.7562, -0.7562, -0.7562],\n",
            "         [ 2.5787,  6.7004,  4.4968,  ..., -0.7920, -0.7920, -0.7920],\n",
            "         [ 3.8661,  5.9785,  4.4592,  ..., -0.8077, -0.8077, -0.8077]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 4.8654,  7.1766,  5.9704,  ..., -1.1266, -1.1266, -1.1266],\n",
            "         [ 5.2021,  6.5215,  6.2567,  ..., -1.0790, -1.0790, -1.0790],\n",
            "         [ 4.4768,  6.4583,  5.9999,  ..., -1.0015, -1.0015, -1.0015],\n",
            "         ...,\n",
            "         [ 3.9623,  3.4019,  3.4106,  ..., -0.8771, -0.8771, -0.8771],\n",
            "         [ 3.7383,  3.0963,  3.5950,  ..., -0.8851, -0.8851, -0.8851],\n",
            "         [ 3.5118,  3.6937,  3.9036,  ..., -0.8833, -0.8833, -0.8833]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 41, 20108])\n",
            "tensor([[[ 2.9544,  4.6703,  3.9170,  ..., -0.9943, -0.9943, -0.9943],\n",
            "         [ 4.2546,  5.3109,  4.8114,  ..., -0.9633, -0.9633, -0.9633],\n",
            "         [ 5.3924,  6.1389,  5.2076,  ..., -1.0289, -1.0289, -1.0289],\n",
            "         ...,\n",
            "         [ 7.2207,  6.0590,  4.9251,  ..., -0.9588, -0.9588, -0.9588],\n",
            "         [ 7.4713,  5.2085,  4.5240,  ..., -0.9362, -0.9362, -0.9362],\n",
            "         [ 7.6748,  5.2142,  4.8338,  ..., -1.0134, -1.0134, -1.0134]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 4.9644,  5.1639,  3.6549,  ..., -0.4546, -0.4546, -0.4546],\n",
            "         [ 4.3187,  4.8450,  2.5958,  ..., -0.4640, -0.4640, -0.4640],\n",
            "         [ 4.4882,  4.1771,  2.0004,  ..., -0.4003, -0.4003, -0.4003],\n",
            "         [ 4.5403,  3.1980,  1.2302,  ..., -0.4255, -0.4255, -0.4255],\n",
            "         [ 4.8257,  3.7833,  1.6690,  ..., -0.5661, -0.5661, -0.5661],\n",
            "         [ 5.5225,  3.4344,  1.8149,  ..., -0.5255, -0.5255, -0.5255]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 62, 20108])\n",
            "tensor([[[ 5.3310,  7.6891,  6.1315,  ..., -1.0858, -1.0858, -1.0858],\n",
            "         [ 5.1607,  6.9112,  5.6431,  ..., -1.0396, -1.0396, -1.0396],\n",
            "         [ 5.1850,  7.2385,  6.2522,  ..., -1.0758, -1.0758, -1.0758],\n",
            "         ...,\n",
            "         [ 2.2169,  3.4241,  4.1999,  ..., -0.6216, -0.6216, -0.6216],\n",
            "         [ 1.9880,  3.6663,  3.9158,  ..., -0.6207, -0.6207, -0.6207],\n",
            "         [ 2.5307,  3.8688,  4.0403,  ..., -0.6423, -0.6423, -0.6423]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 29, 20108])\n",
            "tensor([[[ 1.6385,  4.8919,  3.7981,  ..., -0.9824, -0.9824, -0.9824],\n",
            "         [ 3.5824,  7.4705,  5.9781,  ..., -1.0770, -1.0770, -1.0770],\n",
            "         [ 3.6627,  7.7355,  6.6518,  ..., -0.9941, -0.9941, -0.9941],\n",
            "         ...,\n",
            "         [ 4.2061,  8.5298,  7.5031,  ..., -0.8811, -0.8811, -0.8811],\n",
            "         [ 3.7963,  7.6012,  6.6806,  ..., -0.8989, -0.8989, -0.8989],\n",
            "         [ 4.0660,  7.4624,  6.7253,  ..., -0.9142, -0.9142, -0.9142]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 27, 20108])\n",
            "tensor([[[ 3.0299,  5.3049,  4.3961,  ..., -1.0710, -1.0710, -1.0710],\n",
            "         [ 2.0104,  5.7413,  3.8702,  ..., -1.0549, -1.0549, -1.0549],\n",
            "         [ 1.4897,  4.9734,  3.4794,  ..., -1.0436, -1.0436, -1.0436],\n",
            "         ...,\n",
            "         [ 4.3391,  8.0692,  6.1262,  ..., -0.8408, -0.8408, -0.8408],\n",
            "         [ 3.8226,  7.0943,  5.7382,  ..., -0.8319, -0.8319, -0.8319],\n",
            "         [ 3.4325,  6.0918,  5.2819,  ..., -0.8219, -0.8219, -0.8219]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 69, 20108])\n",
            "tensor([[[ 5.3069,  8.2058,  7.7020,  ..., -1.0722, -1.0722, -1.0722],\n",
            "         [ 5.0705,  7.6561,  7.2274,  ..., -1.1243, -1.1243, -1.1243],\n",
            "         [ 5.6219,  8.8605,  8.0053,  ..., -1.0763, -1.0763, -1.0763],\n",
            "         ...,\n",
            "         [ 7.2015,  7.1179,  7.5592,  ..., -1.0319, -1.0319, -1.0319],\n",
            "         [ 7.1799,  6.6380,  6.9583,  ..., -1.0593, -1.0593, -1.0593],\n",
            "         [ 6.5983,  6.2736,  6.3763,  ..., -1.0225, -1.0225, -1.0225]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 3.6864,  4.3051,  2.2591,  ..., -0.5291, -0.5291, -0.5291],\n",
            "         [ 3.1343,  4.3455,  2.4007,  ..., -0.4552, -0.4552, -0.4552],\n",
            "         [ 3.3183,  4.3451,  1.9502,  ..., -0.4379, -0.4379, -0.4379],\n",
            "         ...,\n",
            "         [ 6.7993,  1.9709,  0.8556,  ..., -0.3438, -0.3438, -0.3438],\n",
            "         [ 7.1049,  1.7092,  0.6379,  ..., -0.3228, -0.3228, -0.3228],\n",
            "         [ 6.8167,  1.9806,  0.3999,  ..., -0.2727, -0.2727, -0.2727]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 3.7394,  6.6023,  5.2201,  ..., -1.0562, -1.0562, -1.0562],\n",
            "         [ 3.0408,  5.7062,  4.5379,  ..., -1.0351, -1.0351, -1.0351],\n",
            "         [ 2.1958,  5.1503,  4.0965,  ..., -0.9559, -0.9559, -0.9559],\n",
            "         ...,\n",
            "         [ 4.4637,  5.6050,  6.7141,  ..., -0.9580, -0.9580, -0.9580],\n",
            "         [ 4.8601,  5.7345,  6.9898,  ..., -0.9444, -0.9444, -0.9444],\n",
            "         [ 4.6072,  5.5341,  7.2082,  ..., -0.9161, -0.9161, -0.9161]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 72, 20108])\n",
            "tensor([[[ 3.6692,  6.8992,  5.5876,  ..., -1.1657, -1.1657, -1.1657],\n",
            "         [ 2.1373,  5.7189,  4.1098,  ..., -1.0608, -1.0608, -1.0608],\n",
            "         [ 2.9521,  6.0053,  4.8158,  ..., -1.0907, -1.0907, -1.0907],\n",
            "         ...,\n",
            "         [ 4.1877,  6.2146,  5.7961,  ..., -0.7642, -0.7642, -0.7642],\n",
            "         [ 3.2337,  5.6564,  5.4700,  ..., -0.7055, -0.7055, -0.7055],\n",
            "         [ 3.2932,  5.7466,  5.4810,  ..., -0.7013, -0.7013, -0.7013]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 2.7572,  5.3837,  4.2390,  ..., -0.9709, -0.9709, -0.9709],\n",
            "         [ 2.5958,  7.0007,  3.8950,  ..., -0.7421, -0.7421, -0.7421],\n",
            "         [ 2.5837,  9.0737,  5.4518,  ..., -0.8259, -0.8259, -0.8259],\n",
            "         ...,\n",
            "         [ 5.3520,  8.0903,  7.0751,  ..., -0.9345, -0.9345, -0.9345],\n",
            "         [ 5.5667,  7.9433,  6.6039,  ..., -0.9522, -0.9522, -0.9522],\n",
            "         [ 5.8117,  7.5461,  6.6548,  ..., -0.9872, -0.9872, -0.9872]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 4.4858,  6.7534,  5.3973,  ..., -1.1290, -1.1290, -1.1290],\n",
            "         [ 4.1047,  6.4042,  5.5147,  ..., -1.0979, -1.0979, -1.0979],\n",
            "         [ 5.3781,  7.2139,  7.3707,  ..., -1.0964, -1.0964, -1.0964],\n",
            "         ...,\n",
            "         [ 4.8675,  5.0954,  5.8877,  ..., -1.1063, -1.1063, -1.1063],\n",
            "         [ 6.5070,  5.5165,  5.5010,  ..., -1.0817, -1.0817, -1.0817],\n",
            "         [ 6.6321,  5.7534,  5.9300,  ..., -1.0907, -1.0907, -1.0907]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 2.9145,  5.7991,  4.0853,  ..., -1.0965, -1.0965, -1.0965],\n",
            "         [ 2.9637,  6.1522,  3.9691,  ..., -1.0905, -1.0905, -1.0905],\n",
            "         [ 2.8316,  5.9810,  3.7590,  ..., -1.0830, -1.0830, -1.0830],\n",
            "         ...,\n",
            "         [ 4.3784,  6.8948,  5.5192,  ..., -0.6902, -0.6902, -0.6902],\n",
            "         [ 4.1792,  6.7446,  5.3584,  ..., -0.6991, -0.6991, -0.6991],\n",
            "         [ 4.4329,  6.7778,  5.0399,  ..., -0.7442, -0.7442, -0.7442]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 171, 20108])\n",
            "tensor([[[ 4.9221,  9.3413,  6.3833,  ..., -0.9011, -0.9011, -0.9011],\n",
            "         [ 5.5809,  9.6652,  8.3885,  ..., -0.9159, -0.9159, -0.9159],\n",
            "         [ 4.8478,  9.6467,  8.4464,  ..., -0.9324, -0.9324, -0.9324],\n",
            "         ...,\n",
            "         [ 2.1899,  3.2373,  3.2861,  ..., -0.6934, -0.6934, -0.6934],\n",
            "         [ 3.1970,  4.8942,  4.4260,  ..., -0.7214, -0.7214, -0.7214],\n",
            "         [ 2.8754,  3.9576,  3.7987,  ..., -0.7393, -0.7393, -0.7393]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 197, 20108])\n",
            "tensor([[[ 5.1102,  6.5968,  5.8799,  ..., -1.1106, -1.1106, -1.1106],\n",
            "         [ 6.0450,  7.2525,  5.8985,  ..., -1.0170, -1.0170, -1.0170],\n",
            "         [ 4.8350,  7.4495,  6.5854,  ..., -0.9421, -0.9421, -0.9421],\n",
            "         ...,\n",
            "         [ 2.7634,  4.7972,  3.7294,  ..., -0.5086, -0.5086, -0.5086],\n",
            "         [ 2.3609,  4.7249,  3.5152,  ..., -0.5220, -0.5220, -0.5220],\n",
            "         [ 2.3764,  4.3596,  3.2236,  ..., -0.5295, -0.5295, -0.5295]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 6.7714,  7.3529,  6.5402,  ..., -1.1475, -1.1475, -1.1475],\n",
            "         [ 5.1566,  7.0110,  6.0883,  ..., -1.0750, -1.0750, -1.0750],\n",
            "         [ 6.1654,  6.9639,  6.2430,  ..., -1.1029, -1.1029, -1.1029],\n",
            "         ...,\n",
            "         [ 3.8877,  6.4064,  6.8356,  ..., -1.0467, -1.0467, -1.0467],\n",
            "         [ 4.0213,  6.5307,  7.2791,  ..., -1.0206, -1.0206, -1.0206],\n",
            "         [ 3.0426,  6.5414,  6.6750,  ..., -0.9409, -0.9409, -0.9409]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 47, 20108])\n",
            "tensor([[[ 4.9818,  9.7986,  6.8659,  ..., -0.8448, -0.8448, -0.8448],\n",
            "         [ 5.5505,  8.1072,  7.3747,  ..., -1.0460, -1.0460, -1.0460],\n",
            "         [ 6.3926,  7.7216,  7.1217,  ..., -1.0383, -1.0383, -1.0383],\n",
            "         ...,\n",
            "         [ 8.5309,  5.8253,  4.8241,  ..., -0.8965, -0.8965, -0.8965],\n",
            "         [ 7.8459,  5.6627,  4.6106,  ..., -0.9828, -0.9828, -0.9828],\n",
            "         [ 6.7899,  5.1480,  4.2547,  ..., -0.9470, -0.9470, -0.9470]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 5.0723,  9.5752,  7.0048,  ..., -0.9031, -0.9031, -0.9031],\n",
            "         [ 4.8106,  9.9083,  6.6944,  ..., -0.7946, -0.7946, -0.7946],\n",
            "         [ 5.7696,  8.2083,  4.9427,  ..., -0.5246, -0.5246, -0.5246],\n",
            "         ...,\n",
            "         [ 6.9965,  2.1964,  0.8021,  ..., -0.4254, -0.4254, -0.4254],\n",
            "         [ 7.4994,  2.1558,  1.2128,  ..., -0.4689, -0.4689, -0.4689],\n",
            "         [ 7.2833,  1.9958,  0.8607,  ..., -0.4474, -0.4474, -0.4474]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 43, 20108])\n",
            "tensor([[[ 5.8938,  5.4539,  3.4104,  ..., -0.6175, -0.6175, -0.6175],\n",
            "         [ 7.0712,  6.9159,  5.3111,  ..., -0.9616, -0.9616, -0.9616],\n",
            "         [ 6.4888,  6.8494,  6.0422,  ..., -0.9202, -0.9202, -0.9202],\n",
            "         ...,\n",
            "         [ 5.3406,  4.0111,  4.0820,  ..., -0.8685, -0.8685, -0.8685],\n",
            "         [ 5.9763,  3.9722,  3.5510,  ..., -0.8322, -0.8322, -0.8322],\n",
            "         [ 5.0818,  3.4031,  3.0469,  ..., -0.8220, -0.8220, -0.8220]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.9841,  6.8153,  6.5448,  ..., -1.0912, -1.0912, -1.0912],\n",
            "         [ 4.9768,  7.0244,  6.4937,  ..., -1.0886, -1.0886, -1.0886],\n",
            "         [ 4.0481,  6.2775,  5.8262,  ..., -1.0771, -1.0771, -1.0771],\n",
            "         ...,\n",
            "         [ 3.7018,  6.2443,  6.0870,  ..., -0.6109, -0.6109, -0.6109],\n",
            "         [ 3.3496,  6.0050,  5.9554,  ..., -0.6024, -0.6024, -0.6024],\n",
            "         [ 3.4684,  6.3400,  5.9531,  ..., -0.5824, -0.5824, -0.5824]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 148, 20108])\n",
            "tensor([[[ 5.7408,  5.9324,  5.8362,  ..., -1.0685, -1.0685, -1.0685],\n",
            "         [ 5.7117,  5.8092,  5.8295,  ..., -1.0728, -1.0728, -1.0728],\n",
            "         [ 5.3105,  5.9924,  5.9966,  ..., -1.0341, -1.0341, -1.0341],\n",
            "         ...,\n",
            "         [ 7.0052,  5.7818,  3.9805,  ..., -0.8647, -0.8647, -0.8647],\n",
            "         [ 6.8013,  5.3601,  3.7890,  ..., -0.8754, -0.8754, -0.8754],\n",
            "         [ 6.9279,  4.8463,  3.5001,  ..., -0.8821, -0.8821, -0.8821]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 4.0310,  5.0244,  2.5560,  ..., -0.6039, -0.6039, -0.6039],\n",
            "         [ 3.5583,  5.0091,  2.8624,  ..., -0.4575, -0.4575, -0.4575],\n",
            "         [ 4.2103,  5.0057,  2.4516,  ..., -0.4693, -0.4693, -0.4693],\n",
            "         ...,\n",
            "         [ 5.6897,  2.4144,  1.2182,  ..., -0.3910, -0.3910, -0.3910],\n",
            "         [ 5.9617,  1.4351,  0.0579,  ..., -0.4175, -0.4175, -0.4175],\n",
            "         [ 5.7979,  1.1438, -0.1029,  ..., -0.3980, -0.3980, -0.3980]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 6.1035,  6.3848,  3.7839,  ..., -0.4730, -0.4730, -0.4730],\n",
            "         [ 5.3442,  4.8748,  2.5807,  ..., -0.3849, -0.3849, -0.3849],\n",
            "         [ 5.1543,  4.7984,  2.5339,  ..., -0.4092, -0.4092, -0.4092],\n",
            "         ...,\n",
            "         [ 6.5401,  4.0032,  2.2098,  ..., -0.4961, -0.4961, -0.4961],\n",
            "         [ 6.7184,  4.3812,  2.6722,  ..., -0.4614, -0.4614, -0.4614],\n",
            "         [ 6.8028,  4.3088,  2.7639,  ..., -0.4336, -0.4336, -0.4336]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 4.5054,  7.0818,  4.5944,  ..., -0.7281, -0.7281, -0.7281],\n",
            "         [ 4.5115,  5.0991,  2.8046,  ..., -0.5041, -0.5041, -0.5041],\n",
            "         [ 3.2903,  4.2894,  2.2327,  ..., -0.4007, -0.4007, -0.4007],\n",
            "         ...,\n",
            "         [ 6.5526,  2.7349,  1.8098,  ..., -0.3459, -0.3459, -0.3459],\n",
            "         [ 6.0966,  3.4019,  2.0291,  ..., -0.3516, -0.3516, -0.3516],\n",
            "         [ 6.5152,  3.4996,  1.5706,  ..., -0.3613, -0.3613, -0.3613]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 68, 20108])\n",
            "tensor([[[-0.0412,  5.8999,  3.5632,  ..., -0.6816, -0.6816, -0.6816],\n",
            "         [ 1.8625,  8.1634,  6.4453,  ..., -0.7729, -0.7729, -0.7729],\n",
            "         [ 2.1078,  8.7425,  6.8066,  ..., -0.7920, -0.7920, -0.7920],\n",
            "         ...,\n",
            "         [ 3.1991,  6.3379,  5.5902,  ..., -0.6093, -0.6093, -0.6093],\n",
            "         [ 3.9055,  6.9529,  6.0729,  ..., -0.7436, -0.7436, -0.7436],\n",
            "         [ 4.5962,  6.4518,  5.8758,  ..., -0.7097, -0.7097, -0.7097]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 3.7780,  5.6253,  4.2333,  ..., -1.0638, -1.0638, -1.0638],\n",
            "         [ 2.5744,  5.3752,  3.8541,  ..., -1.0154, -1.0154, -1.0154],\n",
            "         [ 2.0771,  4.8831,  3.4154,  ..., -1.0331, -1.0331, -1.0331],\n",
            "         ...,\n",
            "         [ 1.4395,  5.9140,  4.9690,  ..., -0.7673, -0.7673, -0.7673],\n",
            "         [ 0.4105,  4.8580,  4.1175,  ..., -0.6627, -0.6627, -0.6627],\n",
            "         [ 0.7719,  5.3220,  4.5360,  ..., -0.6939, -0.6939, -0.6939]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 2.5442,  6.4238,  4.8801,  ..., -1.0553, -1.0553, -1.0553],\n",
            "         [ 2.3203,  6.3583,  4.9293,  ..., -1.0515, -1.0515, -1.0515],\n",
            "         [ 3.2366,  7.4640,  4.6861,  ..., -0.9511, -0.9511, -0.9511],\n",
            "         ...,\n",
            "         [ 3.6150,  9.5568,  7.1745,  ..., -0.8564, -0.8564, -0.8564],\n",
            "         [ 4.8730,  8.7155,  6.5173,  ..., -0.8340, -0.8340, -0.8340],\n",
            "         [ 4.8684,  8.5872,  6.3292,  ..., -0.9370, -0.9370, -0.9370]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 4.6135,  6.1072,  5.8530,  ..., -1.0417, -1.0417, -1.0417],\n",
            "         [ 4.1520,  6.6545,  6.0720,  ..., -1.0467, -1.0467, -1.0467],\n",
            "         [ 3.9438,  6.3346,  5.3842,  ..., -1.0745, -1.0745, -1.0745],\n",
            "         ...,\n",
            "         [ 5.8176,  7.6910,  7.1318,  ..., -1.1506, -1.1506, -1.1506],\n",
            "         [ 5.7311,  7.3378,  7.1642,  ..., -1.1351, -1.1351, -1.1351],\n",
            "         [ 5.6984,  7.2006,  6.8970,  ..., -1.1466, -1.1466, -1.1466]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 3.8596,  4.7430,  3.7147,  ..., -1.0436, -1.0436, -1.0436],\n",
            "         [ 4.9188,  8.2097,  6.6666,  ..., -1.0530, -1.0530, -1.0530],\n",
            "         [ 3.3077,  8.0944,  7.0083,  ..., -1.0191, -1.0191, -1.0191],\n",
            "         ...,\n",
            "         [ 3.0019,  6.2702,  6.0789,  ..., -0.7049, -0.7049, -0.7049],\n",
            "         [ 3.0787,  6.3935,  6.4470,  ..., -0.7343, -0.7343, -0.7343],\n",
            "         [ 3.1184,  5.7628,  5.8378,  ..., -0.6615, -0.6615, -0.6615]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 64, 20108])\n",
            "tensor([[[ 3.4765,  6.0884,  4.9227,  ..., -1.1019, -1.1019, -1.1019],\n",
            "         [ 2.9358,  5.0511,  3.6178,  ..., -1.0552, -1.0552, -1.0552],\n",
            "         [ 3.0392,  5.3753,  3.8350,  ..., -1.0424, -1.0424, -1.0424],\n",
            "         ...,\n",
            "         [ 4.7987,  7.1698,  6.2222,  ..., -0.8342, -0.8342, -0.8342],\n",
            "         [ 4.9404,  7.3865,  6.0764,  ..., -0.8614, -0.8614, -0.8614],\n",
            "         [ 4.4989,  6.7510,  5.4765,  ..., -0.7843, -0.7843, -0.7843]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 91, 20108])\n",
            "tensor([[[ 4.9852,  6.9408,  6.5801,  ..., -1.1083, -1.1083, -1.1083],\n",
            "         [ 4.6303,  5.6016,  5.2839,  ..., -1.0025, -1.0025, -1.0025],\n",
            "         [ 4.8337,  5.6514,  4.7136,  ..., -0.9190, -0.9190, -0.9190],\n",
            "         ...,\n",
            "         [ 3.8743,  3.0633,  4.1224,  ..., -0.8988, -0.8988, -0.8988],\n",
            "         [ 4.4118,  2.8048,  3.7576,  ..., -0.8608, -0.8608, -0.8608],\n",
            "         [ 4.2683,  2.8646,  4.1930,  ..., -0.8881, -0.8881, -0.8881]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 34, 20108])\n",
            "tensor([[[ 4.8871,  5.9216,  3.3883,  ..., -0.5849, -0.5849, -0.5849],\n",
            "         [ 6.1543,  5.9951,  3.7768,  ..., -0.5467, -0.5467, -0.5467],\n",
            "         [ 6.7441,  4.6765,  2.1375,  ..., -0.4027, -0.4027, -0.4027],\n",
            "         ...,\n",
            "         [ 6.8888,  2.0465, -0.3820,  ..., -0.3626, -0.3626, -0.3626],\n",
            "         [ 7.0137,  2.0081, -0.2828,  ..., -0.2884, -0.2884, -0.2884],\n",
            "         [ 6.5539,  1.4241, -0.5869,  ..., -0.3247, -0.3247, -0.3247]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 76, 20108])\n",
            "tensor([[[ 3.7146,  5.8485,  4.5853,  ..., -1.1167, -1.1167, -1.1167],\n",
            "         [ 3.2360,  6.0057,  4.8520,  ..., -1.1404, -1.1404, -1.1404],\n",
            "         [ 2.9516,  5.6940,  4.4721,  ..., -1.1176, -1.1176, -1.1176],\n",
            "         ...,\n",
            "         [ 4.8125,  6.3695,  5.9530,  ..., -0.9196, -0.9196, -0.9196],\n",
            "         [ 5.2568,  5.7841,  5.6792,  ..., -1.0340, -1.0340, -1.0340],\n",
            "         [ 4.2857,  5.9736,  5.6331,  ..., -0.9916, -0.9916, -0.9916]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 44, 20108])\n",
            "tensor([[[ 3.3940,  4.5870,  2.4612,  ..., -0.5362, -0.5362, -0.5362],\n",
            "         [ 3.9988,  4.3933,  2.2928,  ..., -0.4817, -0.4817, -0.4817],\n",
            "         [ 4.7748,  4.3442,  2.3289,  ..., -0.5564, -0.5564, -0.5564],\n",
            "         ...,\n",
            "         [ 5.1562, -0.1073, -1.6958,  ..., -0.3558, -0.3558, -0.3558],\n",
            "         [ 5.7714,  0.0587, -1.3135,  ..., -0.3475, -0.3475, -0.3475],\n",
            "         [ 5.9706, -0.1515, -1.5816,  ..., -0.2977, -0.2977, -0.2977]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 3.8928,  5.2673,  4.2316,  ..., -1.0875, -1.0875, -1.0875],\n",
            "         [ 3.8715,  6.0770,  5.0569,  ..., -1.1357, -1.1357, -1.1357],\n",
            "         [ 2.5686,  6.3702,  4.6719,  ..., -1.0671, -1.0671, -1.0671],\n",
            "         ...,\n",
            "         [ 3.6159,  7.0542,  5.9960,  ..., -0.9587, -0.9587, -0.9587],\n",
            "         [ 3.9880,  6.2012,  5.0067,  ..., -0.9399, -0.9399, -0.9399],\n",
            "         [ 4.3400,  6.5655,  5.3193,  ..., -0.9880, -0.9880, -0.9880]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 69, 20108])\n",
            "tensor([[[ 4.5349,  7.2131,  5.3309,  ..., -0.9795, -0.9795, -0.9795],\n",
            "         [ 4.1576,  6.7247,  6.7747,  ..., -1.0611, -1.0611, -1.0611],\n",
            "         [ 4.1696,  6.2293,  6.5395,  ..., -1.0362, -1.0362, -1.0362],\n",
            "         ...,\n",
            "         [ 5.1242,  5.6181,  6.4538,  ..., -1.0305, -1.0305, -1.0305],\n",
            "         [ 4.5723,  5.2464,  5.9340,  ..., -1.0138, -1.0138, -1.0138],\n",
            "         [ 3.7752,  5.2506,  5.9974,  ..., -0.9791, -0.9791, -0.9791]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 29, 20108])\n",
            "tensor([[[ 2.2265,  4.5277,  3.0788,  ..., -0.9694, -0.9694, -0.9694],\n",
            "         [ 4.3397,  6.6334,  5.7732,  ..., -1.0914, -1.0914, -1.0914],\n",
            "         [ 3.9652,  6.2424,  5.3969,  ..., -0.9227, -0.9227, -0.9227],\n",
            "         ...,\n",
            "         [ 5.1884,  3.1273,  1.7981,  ..., -0.6378, -0.6378, -0.6378],\n",
            "         [ 5.0045,  2.7610,  1.5792,  ..., -0.6276, -0.6276, -0.6276],\n",
            "         [ 4.8248,  3.0732,  1.6491,  ..., -0.6479, -0.6479, -0.6479]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.9675,  7.2730,  6.0125,  ..., -0.9491, -0.9491, -0.9491],\n",
            "         [ 2.5253,  7.0018,  5.8474,  ..., -0.9019, -0.9019, -0.9019],\n",
            "         [ 2.3987,  6.3156,  5.2703,  ..., -0.8112, -0.8112, -0.8112],\n",
            "         ...,\n",
            "         [ 1.4942,  6.7530,  4.6559,  ..., -0.7299, -0.7299, -0.7299],\n",
            "         [ 3.2912,  7.0682,  5.9060,  ..., -0.6874, -0.6874, -0.6874],\n",
            "         [ 3.0672,  7.3185,  5.9992,  ..., -0.6912, -0.6912, -0.6912]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 2.8525,  5.0020,  4.1904,  ..., -0.9674, -0.9674, -0.9674],\n",
            "         [ 4.5683,  7.8569,  6.1640,  ..., -0.9577, -0.9577, -0.9577],\n",
            "         [ 4.6901,  8.1385,  5.8865,  ..., -0.8679, -0.8679, -0.8679],\n",
            "         ...,\n",
            "         [ 5.5091,  6.4796,  4.0594,  ..., -0.7835, -0.7835, -0.7835],\n",
            "         [ 5.3062,  6.0250,  3.6388,  ..., -0.7454, -0.7454, -0.7454],\n",
            "         [ 5.6164,  6.4026,  3.9340,  ..., -0.7817, -0.7817, -0.7817]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 3.6057,  5.6920,  4.2338,  ..., -1.0438, -1.0438, -1.0438],\n",
            "         [ 3.4300,  5.3517,  4.1855,  ..., -1.0349, -1.0349, -1.0349],\n",
            "         [ 2.5837,  5.6096,  4.2155,  ..., -0.9988, -0.9988, -0.9988],\n",
            "         ...,\n",
            "         [ 5.0696,  8.5303,  6.4733,  ..., -1.0146, -1.0146, -1.0146],\n",
            "         [ 5.1445,  9.3953,  7.0439,  ..., -0.9531, -0.9531, -0.9531],\n",
            "         [ 4.8169,  8.8642,  6.8242,  ..., -0.8758, -0.8758, -0.8758]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 18, 20108])\n",
            "tensor([[[ 5.6371,  7.2080,  5.9031,  ..., -0.8318, -0.8318, -0.8318],\n",
            "         [ 4.4698,  4.9319,  4.9529,  ..., -1.0845, -1.0845, -1.0845],\n",
            "         [ 5.3002,  5.3364,  5.3000,  ..., -1.0170, -1.0170, -1.0170],\n",
            "         ...,\n",
            "         [ 3.7672,  5.1274,  6.1678,  ..., -0.9411, -0.9411, -0.9411],\n",
            "         [ 3.1333,  4.4826,  5.5260,  ..., -0.8921, -0.8921, -0.8921],\n",
            "         [ 4.6902,  5.3727,  6.6254,  ..., -1.0444, -1.0444, -1.0444]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 17, 20108])\n",
            "tensor([[[ 3.2890,  5.1643,  2.7169,  ..., -0.5014, -0.5014, -0.5014],\n",
            "         [ 4.4698,  5.0095,  2.6152,  ..., -0.4763, -0.4763, -0.4763],\n",
            "         [ 5.1013,  5.5753,  2.8987,  ..., -0.3754, -0.3754, -0.3754],\n",
            "         ...,\n",
            "         [ 5.9641,  3.7079,  1.2557,  ..., -0.2843, -0.2843, -0.2843],\n",
            "         [ 6.0516,  3.6430,  1.3938,  ..., -0.3178, -0.3178, -0.3178],\n",
            "         [ 5.9996,  4.1424,  1.1576,  ..., -0.3028, -0.3028, -0.3028]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 4.2397,  6.4271,  5.4526,  ..., -1.1092, -1.1092, -1.1092],\n",
            "         [ 5.6412,  7.3673,  6.9512,  ..., -1.0836, -1.0836, -1.0836],\n",
            "         [ 5.0874,  8.5677,  7.5480,  ..., -1.0722, -1.0722, -1.0722],\n",
            "         ...,\n",
            "         [ 4.5560,  7.3515,  6.5633,  ..., -0.7644, -0.7644, -0.7644],\n",
            "         [ 4.4357,  7.0207,  6.2634,  ..., -0.7310, -0.7310, -0.7310],\n",
            "         [ 4.8177,  8.1875,  7.3671,  ..., -0.8025, -0.8025, -0.8025]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 3.4729,  5.6241,  4.9355,  ..., -0.9366, -0.9366, -0.9366],\n",
            "         [ 3.4141,  4.4878,  3.7276,  ..., -0.9101, -0.9101, -0.9101],\n",
            "         [ 5.2314,  6.7306,  5.8228,  ..., -0.9892, -0.9892, -0.9892],\n",
            "         ...,\n",
            "         [ 6.8913,  5.2552,  5.4759,  ..., -1.0640, -1.0640, -1.0640],\n",
            "         [ 6.5988,  5.3437,  5.7435,  ..., -0.9935, -0.9935, -0.9935],\n",
            "         [ 5.6308,  5.2600,  5.6183,  ..., -1.0540, -1.0540, -1.0540]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 195, 20108])\n",
            "tensor([[[ 3.3826,  6.0412,  5.1702,  ..., -1.0957, -1.0957, -1.0957],\n",
            "         [ 2.4013,  5.5027,  4.2777,  ..., -1.0973, -1.0973, -1.0973],\n",
            "         [ 2.4178,  5.5362,  4.1436,  ..., -1.1268, -1.1268, -1.1268],\n",
            "         ...,\n",
            "         [ 2.1518,  3.3595,  3.3074,  ..., -0.8310, -0.8310, -0.8310],\n",
            "         [ 2.3657,  3.4716,  3.5216,  ..., -0.8294, -0.8294, -0.8294],\n",
            "         [ 2.7357,  4.1319,  3.6571,  ..., -0.8635, -0.8635, -0.8635]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 6.1074,  6.5039,  4.9669,  ..., -1.0363, -1.0363, -1.0363],\n",
            "         [ 3.9254,  5.6861,  3.7720,  ..., -0.8675, -0.8675, -0.8675],\n",
            "         [ 5.0074,  6.5408,  5.0000,  ..., -0.9020, -0.9020, -0.9020],\n",
            "         [ 4.9347,  6.0308,  3.6092,  ..., -0.8274, -0.8274, -0.8274],\n",
            "         [ 4.8785,  6.5095,  4.2230,  ..., -0.8846, -0.8846, -0.8846],\n",
            "         [ 4.9941,  6.2319,  4.2999,  ..., -0.8262, -0.8262, -0.8262]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 1.8605,  5.6434,  3.8257,  ..., -0.9872, -0.9872, -0.9872],\n",
            "         [ 1.2306,  5.5085,  4.0653,  ..., -0.8865, -0.8865, -0.8865],\n",
            "         [ 0.6538,  6.3421,  3.6928,  ..., -0.8867, -0.8867, -0.8867],\n",
            "         ...,\n",
            "         [ 1.8550,  6.0247,  3.8231,  ..., -0.7024, -0.7024, -0.7024],\n",
            "         [ 2.2392,  5.8530,  3.2444,  ..., -0.6571, -0.6571, -0.6571],\n",
            "         [ 1.6125,  5.8817,  3.3437,  ..., -0.6254, -0.6254, -0.6254]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 295, 20108])\n",
            "tensor([[[ 7.9713,  9.9259,  8.7016,  ..., -0.9936, -0.9936, -0.9936],\n",
            "         [ 7.6995, 10.1027,  8.7629,  ..., -0.8999, -0.8999, -0.8999],\n",
            "         [ 8.6077, 10.0016,  9.4343,  ..., -0.8986, -0.8986, -0.8986],\n",
            "         ...,\n",
            "         [ 4.2660,  1.8471,  2.2079,  ..., -0.7541, -0.7541, -0.7541],\n",
            "         [ 4.1103,  1.7369,  2.2595,  ..., -0.7361, -0.7361, -0.7361],\n",
            "         [ 4.0700,  1.5046,  1.9950,  ..., -0.7561, -0.7561, -0.7561]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 3.6164,  4.1282,  2.1378,  ..., -0.5264, -0.5264, -0.5264],\n",
            "         [ 3.6320,  4.7265,  2.6538,  ..., -0.5133, -0.5133, -0.5133],\n",
            "         [ 4.5173,  3.2369,  2.4218,  ..., -0.5236, -0.5236, -0.5236],\n",
            "         ...,\n",
            "         [ 5.6534,  3.1830,  1.4670,  ..., -0.3821, -0.3821, -0.3821],\n",
            "         [ 5.9148,  3.0074,  1.6759,  ..., -0.3936, -0.3936, -0.3936],\n",
            "         [ 6.0552,  3.4385,  2.1613,  ..., -0.3676, -0.3676, -0.3676]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 83, 20108])\n",
            "tensor([[[ 3.8002,  5.0086,  4.0309,  ..., -0.9962, -0.9962, -0.9962],\n",
            "         [ 2.2047,  5.1130,  3.0082,  ..., -0.9187, -0.9187, -0.9187],\n",
            "         [ 0.8530,  5.5539,  3.8359,  ..., -0.7761, -0.7761, -0.7761],\n",
            "         ...,\n",
            "         [ 3.8007,  5.4133,  4.7994,  ..., -0.7376, -0.7376, -0.7376],\n",
            "         [ 3.2769,  5.3118,  4.6789,  ..., -0.7267, -0.7267, -0.7267],\n",
            "         [ 3.1873,  5.0962,  4.2986,  ..., -0.7200, -0.7200, -0.7200]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 220, 20108])\n",
            "tensor([[[ 6.3947,  7.2542,  7.0917,  ..., -1.0959, -1.0959, -1.0959],\n",
            "         [ 5.3188,  6.5340,  7.2004,  ..., -1.0520, -1.0520, -1.0520],\n",
            "         [ 6.2823,  6.9209,  6.8439,  ..., -1.0624, -1.0624, -1.0624],\n",
            "         ...,\n",
            "         [ 5.2563,  5.7737,  5.7671,  ..., -0.7872, -0.7872, -0.7872],\n",
            "         [ 5.0710,  5.7190,  5.7755,  ..., -0.7801, -0.7801, -0.7801],\n",
            "         [ 4.9964,  6.3083,  6.5413,  ..., -0.7944, -0.7944, -0.7944]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 18, 20108])\n",
            "tensor([[[ 4.7055,  5.8153,  5.1808,  ..., -0.9925, -0.9925, -0.9925],\n",
            "         [ 5.2990,  7.6156,  7.1122,  ..., -1.1067, -1.1067, -1.1067],\n",
            "         [ 4.7235,  7.0149,  6.3544,  ..., -1.0966, -1.0966, -1.0966],\n",
            "         ...,\n",
            "         [ 4.8229,  7.0245,  6.8548,  ..., -0.9261, -0.9261, -0.9261],\n",
            "         [ 4.3351,  6.0985,  6.3550,  ..., -0.8502, -0.8502, -0.8502],\n",
            "         [ 5.2254,  7.5651,  7.6556,  ..., -0.8751, -0.8751, -0.8751]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.9880,  8.1927,  7.4676,  ..., -0.8919, -0.8919, -0.8919],\n",
            "         [ 4.1054,  8.9176,  7.5168,  ..., -0.9727, -0.9727, -0.9727],\n",
            "         [ 4.4017,  8.6210,  7.5248,  ..., -0.9626, -0.9626, -0.9626],\n",
            "         ...,\n",
            "         [ 2.0241,  8.1594,  6.2025,  ..., -0.5666, -0.5666, -0.5666],\n",
            "         [ 2.5887,  9.1914,  6.1833,  ..., -0.6758, -0.6758, -0.6758],\n",
            "         [ 2.7061,  8.9767,  6.5659,  ..., -0.6645, -0.6645, -0.6645]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 6.7839,  7.8987,  6.6897,  ..., -1.1013, -1.1013, -1.1013],\n",
            "         [ 6.6346,  6.5338,  6.0556,  ..., -0.9574, -0.9574, -0.9574],\n",
            "         [ 5.9189,  6.4906,  6.2810,  ..., -1.0824, -1.0824, -1.0824],\n",
            "         ...,\n",
            "         [ 4.9432,  4.9144,  7.0983,  ..., -1.0058, -1.0058, -1.0058],\n",
            "         [ 4.3427,  4.6963,  6.8055,  ..., -0.9660, -0.9660, -0.9660],\n",
            "         [ 3.6558,  3.5724,  6.4417,  ..., -0.9292, -0.9292, -0.9292]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 3.2061,  5.5667,  3.9590,  ..., -1.0663, -1.0663, -1.0663],\n",
            "         [ 3.0495,  5.7403,  4.0324,  ..., -1.0656, -1.0656, -1.0656],\n",
            "         [ 2.5668,  5.6747,  3.4422,  ..., -1.0103, -1.0103, -1.0103],\n",
            "         ...,\n",
            "         [ 5.3312,  8.5360,  8.0248,  ..., -0.8488, -0.8488, -0.8488],\n",
            "         [ 5.4142,  9.1344,  8.2991,  ..., -0.9256, -0.9256, -0.9256],\n",
            "         [ 5.8469,  9.2084,  8.3614,  ..., -0.9303, -0.9303, -0.9303]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 2.8452,  4.3600,  3.5168,  ..., -0.9484, -0.9484, -0.9484],\n",
            "         [ 1.7947,  5.3749,  4.2144,  ..., -0.8907, -0.8907, -0.8907],\n",
            "         [ 1.9580,  5.9557,  4.0948,  ..., -0.8268, -0.8268, -0.8268],\n",
            "         ...,\n",
            "         [ 3.9963,  8.7098,  7.3347,  ..., -0.8606, -0.8606, -0.8606],\n",
            "         [ 3.9758,  7.6327,  6.8525,  ..., -0.8625, -0.8625, -0.8625],\n",
            "         [ 4.8358,  7.9373,  6.7942,  ..., -0.8737, -0.8737, -0.8737]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 40, 20108])\n",
            "tensor([[[ 4.2804,  6.9094,  6.0933,  ..., -1.0985, -1.0985, -1.0985],\n",
            "         [ 4.8274,  6.9136,  7.2905,  ..., -1.0754, -1.0754, -1.0754],\n",
            "         [ 4.7876,  7.2026,  7.8603,  ..., -1.0758, -1.0758, -1.0758],\n",
            "         ...,\n",
            "         [ 3.7482,  4.6143,  5.9884,  ..., -1.0175, -1.0175, -1.0175],\n",
            "         [ 4.6597,  5.2204,  6.6463,  ..., -1.0614, -1.0614, -1.0614],\n",
            "         [ 5.2850,  5.0918,  6.2394,  ..., -1.0554, -1.0554, -1.0554]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 424, 20108])\n",
            "tensor([[[ 6.5956,  6.5917,  5.5173,  ..., -1.0012, -1.0012, -1.0012],\n",
            "         [ 6.5095,  7.4831,  5.5907,  ..., -1.0026, -1.0026, -1.0026],\n",
            "         [ 6.0204,  6.0171,  4.2421,  ..., -0.8251, -0.8251, -0.8251],\n",
            "         ...,\n",
            "         [ 3.1371,  3.6636,  3.6707,  ..., -0.6056, -0.6056, -0.6056],\n",
            "         [ 3.0108,  3.4858,  3.3215,  ..., -0.5780, -0.5780, -0.5780],\n",
            "         [ 2.5703,  3.9170,  3.2133,  ..., -0.5203, -0.5203, -0.5203]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 130, 20108])\n",
            "tensor([[[ 2.7902,  5.3144,  4.1621,  ..., -1.0632, -1.0632, -1.0632],\n",
            "         [ 3.4106,  5.6502,  3.7343,  ..., -1.0883, -1.0883, -1.0883],\n",
            "         [ 3.4058,  6.4076,  4.2787,  ..., -1.0865, -1.0865, -1.0865],\n",
            "         ...,\n",
            "         [ 6.0224,  5.1279,  5.5294,  ..., -1.0231, -1.0231, -1.0231],\n",
            "         [ 6.5979,  5.7574,  5.8138,  ..., -1.0233, -1.0233, -1.0233],\n",
            "         [ 6.6677,  6.2097,  6.4643,  ..., -1.0705, -1.0705, -1.0705]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 51, 20108])\n",
            "tensor([[[ 3.1093,  6.5595,  5.0910,  ..., -1.1351, -1.1351, -1.1351],\n",
            "         [ 4.5740,  7.4765,  6.7393,  ..., -1.1348, -1.1348, -1.1348],\n",
            "         [ 3.8192,  7.2624,  5.7389,  ..., -1.0310, -1.0310, -1.0310],\n",
            "         ...,\n",
            "         [ 6.0191,  5.5362,  6.0169,  ..., -0.8300, -0.8300, -0.8300],\n",
            "         [ 6.4489,  5.6238,  6.1980,  ..., -0.8302, -0.8302, -0.8302],\n",
            "         [ 6.6948,  5.6264,  6.2160,  ..., -0.8533, -0.8533, -0.8533]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 27, 20108])\n",
            "tensor([[[ 4.2656,  6.6658,  5.5893,  ..., -1.1194, -1.1194, -1.1194],\n",
            "         [ 4.6387,  6.2973,  5.6156,  ..., -1.0829, -1.0829, -1.0829],\n",
            "         [ 4.2024,  6.3633,  5.5103,  ..., -1.0863, -1.0863, -1.0863],\n",
            "         ...,\n",
            "         [ 4.2528,  7.1127,  6.8383,  ..., -0.7764, -0.7764, -0.7764],\n",
            "         [ 3.8914,  7.0394,  6.3190,  ..., -0.8039, -0.8039, -0.8039],\n",
            "         [ 3.3734,  7.5505,  6.1530,  ..., -0.7430, -0.7430, -0.7430]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 3.4456,  6.6323,  5.2537,  ..., -1.0901, -1.0901, -1.0901],\n",
            "         [ 3.3092,  6.2172,  4.8867,  ..., -0.9821, -0.9821, -0.9821],\n",
            "         [ 3.1029,  6.6945,  4.6025,  ..., -0.8860, -0.8860, -0.8860],\n",
            "         ...,\n",
            "         [ 3.8360,  8.7636,  8.1716,  ..., -0.8771, -0.8771, -0.8771],\n",
            "         [ 3.9191,  8.8033,  7.5902,  ..., -0.8685, -0.8685, -0.8685],\n",
            "         [ 4.0499,  8.5973,  7.4799,  ..., -0.8426, -0.8426, -0.8426]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 55, 20108])\n",
            "tensor([[[ 4.2145,  6.5278,  6.1655,  ..., -1.0618, -1.0618, -1.0618],\n",
            "         [ 2.7659,  5.7778,  4.9969,  ..., -1.0171, -1.0171, -1.0171],\n",
            "         [ 3.0770,  6.3542,  5.2290,  ..., -1.0740, -1.0740, -1.0740],\n",
            "         ...,\n",
            "         [ 6.0396,  5.0230,  5.0387,  ..., -0.8869, -0.8869, -0.8869],\n",
            "         [ 6.9368,  5.0756,  4.6506,  ..., -0.8985, -0.8985, -0.8985],\n",
            "         [ 5.2556,  3.9488,  4.5612,  ..., -0.9156, -0.9156, -0.9156]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.1272,  6.3919,  5.1761,  ..., -1.1269, -1.1269, -1.1269],\n",
            "         [ 3.4801,  5.9193,  5.2046,  ..., -1.0831, -1.0831, -1.0831],\n",
            "         [ 2.5561,  5.2099,  4.2324,  ..., -1.1032, -1.1032, -1.1032],\n",
            "         ...,\n",
            "         [ 3.6291,  9.5348,  6.8151,  ..., -0.8761, -0.8761, -0.8761],\n",
            "         [ 4.6385,  9.4844,  7.6069,  ..., -0.8918, -0.8918, -0.8918],\n",
            "         [ 3.9504,  8.5851,  7.1263,  ..., -0.8861, -0.8861, -0.8861]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 4.9231,  6.8489,  6.5600,  ..., -1.1323, -1.1323, -1.1323],\n",
            "         [ 5.9160,  6.8657,  7.1004,  ..., -1.0955, -1.0955, -1.0955],\n",
            "         [ 4.6896,  7.8496,  7.0858,  ..., -1.0194, -1.0194, -1.0194],\n",
            "         ...,\n",
            "         [ 5.9146,  7.9708,  6.6132,  ..., -0.9476, -0.9476, -0.9476],\n",
            "         [ 5.7886,  6.8024,  6.2369,  ..., -1.0005, -1.0005, -1.0005],\n",
            "         [ 5.4877,  7.2600,  6.0278,  ..., -0.9781, -0.9781, -0.9781]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 3.6403,  4.4231,  2.5250,  ..., -0.6131, -0.6131, -0.6131],\n",
            "         [ 3.0923,  4.4627,  2.4134,  ..., -0.4635, -0.4635, -0.4635],\n",
            "         [ 3.1324,  4.3738,  2.3302,  ..., -0.4607, -0.4607, -0.4607],\n",
            "         ...,\n",
            "         [ 6.1039,  3.9432,  1.6575,  ..., -0.2839, -0.2839, -0.2839],\n",
            "         [ 5.9668,  4.0127,  1.9819,  ..., -0.2834, -0.2834, -0.2834],\n",
            "         [ 5.6337,  3.7277,  1.6474,  ..., -0.2183, -0.2183, -0.2183]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 4.4460,  5.3439,  3.6837,  ..., -0.5716, -0.5716, -0.5716],\n",
            "         [ 5.1705,  6.1133,  4.9295,  ..., -0.7666, -0.7666, -0.7666],\n",
            "         [ 4.7653,  6.6020,  4.3150,  ..., -0.8310, -0.8310, -0.8310],\n",
            "         [ 5.6251,  6.1639,  4.6109,  ..., -0.8497, -0.8497, -0.8497],\n",
            "         [ 5.3825,  5.2690,  3.2174,  ..., -0.6454, -0.6454, -0.6454]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 59, 20108])\n",
            "tensor([[[ 1.9794,  4.0684,  2.9110,  ..., -0.9657, -0.9657, -0.9657],\n",
            "         [ 2.2509,  5.1295,  3.4676,  ..., -1.0197, -1.0197, -1.0197],\n",
            "         [ 3.3554,  6.1062,  4.0470,  ..., -0.9102, -0.9102, -0.9102],\n",
            "         ...,\n",
            "         [ 7.4920,  8.0900,  7.8813,  ..., -0.8972, -0.8972, -0.8972],\n",
            "         [ 7.7635,  7.1608,  7.7802,  ..., -0.9145, -0.9145, -0.9145],\n",
            "         [ 7.6157,  7.9449,  7.7652,  ..., -0.9182, -0.9182, -0.9182]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 5.4658,  7.7796,  6.8360,  ..., -1.1208, -1.1208, -1.1208],\n",
            "         [ 5.8010,  8.1468,  6.7163,  ..., -0.8987, -0.8987, -0.8987],\n",
            "         [ 5.3111,  6.1398,  4.7530,  ..., -0.6914, -0.6914, -0.6914],\n",
            "         ...,\n",
            "         [ 6.2717,  4.5417,  3.0440,  ..., -0.4452, -0.4452, -0.4452],\n",
            "         [ 6.2460,  4.9779,  2.8600,  ..., -0.4115, -0.4115, -0.4115],\n",
            "         [ 5.8312,  4.3198,  2.0719,  ..., -0.3530, -0.3530, -0.3530]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 183, 20108])\n",
            "tensor([[[ 4.1650,  6.0438,  4.4917,  ..., -1.0628, -1.0628, -1.0628],\n",
            "         [ 3.6775,  5.7258,  4.1959,  ..., -1.0659, -1.0659, -1.0659],\n",
            "         [ 2.9035,  4.8961,  3.6924,  ..., -1.0272, -1.0272, -1.0272],\n",
            "         ...,\n",
            "         [ 6.4104,  5.0376,  3.9989,  ..., -0.9252, -0.9252, -0.9252],\n",
            "         [ 6.2814,  5.0766,  4.3106,  ..., -0.9505, -0.9505, -0.9505],\n",
            "         [ 6.1029,  4.9273,  3.7852,  ..., -0.8888, -0.8888, -0.8888]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 3.3557,  5.4162,  3.6950,  ..., -0.9830, -0.9830, -0.9830],\n",
            "         [ 1.7603,  5.6239,  4.3461,  ..., -0.8879, -0.8879, -0.8879],\n",
            "         [ 5.6579,  7.4203,  6.9877,  ..., -1.1049, -1.1049, -1.1049],\n",
            "         ...,\n",
            "         [ 7.0481,  7.9620,  8.3302,  ..., -1.0834, -1.0834, -1.0834],\n",
            "         [ 7.3284,  8.2114,  8.0818,  ..., -1.1133, -1.1133, -1.1133],\n",
            "         [ 7.8089,  7.8108,  8.2089,  ..., -1.1521, -1.1521, -1.1521]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 5.3209,  7.6515,  6.6138,  ..., -1.0882, -1.0882, -1.0882],\n",
            "         [ 5.1820,  6.6267,  5.7186,  ..., -0.9892, -0.9892, -0.9892],\n",
            "         [ 4.2028,  7.4237,  5.1600,  ..., -0.9391, -0.9391, -0.9391],\n",
            "         ...,\n",
            "         [ 8.0290,  6.6780,  5.2637,  ..., -0.8686, -0.8686, -0.8686],\n",
            "         [ 7.0652,  6.3196,  5.1617,  ..., -0.8595, -0.8595, -0.8595],\n",
            "         [ 6.3972,  5.7139,  4.9546,  ..., -0.8824, -0.8824, -0.8824]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 156, 20108])\n",
            "tensor([[[ 2.8984,  6.4043,  5.0809,  ..., -1.1402, -1.1402, -1.1402],\n",
            "         [ 4.2273,  5.2647,  4.4488,  ..., -1.0797, -1.0797, -1.0797],\n",
            "         [ 4.8308,  6.4222,  5.8580,  ..., -1.1679, -1.1679, -1.1679],\n",
            "         ...,\n",
            "         [ 4.2975,  3.4982,  4.3413,  ..., -0.8914, -0.8914, -0.8914],\n",
            "         [ 5.4898,  3.1132,  4.0386,  ..., -0.9317, -0.9317, -0.9317],\n",
            "         [ 4.3586,  2.9668,  3.7851,  ..., -0.9113, -0.9113, -0.9113]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 57, 20108])\n",
            "tensor([[[ 5.8238,  5.9736,  3.8444,  ..., -0.5493, -0.5493, -0.5493],\n",
            "         [ 5.5255,  4.2522,  2.1898,  ..., -0.4549, -0.4549, -0.4549],\n",
            "         [ 5.5695,  3.2603,  1.5692,  ..., -0.4596, -0.4596, -0.4596],\n",
            "         ...,\n",
            "         [ 8.9442,  4.2069,  2.8755,  ..., -0.7197, -0.7197, -0.7197],\n",
            "         [ 8.8024,  4.1609,  2.8144,  ..., -0.7036, -0.7036, -0.7036],\n",
            "         [ 8.1662,  3.9104,  2.4776,  ..., -0.7337, -0.7337, -0.7337]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.3177,  4.5225,  4.2545,  ..., -0.9087, -0.9087, -0.9087],\n",
            "         [ 4.9594,  4.3276,  2.6697,  ..., -0.7588, -0.7588, -0.7588],\n",
            "         [ 5.0536,  5.5593,  3.4894,  ..., -0.8265, -0.8265, -0.8265],\n",
            "         ...,\n",
            "         [ 6.1077,  5.9946,  4.4046,  ..., -0.7901, -0.7901, -0.7901],\n",
            "         [ 5.3335,  6.2787,  4.4414,  ..., -0.8423, -0.8423, -0.8423],\n",
            "         [ 5.7828,  6.5260,  4.6972,  ..., -0.8160, -0.8160, -0.8160]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.9306,  5.2939,  4.0363,  ..., -1.0643, -1.0643, -1.0643],\n",
            "         [ 5.9696,  7.0196,  6.4272,  ..., -1.1607, -1.1607, -1.1607],\n",
            "         [ 4.8381,  6.6483,  5.7805,  ..., -0.9565, -0.9565, -0.9565],\n",
            "         ...,\n",
            "         [ 5.8919,  8.1642,  5.8018,  ..., -0.9101, -0.9101, -0.9101],\n",
            "         [ 4.7165,  8.6331,  5.5435,  ..., -0.8413, -0.8413, -0.8413],\n",
            "         [ 4.7299,  8.7683,  5.6086,  ..., -0.8081, -0.8081, -0.8081]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 3.4442,  5.1484,  4.5802,  ..., -1.0858, -1.0858, -1.0858],\n",
            "         [ 3.7886,  5.6956,  5.0854,  ..., -1.1002, -1.1002, -1.1002],\n",
            "         [ 4.6241,  6.5434,  6.3154,  ..., -1.1487, -1.1487, -1.1487],\n",
            "         ...,\n",
            "         [ 5.1058,  6.4430,  6.7753,  ..., -1.0641, -1.0641, -1.0641],\n",
            "         [ 5.8185,  6.1406,  6.7187,  ..., -1.0539, -1.0539, -1.0539],\n",
            "         [ 6.4260,  7.5679,  6.8512,  ..., -1.0344, -1.0344, -1.0344]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 193, 20108])\n",
            "tensor([[[ 2.9050,  4.9953,  4.1829,  ..., -1.0668, -1.0668, -1.0668],\n",
            "         [ 3.0560,  6.1124,  4.6657,  ..., -1.1010, -1.1010, -1.1010],\n",
            "         [ 3.5551,  6.2977,  4.5557,  ..., -1.1034, -1.1034, -1.1034],\n",
            "         ...,\n",
            "         [ 3.8126,  3.9084,  3.7953,  ..., -0.7007, -0.7007, -0.7007],\n",
            "         [ 3.4092,  4.0099,  3.8228,  ..., -0.6426, -0.6426, -0.6426],\n",
            "         [ 3.2989,  4.2872,  3.7792,  ..., -0.6392, -0.6392, -0.6392]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 4.5947,  6.8516,  6.4982,  ..., -0.9449, -0.9449, -0.9449],\n",
            "         [ 6.5291,  8.3403,  9.0227,  ..., -1.1014, -1.1014, -1.1014],\n",
            "         [ 5.9619,  7.4660,  8.5396,  ..., -1.1394, -1.1394, -1.1394],\n",
            "         ...,\n",
            "         [ 5.9018,  8.4160,  9.0278,  ..., -1.0655, -1.0655, -1.0655],\n",
            "         [ 6.0232,  8.6022,  8.9699,  ..., -1.0179, -1.0179, -1.0179],\n",
            "         [ 6.4276,  8.4905,  8.4103,  ..., -1.0466, -1.0466, -1.0466]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 3.8967,  6.2114,  4.8483,  ..., -1.0943, -1.0943, -1.0943],\n",
            "         [ 2.6612,  6.4728,  4.5920,  ..., -1.1020, -1.1020, -1.1020],\n",
            "         [ 3.0879,  5.7466,  3.8154,  ..., -1.1136, -1.1136, -1.1136],\n",
            "         ...,\n",
            "         [ 2.9953,  5.7300,  3.7453,  ..., -1.0417, -1.0417, -1.0417],\n",
            "         [ 2.9937,  5.2859,  3.1804,  ..., -1.0161, -1.0161, -1.0161],\n",
            "         [ 3.3953,  7.0471,  5.2795,  ..., -1.0316, -1.0316, -1.0316]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 96, 20108])\n",
            "tensor([[[ 3.5003,  6.5599,  5.5286,  ..., -1.1070, -1.1070, -1.1070],\n",
            "         [ 3.5079,  5.9476,  4.5103,  ..., -1.0964, -1.0964, -1.0964],\n",
            "         [ 3.2065,  6.3013,  4.4492,  ..., -1.0995, -1.0995, -1.0995],\n",
            "         ...,\n",
            "         [ 2.1088,  4.9288,  3.8840,  ..., -0.6460, -0.6460, -0.6460],\n",
            "         [ 2.1958,  6.2947,  4.8533,  ..., -0.6280, -0.6280, -0.6280],\n",
            "         [ 2.6798,  5.7141,  5.0630,  ..., -0.5780, -0.5780, -0.5780]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 3.2144,  5.4949,  3.9847,  ..., -1.0405, -1.0405, -1.0405],\n",
            "         [ 2.9451,  4.4916,  3.8495,  ..., -1.0020, -1.0020, -1.0020],\n",
            "         [ 2.9732,  5.1232,  3.6622,  ..., -1.0023, -1.0023, -1.0023],\n",
            "         ...,\n",
            "         [ 4.6560,  6.7156,  5.2728,  ..., -0.8003, -0.8003, -0.8003],\n",
            "         [ 4.5966,  6.6905,  5.8314,  ..., -0.7602, -0.7602, -0.7602],\n",
            "         [ 4.7731,  5.8798,  5.3261,  ..., -0.8192, -0.8192, -0.8192]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 4.0739,  4.5440,  2.6237,  ..., -0.5626, -0.5626, -0.5626],\n",
            "         [ 3.3844,  4.3545,  2.5205,  ..., -0.4393, -0.4393, -0.4393],\n",
            "         [ 4.5520,  4.4750,  2.1936,  ..., -0.4163, -0.4163, -0.4163],\n",
            "         ...,\n",
            "         [ 5.7157,  4.5599,  2.2278,  ..., -0.3470, -0.3470, -0.3470],\n",
            "         [ 6.0580,  4.0459,  2.7254,  ..., -0.4347, -0.4347, -0.4347],\n",
            "         [ 5.7918,  3.0981,  1.6077,  ..., -0.3404, -0.3404, -0.3404]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 69, 20108])\n",
            "tensor([[[ 4.0146,  4.6146,  2.5848,  ..., -0.4867, -0.4867, -0.4867],\n",
            "         [ 3.9693,  4.6229,  2.4875,  ..., -0.4691, -0.4691, -0.4691],\n",
            "         [ 3.7938,  4.9278,  2.5357,  ..., -0.4403, -0.4403, -0.4403],\n",
            "         ...,\n",
            "         [ 5.7889, -0.4550, -2.3293,  ..., -0.3550, -0.3550, -0.3550],\n",
            "         [ 5.8048, -0.1386, -1.9398,  ..., -0.3781, -0.3781, -0.3781],\n",
            "         [ 6.3267, -0.6674, -1.8110,  ..., -0.3192, -0.3192, -0.3192]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 4.9736,  7.6761,  6.1179,  ..., -0.9886, -0.9886, -0.9886],\n",
            "         [ 5.9401,  7.3405,  6.7828,  ..., -1.1409, -1.1409, -1.1409],\n",
            "         [ 5.7331,  6.9121,  6.9975,  ..., -1.1611, -1.1611, -1.1611],\n",
            "         ...,\n",
            "         [ 6.5736,  6.9064,  5.6988,  ..., -0.7838, -0.7838, -0.7838],\n",
            "         [ 7.1928,  6.4802,  5.0668,  ..., -0.7619, -0.7619, -0.7619],\n",
            "         [ 6.6416,  6.5707,  5.1950,  ..., -0.7808, -0.7808, -0.7808]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 56, 20108])\n",
            "tensor([[[ 6.3514,  6.1393,  5.2944,  ..., -0.8922, -0.8922, -0.8922],\n",
            "         [ 6.0970,  6.5231,  6.8286,  ..., -1.0899, -1.0899, -1.0899],\n",
            "         [ 6.4796,  6.8099,  6.1083,  ..., -1.0128, -1.0128, -1.0128],\n",
            "         ...,\n",
            "         [ 7.2520,  5.1273,  4.3527,  ..., -0.8855, -0.8855, -0.8855],\n",
            "         [ 7.0605,  5.5186,  4.8243,  ..., -0.8937, -0.8937, -0.8937],\n",
            "         [ 6.9650,  5.4715,  4.5255,  ..., -0.9018, -0.9018, -0.9018]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 3.4046,  5.0362,  2.4577,  ..., -0.5091, -0.5091, -0.5091],\n",
            "         [ 3.3830,  4.6440,  2.0594,  ..., -0.4393, -0.4393, -0.4393],\n",
            "         [ 4.9789,  2.9309,  0.7896,  ..., -0.4937, -0.4937, -0.4937],\n",
            "         ...,\n",
            "         [ 5.8786,  2.6607,  1.6619,  ..., -0.4146, -0.4146, -0.4146],\n",
            "         [ 5.8102,  3.2748,  2.3613,  ..., -0.3446, -0.3446, -0.3446],\n",
            "         [ 6.2054,  3.1277,  2.3732,  ..., -0.3684, -0.3684, -0.3684]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 13, 20108])\n",
            "tensor([[[ 6.2856,  7.1144,  6.8523,  ..., -1.1007, -1.1007, -1.1007],\n",
            "         [ 5.4901,  6.9470,  6.8837,  ..., -1.0943, -1.0943, -1.0943],\n",
            "         [ 6.1039,  7.9872,  7.3764,  ..., -1.1185, -1.1185, -1.1185],\n",
            "         ...,\n",
            "         [ 6.3345,  6.0294,  5.8060,  ..., -1.0977, -1.0977, -1.0977],\n",
            "         [ 5.9469,  5.9997,  6.1601,  ..., -1.1383, -1.1383, -1.1383],\n",
            "         [ 5.4096,  5.3404,  5.4110,  ..., -1.0315, -1.0315, -1.0315]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 3.5372,  6.4207,  4.5403,  ..., -1.1068, -1.1068, -1.1068],\n",
            "         [ 3.2519,  6.0574,  4.2817,  ..., -1.0858, -1.0858, -1.0858],\n",
            "         [ 3.5583,  6.2333,  4.4207,  ..., -1.0927, -1.0927, -1.0927],\n",
            "         ...,\n",
            "         [ 2.9730,  7.4679,  4.3973,  ..., -0.8546, -0.8546, -0.8546],\n",
            "         [ 4.8780,  9.3668,  5.7783,  ..., -0.8784, -0.8784, -0.8784],\n",
            "         [ 4.6454,  9.4561,  6.9837,  ..., -0.9520, -0.9520, -0.9520]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 87, 20108])\n",
            "tensor([[[ 5.6432,  5.8049,  4.2914,  ..., -0.6349, -0.6349, -0.6349],\n",
            "         [ 7.1465,  8.6722,  7.5068,  ..., -0.9429, -0.9429, -0.9429],\n",
            "         [ 7.0143,  8.7200,  9.3919,  ..., -0.8873, -0.8873, -0.8873],\n",
            "         ...,\n",
            "         [ 5.2142,  4.8604,  4.8513,  ..., -0.8235, -0.8235, -0.8235],\n",
            "         [ 5.3977,  4.4151,  4.5814,  ..., -0.8584, -0.8584, -0.8584],\n",
            "         [ 5.4645,  4.2871,  4.6128,  ..., -0.8342, -0.8342, -0.8342]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 3.2174,  5.1411,  3.9288,  ..., -1.0469, -1.0469, -1.0469],\n",
            "         [ 2.8788,  5.5350,  3.8017,  ..., -1.0926, -1.0926, -1.0926],\n",
            "         [ 2.3230,  5.2357,  3.6872,  ..., -1.0460, -1.0460, -1.0460],\n",
            "         ...,\n",
            "         [ 4.2919,  7.9264,  6.6242,  ..., -0.9148, -0.9148, -0.9148],\n",
            "         [ 4.9550,  7.6647,  6.4500,  ..., -0.9656, -0.9656, -0.9656],\n",
            "         [ 4.4777,  8.0301,  6.8181,  ..., -0.9203, -0.9203, -0.9203]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 257, 20108])\n",
            "tensor([[[ 3.4151,  6.9436,  4.7839,  ..., -0.9625, -0.9625, -0.9625],\n",
            "         [ 3.8201,  6.0152,  3.7158,  ..., -0.9960, -0.9960, -0.9960],\n",
            "         [ 2.5148,  6.2953,  4.1175,  ..., -0.9102, -0.9102, -0.9102],\n",
            "         ...,\n",
            "         [ 3.0842,  2.5955,  3.0804,  ..., -0.6367, -0.6367, -0.6367],\n",
            "         [ 3.2892,  3.1184,  3.4331,  ..., -0.6210, -0.6210, -0.6210],\n",
            "         [ 3.1582,  2.9610,  2.8871,  ..., -0.6231, -0.6231, -0.6231]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 5.0807,  7.3935,  6.1433,  ..., -1.0550, -1.0550, -1.0550],\n",
            "         [ 3.8179,  6.8956,  5.1721,  ..., -1.0476, -1.0476, -1.0476],\n",
            "         [ 3.2251,  6.5878,  5.1917,  ..., -1.1231, -1.1231, -1.1231],\n",
            "         ...,\n",
            "         [ 4.0118,  6.1234,  5.9388,  ..., -1.0454, -1.0454, -1.0454],\n",
            "         [ 3.5974,  6.8087,  6.6169,  ..., -0.9861, -0.9861, -0.9861],\n",
            "         [ 3.0544,  6.8442,  6.4761,  ..., -1.0216, -1.0216, -1.0216]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 4.3491,  4.6478,  2.6303,  ..., -0.4990, -0.4990, -0.4990],\n",
            "         [ 5.3105,  4.5461,  2.3765,  ..., -0.5401, -0.5401, -0.5401],\n",
            "         [ 4.2994,  4.1365,  2.2987,  ..., -0.5149, -0.5149, -0.5149],\n",
            "         ...,\n",
            "         [ 6.0273,  4.4409,  3.1092,  ..., -0.4085, -0.4085, -0.4085],\n",
            "         [ 5.9972,  3.9119,  2.3191,  ..., -0.3240, -0.3240, -0.3240],\n",
            "         [ 5.9645,  2.7291,  1.8769,  ..., -0.4454, -0.4454, -0.4454]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 5.4050,  6.7596,  6.4226,  ..., -1.1308, -1.1308, -1.1308],\n",
            "         [ 3.6380,  5.9049,  4.6573,  ..., -1.0333, -1.0333, -1.0333],\n",
            "         [ 5.7937,  7.7480,  6.8917,  ..., -1.0870, -1.0870, -1.0870],\n",
            "         ...,\n",
            "         [ 4.3040,  3.6436,  4.4385,  ..., -0.8153, -0.8153, -0.8153],\n",
            "         [ 3.7425,  3.1614,  3.7823,  ..., -0.8289, -0.8289, -0.8289],\n",
            "         [ 3.1555,  3.1726,  3.6250,  ..., -0.8262, -0.8262, -0.8262]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 4.5137,  6.6217,  6.0328,  ..., -1.1255, -1.1255, -1.1255],\n",
            "         [ 3.5547,  5.6746,  5.0788,  ..., -0.9871, -0.9871, -0.9871],\n",
            "         [ 3.2968,  4.9158,  5.2646,  ..., -1.0491, -1.0491, -1.0491],\n",
            "         ...,\n",
            "         [ 5.5988,  7.8690,  7.2154,  ..., -0.9023, -0.9023, -0.9023],\n",
            "         [ 5.0698,  6.9728,  7.0421,  ..., -0.8632, -0.8632, -0.8632],\n",
            "         [ 4.7548,  7.5633,  6.8052,  ..., -0.8569, -0.8569, -0.8569]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 77, 20108])\n",
            "tensor([[[ 3.1977,  5.2828,  4.2198,  ..., -1.0641, -1.0641, -1.0641],\n",
            "         [ 2.8264,  5.4760,  3.5538,  ..., -1.0523, -1.0523, -1.0523],\n",
            "         [ 3.6593,  5.3643,  4.3523,  ..., -1.0408, -1.0408, -1.0408],\n",
            "         ...,\n",
            "         [ 4.0889,  4.5228,  4.4613,  ..., -0.7442, -0.7442, -0.7442],\n",
            "         [ 3.8754,  4.4064,  4.4315,  ..., -0.6986, -0.6986, -0.6986],\n",
            "         [ 3.4492,  4.0970,  4.2255,  ..., -0.6603, -0.6603, -0.6603]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 3.4146,  4.7669,  2.5669,  ..., -0.5942, -0.5942, -0.5942],\n",
            "         [ 2.4089,  4.5214,  2.6262,  ..., -0.4211, -0.4211, -0.4211],\n",
            "         [ 3.2446,  4.6535,  3.0467,  ..., -0.4861, -0.4861, -0.4861],\n",
            "         ...,\n",
            "         [ 6.1322,  2.3170,  0.7979,  ..., -0.3844, -0.3844, -0.3844],\n",
            "         [ 6.6162,  1.3625, -0.0738,  ..., -0.3892, -0.3892, -0.3892],\n",
            "         [ 5.8682,  1.1837, -0.3913,  ..., -0.3446, -0.3446, -0.3446]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 44, 20108])\n",
            "tensor([[[ 5.3817,  6.6779,  6.8889,  ..., -0.9913, -0.9913, -0.9913],\n",
            "         [ 4.9393,  6.6307,  6.4986,  ..., -1.0561, -1.0561, -1.0561],\n",
            "         [ 5.5298,  6.5463,  6.6234,  ..., -1.0979, -1.0979, -1.0979],\n",
            "         ...,\n",
            "         [ 7.7317,  4.6677,  4.5774,  ..., -1.0021, -1.0021, -1.0021],\n",
            "         [ 7.4218,  3.7536,  4.4639,  ..., -0.9678, -0.9678, -0.9678],\n",
            "         [ 6.8751,  3.5620,  4.0407,  ..., -0.9501, -0.9501, -0.9501]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 56, 20108])\n",
            "tensor([[[ 8.1030,  9.7585,  8.2831,  ..., -0.9506, -0.9506, -0.9506],\n",
            "         [ 8.3541,  9.9986,  8.8247,  ..., -1.0598, -1.0598, -1.0598],\n",
            "         [ 6.9848,  9.7880,  8.7158,  ..., -1.0579, -1.0579, -1.0579],\n",
            "         ...,\n",
            "         [ 6.1952,  8.1034,  7.7898,  ..., -0.8605, -0.8605, -0.8605],\n",
            "         [ 6.4569,  8.0209,  7.7866,  ..., -0.9235, -0.9235, -0.9235],\n",
            "         [ 6.9052,  7.3332,  7.0704,  ..., -0.9339, -0.9339, -0.9339]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 2.1450,  5.3287,  3.2813,  ..., -0.8290, -0.8290, -0.8290],\n",
            "         [ 2.6499,  7.2357,  5.0353,  ..., -0.8670, -0.8670, -0.8670],\n",
            "         [ 3.4541,  8.3925,  6.4427,  ..., -0.8771, -0.8771, -0.8771],\n",
            "         ...,\n",
            "         [ 5.3896,  9.0339,  7.1683,  ..., -0.8609, -0.8609, -0.8609],\n",
            "         [ 5.5304,  8.6615,  6.7214,  ..., -0.9533, -0.9533, -0.9533],\n",
            "         [ 4.6353,  8.2865,  6.1488,  ..., -0.8940, -0.8940, -0.8940]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 41, 20108])\n",
            "tensor([[[ 6.3209,  6.5356,  4.4430,  ..., -0.5340, -0.5340, -0.5340],\n",
            "         [ 6.2884,  4.1463,  2.4582,  ..., -0.4469, -0.4469, -0.4469],\n",
            "         [ 5.7198,  3.4799,  1.6331,  ..., -0.4328, -0.4328, -0.4328],\n",
            "         ...,\n",
            "         [ 8.2866,  3.5412,  2.5667,  ..., -0.6242, -0.6242, -0.6242],\n",
            "         [ 8.0136,  3.6919,  2.3879,  ..., -0.6227, -0.6227, -0.6227],\n",
            "         [ 7.7643,  3.4655,  2.3161,  ..., -0.6002, -0.6002, -0.6002]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 4.4620,  7.1372,  5.6645,  ..., -0.8368, -0.8368, -0.8368],\n",
            "         [ 4.1014,  5.6612,  5.5283,  ..., -0.9831, -0.9831, -0.9831],\n",
            "         [ 5.4429,  6.8576,  6.0417,  ..., -1.0412, -1.0412, -1.0412],\n",
            "         ...,\n",
            "         [ 5.7777,  5.7892,  6.2325,  ..., -0.9573, -0.9573, -0.9573],\n",
            "         [ 4.9915,  5.2902,  6.1869,  ..., -0.9677, -0.9677, -0.9677],\n",
            "         [ 5.6199,  4.8321,  5.4542,  ..., -1.0283, -1.0283, -1.0283]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 2.7892,  4.8876,  4.0449,  ..., -1.0699, -1.0699, -1.0699],\n",
            "         [ 2.6473,  5.1141,  4.0679,  ..., -1.0672, -1.0672, -1.0672],\n",
            "         [ 2.7654,  5.2971,  3.4810,  ..., -1.0331, -1.0331, -1.0331],\n",
            "         ...,\n",
            "         [ 3.9420,  7.4260,  7.3772,  ..., -0.8549, -0.8549, -0.8549],\n",
            "         [ 3.7334,  6.7295,  6.1521,  ..., -0.9198, -0.9198, -0.9198],\n",
            "         [ 3.7210,  6.4944,  5.7411,  ..., -0.9069, -0.9069, -0.9069]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 123, 20108])\n",
            "tensor([[[ 5.0827,  8.3419,  5.7974,  ..., -1.0054, -1.0054, -1.0054],\n",
            "         [ 3.8781,  8.8346,  6.8436,  ..., -0.9979, -0.9979, -0.9979],\n",
            "         [ 5.0459,  8.4598,  7.4189,  ..., -1.0678, -1.0678, -1.0678],\n",
            "         ...,\n",
            "         [ 4.2238,  4.5189,  3.6241,  ..., -0.8827, -0.8827, -0.8827],\n",
            "         [ 3.6800,  5.0707,  4.0476,  ..., -0.8771, -0.8771, -0.8771],\n",
            "         [ 3.9145,  6.8292,  4.3614,  ..., -0.8680, -0.8680, -0.8680]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 3.4154,  4.8802,  2.9584,  ..., -0.5682, -0.5682, -0.5682],\n",
            "         [ 5.2515,  5.8331,  3.5541,  ..., -0.4823, -0.4823, -0.4823],\n",
            "         [ 4.8390,  5.1859,  3.0045,  ..., -0.3963, -0.3963, -0.3963],\n",
            "         [ 5.7021,  5.0566,  2.3925,  ..., -0.3358, -0.3358, -0.3358]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 163, 20108])\n",
            "tensor([[[ 5.1168,  7.0891,  6.4366,  ..., -1.1653, -1.1653, -1.1653],\n",
            "         [ 6.2782,  7.6078,  6.3770,  ..., -1.0730, -1.0730, -1.0730],\n",
            "         [ 5.8623,  7.7161,  6.2854,  ..., -0.9943, -0.9943, -0.9943],\n",
            "         ...,\n",
            "         [ 4.5119,  6.6253,  6.7817,  ..., -0.8890, -0.8890, -0.8890],\n",
            "         [ 3.7969,  5.9005,  6.1627,  ..., -0.8723, -0.8723, -0.8723],\n",
            "         [ 3.6235,  5.1412,  5.5464,  ..., -0.8799, -0.8799, -0.8799]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 2.9493,  5.3331,  2.8569,  ..., -0.4895, -0.4895, -0.4895],\n",
            "         [ 4.3242,  5.1014,  2.5879,  ..., -0.4984, -0.4984, -0.4984],\n",
            "         [ 3.9488,  4.2855,  2.2010,  ..., -0.4612, -0.4612, -0.4612],\n",
            "         ...,\n",
            "         [ 5.7188,  4.6927,  2.7777,  ..., -0.3594, -0.3594, -0.3594],\n",
            "         [ 6.0583,  4.7804,  2.7398,  ..., -0.3946, -0.3946, -0.3946],\n",
            "         [ 6.2882,  5.5342,  3.0242,  ..., -0.4263, -0.4263, -0.4263]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 48, 20108])\n",
            "tensor([[[ 4.7522,  7.9215,  5.8072,  ..., -0.9452, -0.9452, -0.9452],\n",
            "         [ 5.3781,  8.0991,  6.9754,  ..., -0.9836, -0.9836, -0.9836],\n",
            "         [ 4.5595,  8.3667,  5.8688,  ..., -0.9194, -0.9194, -0.9194],\n",
            "         ...,\n",
            "         [ 6.2649,  4.8959,  4.7112,  ..., -0.9476, -0.9476, -0.9476],\n",
            "         [ 6.8167,  5.0209,  4.5203,  ..., -0.9064, -0.9064, -0.9064],\n",
            "         [ 6.4542,  5.2768,  4.8166,  ..., -0.9459, -0.9459, -0.9459]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 159, 20108])\n",
            "tensor([[[ 2.5543,  5.0179,  3.8822,  ..., -1.0465, -1.0465, -1.0465],\n",
            "         [ 2.0943,  5.5324,  4.0527,  ..., -0.9288, -0.9288, -0.9288],\n",
            "         [ 1.7234,  5.7338,  3.7511,  ..., -0.9596, -0.9596, -0.9596],\n",
            "         ...,\n",
            "         [ 3.1199,  4.2727,  3.5140,  ..., -0.9044, -0.9044, -0.9044],\n",
            "         [ 3.1154,  4.8625,  4.1267,  ..., -0.9772, -0.9772, -0.9772],\n",
            "         [ 3.1100,  4.6703,  4.0547,  ..., -0.9533, -0.9533, -0.9533]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 27, 20108])\n",
            "tensor([[[ 5.2501,  6.8940,  6.7535,  ..., -1.1122, -1.1122, -1.1122],\n",
            "         [ 5.2414,  7.2945,  6.7933,  ..., -1.0952, -1.0952, -1.0952],\n",
            "         [ 4.9704,  7.9276,  7.2540,  ..., -0.9975, -0.9975, -0.9975],\n",
            "         ...,\n",
            "         [ 2.8615,  6.1217,  5.6719,  ..., -0.7683, -0.7683, -0.7683],\n",
            "         [ 2.4118,  5.6620,  6.2816,  ..., -0.7863, -0.7863, -0.7863],\n",
            "         [ 2.8941,  5.4461,  6.6612,  ..., -0.7988, -0.7988, -0.7988]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 3.1410,  4.4062,  2.5640,  ..., -0.5366, -0.5366, -0.5366],\n",
            "         [ 3.2320,  4.6289,  2.5619,  ..., -0.4110, -0.4110, -0.4110],\n",
            "         [ 3.8111,  4.9830,  2.4182,  ..., -0.3246, -0.3246, -0.3246],\n",
            "         ...,\n",
            "         [ 5.3576,  4.2683,  1.9776,  ..., -0.2696, -0.2696, -0.2696],\n",
            "         [ 5.3267,  4.0683,  2.7528,  ..., -0.3259, -0.3259, -0.3259],\n",
            "         [ 5.0590,  4.5654,  2.8462,  ..., -0.3462, -0.3462, -0.3462]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 4.5640,  6.3139,  6.1058,  ..., -1.0562, -1.0562, -1.0562],\n",
            "         [ 3.5738,  6.8692,  5.4871,  ..., -0.9732, -0.9732, -0.9732],\n",
            "         [ 4.9684,  7.1255,  6.4770,  ..., -1.1231, -1.1231, -1.1231],\n",
            "         ...,\n",
            "         [ 6.5138,  9.2342,  8.0001,  ..., -0.9584, -0.9584, -0.9584],\n",
            "         [ 6.2695,  8.8876,  7.8775,  ..., -0.9603, -0.9603, -0.9603],\n",
            "         [ 5.5984,  8.1298,  7.3839,  ..., -0.9795, -0.9795, -0.9795]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.9503,  6.1954,  5.5093,  ..., -0.9854, -0.9854, -0.9854],\n",
            "         [ 2.6612,  6.0851,  5.4045,  ..., -0.9954, -0.9954, -0.9954],\n",
            "         [ 3.7217,  6.9581,  6.1788,  ..., -1.0482, -1.0482, -1.0482],\n",
            "         ...,\n",
            "         [ 4.2770,  6.2616,  6.3429,  ..., -1.0190, -1.0190, -1.0190],\n",
            "         [ 3.5399,  6.0971,  6.0830,  ..., -0.8478, -0.8478, -0.8478],\n",
            "         [ 4.1096,  6.5243,  6.9705,  ..., -1.0349, -1.0349, -1.0349]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 5.7943,  5.6792,  4.1702,  ..., -0.5176, -0.5176, -0.5176],\n",
            "         [ 5.4976,  5.4874,  3.2326,  ..., -0.4257, -0.4257, -0.4257],\n",
            "         [ 4.6732,  4.2193,  2.4255,  ..., -0.3788, -0.3788, -0.3788],\n",
            "         ...,\n",
            "         [ 5.6010,  2.9516,  0.8694,  ..., -0.3934, -0.3934, -0.3934],\n",
            "         [ 5.7760,  2.7402,  1.1386,  ..., -0.5069, -0.5069, -0.5069],\n",
            "         [ 6.0436,  3.1905,  1.4297,  ..., -0.5244, -0.5244, -0.5244]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 150, 20108])\n",
            "tensor([[[ 3.1630,  6.4398,  5.2202,  ..., -1.0223, -1.0223, -1.0223],\n",
            "         [ 3.8320,  6.2008,  5.3632,  ..., -1.0859, -1.0859, -1.0859],\n",
            "         [ 4.2150,  5.9187,  4.8294,  ..., -1.0276, -1.0276, -1.0276],\n",
            "         ...,\n",
            "         [ 2.9370,  4.0442,  4.2692,  ..., -0.8627, -0.8627, -0.8627],\n",
            "         [ 3.0732,  4.2304,  4.1031,  ..., -0.8298, -0.8298, -0.8298],\n",
            "         [ 2.7432,  3.2728,  3.9315,  ..., -0.7542, -0.7542, -0.7542]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 41, 20108])\n",
            "tensor([[[ 3.4930,  5.3713,  4.0027,  ..., -1.0065, -1.0065, -1.0065],\n",
            "         [ 4.0332,  6.2076,  4.9317,  ..., -0.9935, -0.9935, -0.9935],\n",
            "         [ 3.4208,  6.1352,  4.5521,  ..., -0.9365, -0.9365, -0.9365],\n",
            "         ...,\n",
            "         [ 4.4554,  7.7464,  5.7180,  ..., -0.8383, -0.8383, -0.8383],\n",
            "         [ 4.2369,  6.9026,  5.1998,  ..., -0.8568, -0.8568, -0.8568],\n",
            "         [ 4.6586,  6.8222,  5.1204,  ..., -0.8887, -0.8887, -0.8887]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 6.9635,  7.6383,  7.2544,  ..., -1.1590, -1.1590, -1.1590],\n",
            "         [ 6.9804,  8.3709,  7.9158,  ..., -1.1072, -1.1072, -1.1072],\n",
            "         [ 7.1009,  8.0028,  8.1579,  ..., -1.1058, -1.1058, -1.1058],\n",
            "         ...,\n",
            "         [ 3.7151,  4.9408,  4.9501,  ..., -0.9762, -0.9762, -0.9762],\n",
            "         [ 4.3032,  6.0879,  6.0521,  ..., -0.9635, -0.9635, -0.9635],\n",
            "         [ 3.8876,  5.3317,  5.0459,  ..., -0.9497, -0.9497, -0.9497]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 3.7536,  5.1258,  2.7570,  ..., -0.5305, -0.5305, -0.5305],\n",
            "         [ 3.4185,  4.8872,  2.8877,  ..., -0.4697, -0.4697, -0.4697],\n",
            "         [ 3.9712,  4.6841,  2.5315,  ..., -0.4232, -0.4232, -0.4232],\n",
            "         ...,\n",
            "         [ 5.6671,  4.0619,  2.3523,  ..., -0.3640, -0.3640, -0.3640],\n",
            "         [ 6.4501,  4.2402,  2.1622,  ..., -0.4284, -0.4284, -0.4284],\n",
            "         [ 6.5687,  3.8505,  2.3448,  ..., -0.4485, -0.4485, -0.4485]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 80, 20108])\n",
            "tensor([[[ 4.4838,  5.0945,  3.9962,  ..., -1.0413, -1.0413, -1.0413],\n",
            "         [ 3.2341,  4.9845,  3.7421,  ..., -0.9974, -0.9974, -0.9974],\n",
            "         [ 2.7048,  5.4022,  3.5398,  ..., -0.9907, -0.9907, -0.9907],\n",
            "         ...,\n",
            "         [ 2.2187,  3.7385,  3.7839,  ..., -0.7483, -0.7483, -0.7483],\n",
            "         [ 2.7229,  4.7966,  4.4639,  ..., -0.8124, -0.8124, -0.8124],\n",
            "         [ 3.6821,  5.4841,  4.5457,  ..., -0.8522, -0.8522, -0.8522]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 127, 20108])\n",
            "tensor([[[ 5.1422,  6.4843,  6.6615,  ..., -1.1024, -1.1024, -1.1024],\n",
            "         [ 5.6904,  6.6837,  7.0621,  ..., -1.0939, -1.0939, -1.0939],\n",
            "         [ 5.5867,  6.6734,  7.6217,  ..., -1.0688, -1.0688, -1.0688],\n",
            "         ...,\n",
            "         [ 4.9611,  2.3840,  2.6233,  ..., -0.7728, -0.7728, -0.7728],\n",
            "         [ 6.7915,  3.5783,  3.4538,  ..., -0.8697, -0.8697, -0.8697],\n",
            "         [ 5.8796,  3.0385,  3.2163,  ..., -0.8462, -0.8462, -0.8462]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 3.2195,  5.7067,  2.9961,  ..., -0.5193, -0.5193, -0.5193],\n",
            "         [ 2.9294,  4.2313,  2.3860,  ..., -0.4542, -0.4542, -0.4542],\n",
            "         [ 2.8010,  4.5068,  2.2839,  ..., -0.3918, -0.3918, -0.3918],\n",
            "         ...,\n",
            "         [ 5.2702,  3.7804,  1.7375,  ..., -0.3147, -0.3147, -0.3147],\n",
            "         [ 5.1031,  4.7323,  2.0504,  ..., -0.3385, -0.3385, -0.3385],\n",
            "         [ 5.0828,  4.1636,  2.2798,  ..., -0.3514, -0.3514, -0.3514]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 74, 20108])\n",
            "tensor([[[ 3.4702,  4.8787,  4.2863,  ..., -1.0616, -1.0616, -1.0616],\n",
            "         [ 2.1594,  5.8568,  4.5808,  ..., -1.0149, -1.0149, -1.0149],\n",
            "         [ 2.5698,  6.0906,  4.9963,  ..., -1.0193, -1.0193, -1.0193],\n",
            "         ...,\n",
            "         [ 3.7839,  6.8430,  5.2904,  ..., -0.8652, -0.8652, -0.8652],\n",
            "         [ 3.0882,  5.9382,  4.5464,  ..., -0.9171, -0.9171, -0.9171],\n",
            "         [ 3.7925,  6.6076,  4.8551,  ..., -0.8330, -0.8330, -0.8330]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 69, 20108])\n",
            "tensor([[[ 1.8303,  3.9762,  2.7626,  ..., -0.8891, -0.8891, -0.8891],\n",
            "         [ 2.2959,  5.3974,  3.5666,  ..., -0.9665, -0.9665, -0.9665],\n",
            "         [ 2.9051,  5.7638,  3.4593,  ..., -0.9511, -0.9511, -0.9511],\n",
            "         ...,\n",
            "         [ 5.2277,  5.7948,  6.1065,  ..., -0.8203, -0.8203, -0.8203],\n",
            "         [ 5.3616,  6.0698,  6.8706,  ..., -0.8044, -0.8044, -0.8044],\n",
            "         [ 5.1777,  6.8528,  6.9109,  ..., -0.8232, -0.8232, -0.8232]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 3.0397,  4.4685,  2.2521,  ..., -0.4960, -0.4960, -0.4960],\n",
            "         [ 2.5149,  4.2030,  2.2778,  ..., -0.4330, -0.4330, -0.4330],\n",
            "         [ 3.9801,  4.6757,  2.4803,  ..., -0.4253, -0.4253, -0.4253],\n",
            "         ...,\n",
            "         [ 4.1638,  3.5832,  1.6168,  ..., -0.3151, -0.3151, -0.3151],\n",
            "         [ 4.1075,  3.5530,  1.5152,  ..., -0.2448, -0.2448, -0.2448],\n",
            "         [ 4.9634,  3.9454,  2.0044,  ..., -0.3410, -0.3410, -0.3410]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 38, 20108])\n",
            "tensor([[[ 2.6206,  5.1385,  4.2596,  ..., -1.0962, -1.0962, -1.0962],\n",
            "         [ 2.2718,  5.2693,  3.4975,  ..., -1.0170, -1.0170, -1.0170],\n",
            "         [ 2.0340,  5.0674,  3.4036,  ..., -1.0358, -1.0358, -1.0358],\n",
            "         ...,\n",
            "         [ 3.7016,  6.3903,  5.2016,  ..., -0.9492, -0.9492, -0.9492],\n",
            "         [ 3.4359,  6.3319,  5.2910,  ..., -0.9253, -0.9253, -0.9253],\n",
            "         [ 3.5960,  6.8949,  5.4778,  ..., -0.8825, -0.8825, -0.8825]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 3, 20108])\n",
            "tensor([[[ 2.6585,  6.4342,  4.0797,  ..., -0.8400, -0.8400, -0.8400],\n",
            "         [ 4.5713,  6.1354,  3.7966,  ..., -0.7468, -0.7468, -0.7468],\n",
            "         [ 4.7953,  4.9559,  2.8612,  ..., -0.5046, -0.5046, -0.5046]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 4.6961,  6.5047,  6.0276,  ..., -1.0417, -1.0417, -1.0417],\n",
            "         [ 4.3360,  6.1080,  5.7338,  ..., -1.0324, -1.0324, -1.0324],\n",
            "         [ 4.9806,  6.7281,  5.8251,  ..., -1.0328, -1.0328, -1.0328],\n",
            "         ...,\n",
            "         [ 5.1996,  5.1403,  5.0682,  ..., -1.0109, -1.0109, -1.0109],\n",
            "         [ 5.5390,  6.2054,  5.7593,  ..., -1.0105, -1.0105, -1.0105],\n",
            "         [ 6.4010,  5.9881,  5.8327,  ..., -1.0323, -1.0323, -1.0323]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 5.5285,  5.7990,  3.7253,  ..., -0.4461, -0.4461, -0.4461],\n",
            "         [ 6.3683,  4.5987,  2.6810,  ..., -0.4903, -0.4903, -0.4903],\n",
            "         [ 5.5424,  3.5702,  1.6316,  ..., -0.4217, -0.4217, -0.4217],\n",
            "         ...,\n",
            "         [ 5.1099,  3.6858,  1.2521,  ..., -0.2782, -0.2782, -0.2782],\n",
            "         [ 4.7430,  3.1982,  0.9726,  ..., -0.2358, -0.2358, -0.2358],\n",
            "         [ 4.8030,  2.7732,  0.5675,  ..., -0.2559, -0.2559, -0.2559]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 303, 20108])\n",
            "tensor([[[ 6.0229,  5.6906,  3.8129,  ..., -0.7154, -0.7154, -0.7154],\n",
            "         [ 6.2228,  7.8755,  6.0419,  ..., -0.8885, -0.8885, -0.8885],\n",
            "         [ 6.8450,  6.9592,  6.0690,  ..., -1.0140, -1.0140, -1.0140],\n",
            "         ...,\n",
            "         [ 3.6902,  3.9296,  4.6991,  ..., -0.7188, -0.7188, -0.7188],\n",
            "         [ 2.8353,  4.4417,  4.9467,  ..., -0.7312, -0.7312, -0.7312],\n",
            "         [ 4.4040,  5.4708,  5.7622,  ..., -0.8572, -0.8572, -0.8572]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 111, 20108])\n",
            "tensor([[[ 5.3509,  7.2491,  6.1373,  ..., -1.0522, -1.0522, -1.0522],\n",
            "         [ 6.0430,  7.1880,  6.7079,  ..., -1.0436, -1.0436, -1.0436],\n",
            "         [ 7.4399,  6.1943,  5.0217,  ..., -0.9172, -0.9172, -0.9172],\n",
            "         ...,\n",
            "         [ 5.1190,  6.3531,  5.3484,  ..., -0.9974, -0.9974, -0.9974],\n",
            "         [ 4.9183,  5.9438,  5.2341,  ..., -0.9938, -0.9938, -0.9938],\n",
            "         [ 4.8508,  6.0160,  5.2400,  ..., -1.0203, -1.0203, -1.0203]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 30, 20108])\n",
            "tensor([[[ 5.7123,  7.1902,  6.9174,  ..., -1.0475, -1.0475, -1.0475],\n",
            "         [ 5.2322,  7.7127,  7.8674,  ..., -1.0284, -1.0284, -1.0284],\n",
            "         [ 5.3222,  7.4249,  6.9402,  ..., -1.0249, -1.0249, -1.0249],\n",
            "         ...,\n",
            "         [ 5.5934,  7.0889,  6.7485,  ..., -0.9345, -0.9345, -0.9345],\n",
            "         [ 5.9219,  7.4635,  6.6915,  ..., -0.9156, -0.9156, -0.9156],\n",
            "         [ 6.5757,  6.8813,  6.4881,  ..., -0.9362, -0.9362, -0.9362]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 4.4540,  6.3461,  6.2020,  ..., -1.1279, -1.1279, -1.1279],\n",
            "         [ 4.3349,  5.0876,  5.4523,  ..., -1.0667, -1.0667, -1.0667],\n",
            "         [ 4.7472,  6.1165,  5.7051,  ..., -0.9901, -0.9901, -0.9901],\n",
            "         ...,\n",
            "         [ 4.7666,  4.7024,  5.0247,  ..., -0.9486, -0.9486, -0.9486],\n",
            "         [ 5.4269,  3.9857,  4.7621,  ..., -0.8882, -0.8882, -0.8882],\n",
            "         [ 4.9643,  4.2375,  4.9970,  ..., -0.9266, -0.9266, -0.9266]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 79, 20108])\n",
            "tensor([[[ 5.1604,  8.0841,  7.1768,  ..., -1.1898, -1.1898, -1.1898],\n",
            "         [ 4.4033,  7.6440,  6.9364,  ..., -1.1057, -1.1057, -1.1057],\n",
            "         [ 4.4805,  7.3174,  6.6147,  ..., -1.1025, -1.1025, -1.1025],\n",
            "         ...,\n",
            "         [ 5.2997,  3.7037,  3.8267,  ..., -0.8106, -0.8106, -0.8106],\n",
            "         [ 4.9504,  3.1770,  3.4994,  ..., -0.7390, -0.7390, -0.7390],\n",
            "         [ 4.3898,  3.4455,  3.4400,  ..., -0.7011, -0.7011, -0.7011]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 4, 20108])\n",
            "tensor([[[ 2.3674,  5.4096,  3.2528,  ..., -0.9695, -0.9695, -0.9695],\n",
            "         [ 3.4913,  7.2629,  5.9105,  ..., -1.1036, -1.1036, -1.1036],\n",
            "         [ 3.7619,  7.8339,  5.6457,  ..., -1.0838, -1.0838, -1.0838],\n",
            "         [ 3.7945,  8.1451,  7.0953,  ..., -1.0647, -1.0647, -1.0647]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 5.3371,  6.7301,  5.3705,  ..., -0.7794, -0.7794, -0.7794],\n",
            "         [ 4.4584,  5.2644,  3.3739,  ..., -0.5999, -0.5999, -0.5999],\n",
            "         [ 5.1948,  6.6645,  4.3551,  ..., -0.6267, -0.6267, -0.6267],\n",
            "         ...,\n",
            "         [ 5.4573,  4.9895,  2.5711,  ..., -0.3168, -0.3168, -0.3168],\n",
            "         [ 5.5830,  5.3171,  2.6310,  ..., -0.2780, -0.2780, -0.2780],\n",
            "         [ 5.2493,  5.4954,  3.1332,  ..., -0.2889, -0.2889, -0.2889]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 101, 20108])\n",
            "tensor([[[ 5.6691,  6.5888,  5.9659,  ..., -1.0746, -1.0746, -1.0746],\n",
            "         [ 4.9561,  6.1840,  5.5084,  ..., -1.0479, -1.0479, -1.0479],\n",
            "         [ 4.9187,  5.9561,  5.6503,  ..., -1.0033, -1.0033, -1.0033],\n",
            "         ...,\n",
            "         [ 5.5772,  5.8231,  7.0068,  ..., -0.9399, -0.9399, -0.9399],\n",
            "         [ 4.7062,  5.6673,  6.7342,  ..., -0.9390, -0.9390, -0.9390],\n",
            "         [ 4.3701,  5.8160,  6.4918,  ..., -0.9678, -0.9678, -0.9678]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 77, 20108])\n",
            "tensor([[[ 4.9911,  6.9971,  5.6410,  ..., -1.0830, -1.0830, -1.0830],\n",
            "         [ 7.5607,  7.8639,  6.8212,  ..., -1.0550, -1.0550, -1.0550],\n",
            "         [ 7.2852,  7.2996,  7.0859,  ..., -1.0426, -1.0426, -1.0426],\n",
            "         ...,\n",
            "         [ 3.7228,  5.5325,  5.1572,  ..., -0.8305, -0.8305, -0.8305],\n",
            "         [ 3.5435,  5.3504,  4.8659,  ..., -0.8138, -0.8138, -0.8138],\n",
            "         [ 3.7312,  5.3129,  4.9283,  ..., -0.8391, -0.8391, -0.8391]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 297, 20108])\n",
            "tensor([[[ 2.4561,  5.2981,  3.9756,  ..., -0.9822, -0.9822, -0.9822],\n",
            "         [ 4.7459,  6.9453,  6.2590,  ..., -1.0577, -1.0577, -1.0577],\n",
            "         [ 5.0022,  6.4439,  6.5755,  ..., -1.0108, -1.0108, -1.0108],\n",
            "         ...,\n",
            "         [ 3.1625,  4.3937,  4.1061,  ..., -0.6174, -0.6174, -0.6174],\n",
            "         [ 3.0238,  4.4672,  3.5762,  ..., -0.5711, -0.5711, -0.5711],\n",
            "         [ 3.1656,  4.6716,  3.5760,  ..., -0.5598, -0.5598, -0.5598]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 2.8167,  5.7857,  3.2123,  ..., -0.6790, -0.6790, -0.6790],\n",
            "         [ 3.0842,  4.5969,  2.6603,  ..., -0.4968, -0.4968, -0.4968],\n",
            "         [ 2.7305,  4.0090,  2.4241,  ..., -0.3865, -0.3865, -0.3865],\n",
            "         ...,\n",
            "         [ 5.0559,  2.2322,  0.5922,  ..., -0.2286, -0.2286, -0.2286],\n",
            "         [ 4.7348,  2.7538,  0.6225,  ..., -0.2590, -0.2590, -0.2590],\n",
            "         [ 4.8925,  3.0262,  1.4074,  ..., -0.3185, -0.3185, -0.3185]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 82, 20108])\n",
            "tensor([[[ 4.5225,  6.9669,  5.5113,  ..., -1.0274, -1.0274, -1.0274],\n",
            "         [ 4.3815,  4.8674,  4.8591,  ..., -0.9000, -0.9000, -0.9000],\n",
            "         [ 4.2538,  5.2476,  4.8193,  ..., -0.8415, -0.8415, -0.8415],\n",
            "         ...,\n",
            "         [ 7.3808,  4.6127,  3.9058,  ..., -0.6760, -0.6760, -0.6760],\n",
            "         [ 7.6738,  4.8448,  4.6081,  ..., -0.7265, -0.7265, -0.7265],\n",
            "         [ 7.6822,  4.4663,  4.4035,  ..., -0.7527, -0.7527, -0.7527]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 137, 20108])\n",
            "tensor([[[ 4.7847,  7.4575,  6.3615,  ..., -1.1478, -1.1478, -1.1478],\n",
            "         [ 5.8148,  7.1606,  6.1344,  ..., -0.9969, -0.9969, -0.9969],\n",
            "         [ 5.1249,  7.0664,  6.1210,  ..., -0.9880, -0.9880, -0.9880],\n",
            "         ...,\n",
            "         [ 6.5173,  4.9247,  4.0094,  ..., -0.8196, -0.8196, -0.8196],\n",
            "         [ 6.1430,  4.3500,  3.5038,  ..., -0.8340, -0.8340, -0.8340],\n",
            "         [ 6.5309,  4.6913,  3.8012,  ..., -0.8799, -0.8799, -0.8799]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 478, 20108])\n",
            "tensor([[[ 4.2571,  7.3258,  5.5927,  ..., -1.0472, -1.0472, -1.0472],\n",
            "         [ 5.9553,  7.2544,  6.3409,  ..., -1.0461, -1.0461, -1.0461],\n",
            "         [ 5.0527,  6.9918,  5.6401,  ..., -0.9192, -0.9192, -0.9192],\n",
            "         ...,\n",
            "         [ 2.1644,  4.2394,  2.5560,  ..., -0.5854, -0.5854, -0.5854],\n",
            "         [ 2.9625,  4.3379,  2.9009,  ..., -0.6384, -0.6384, -0.6384],\n",
            "         [ 4.1211,  5.6433,  4.7700,  ..., -0.6853, -0.6853, -0.6853]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 83, 20108])\n",
            "tensor([[[ 2.6208,  5.7852,  4.3668,  ..., -1.0738, -1.0738, -1.0738],\n",
            "         [ 2.6988,  5.6420,  3.2886,  ..., -1.0237, -1.0237, -1.0237],\n",
            "         [ 1.8021,  5.2281,  3.3198,  ..., -1.0017, -1.0017, -1.0017],\n",
            "         ...,\n",
            "         [ 3.2530,  3.7386,  3.6864,  ..., -0.7252, -0.7252, -0.7252],\n",
            "         [ 3.3454,  3.0712,  3.3868,  ..., -0.6597, -0.6597, -0.6597],\n",
            "         [ 3.0644,  3.8395,  3.6833,  ..., -0.6626, -0.6626, -0.6626]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 1.8601,  4.3728,  2.7441,  ..., -0.9114, -0.9114, -0.9114],\n",
            "         [ 2.3159,  5.9393,  4.1776,  ..., -1.0497, -1.0497, -1.0497],\n",
            "         [ 2.2390,  5.2881,  3.6235,  ..., -0.9938, -0.9938, -0.9938],\n",
            "         ...,\n",
            "         [ 1.6855,  6.5787,  3.7791,  ..., -0.8510, -0.8510, -0.8510],\n",
            "         [ 1.6784,  6.6662,  4.4964,  ..., -0.7688, -0.7688, -0.7688],\n",
            "         [ 3.2837,  9.5605,  6.3984,  ..., -0.8611, -0.8611, -0.8611]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 74, 20108])\n",
            "tensor([[[ 4.0482,  6.2440,  4.8841,  ..., -1.0513, -1.0513, -1.0513],\n",
            "         [ 2.9509,  5.5676,  4.6255,  ..., -1.0364, -1.0364, -1.0364],\n",
            "         [ 3.4910,  6.2472,  5.2640,  ..., -1.1052, -1.1052, -1.1052],\n",
            "         ...,\n",
            "         [ 6.7253,  7.3676,  6.8437,  ..., -0.9482, -0.9482, -0.9482],\n",
            "         [ 7.3917,  7.0876,  6.8570,  ..., -0.9381, -0.9381, -0.9381],\n",
            "         [ 7.3967,  7.0292,  6.9686,  ..., -0.9057, -0.9057, -0.9057]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 26, 20108])\n",
            "tensor([[[ 3.6495,  5.4357,  4.1436,  ..., -1.0695, -1.0695, -1.0695],\n",
            "         [ 3.1319,  4.3723,  3.0233,  ..., -1.0062, -1.0062, -1.0062],\n",
            "         [ 3.4213,  5.0301,  4.0586,  ..., -1.0132, -1.0132, -1.0132],\n",
            "         ...,\n",
            "         [ 4.0145,  8.0521,  6.4116,  ..., -0.7400, -0.7400, -0.7400],\n",
            "         [ 4.4362,  8.1628,  5.9048,  ..., -0.6860, -0.6860, -0.6860],\n",
            "         [ 3.6234,  7.6236,  5.3628,  ..., -0.6690, -0.6690, -0.6690]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 2.7701,  4.3123,  4.0649,  ..., -0.9764, -0.9764, -0.9764],\n",
            "         [ 2.7063,  5.2784,  3.9420,  ..., -0.9523, -0.9523, -0.9523],\n",
            "         [ 0.8885,  5.9566,  4.2139,  ..., -0.9161, -0.9161, -0.9161],\n",
            "         [ 2.9985,  7.3882,  5.1882,  ..., -0.9471, -0.9471, -0.9471],\n",
            "         [ 3.5141,  8.5852,  7.5496,  ..., -1.0606, -1.0606, -1.0606],\n",
            "         [ 4.1042,  8.8341,  7.8076,  ..., -0.9531, -0.9531, -0.9531]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 2.6074,  5.6032,  4.9291,  ..., -1.0902, -1.0902, -1.0902],\n",
            "         [ 2.3111,  4.5345,  3.1118,  ..., -0.9798, -0.9798, -0.9798],\n",
            "         [ 1.4346,  5.4297,  3.6367,  ..., -0.8883, -0.8883, -0.8883],\n",
            "         ...,\n",
            "         [ 4.0224,  8.3292,  6.0600,  ..., -1.0150, -1.0150, -1.0150],\n",
            "         [ 2.8483,  7.7131,  5.8980,  ..., -0.9562, -0.9562, -0.9562],\n",
            "         [ 3.7705,  7.6680,  5.8278,  ..., -1.0002, -1.0002, -1.0002]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 55, 20108])\n",
            "tensor([[[ 5.4461,  6.0713,  6.4286,  ..., -1.0477, -1.0477, -1.0477],\n",
            "         [ 4.0937,  5.5216,  6.2755,  ..., -1.0025, -1.0025, -1.0025],\n",
            "         [ 4.4752,  6.5339,  7.4842,  ..., -0.9621, -0.9621, -0.9621],\n",
            "         ...,\n",
            "         [ 5.1705,  6.6352,  8.1154,  ..., -1.0173, -1.0173, -1.0173],\n",
            "         [ 5.7549,  6.9493,  7.5703,  ..., -1.0717, -1.0717, -1.0717],\n",
            "         [ 5.4222,  7.3220,  7.1385,  ..., -1.0322, -1.0322, -1.0322]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 4.1202,  6.7467,  5.7550,  ..., -1.0859, -1.0859, -1.0859],\n",
            "         [ 3.6698,  5.9304,  4.3441,  ..., -0.9614, -0.9614, -0.9614],\n",
            "         [ 4.3910,  7.0886,  6.0577,  ..., -1.0383, -1.0383, -1.0383],\n",
            "         ...,\n",
            "         [ 6.0232,  5.7963,  5.7735,  ..., -0.9784, -0.9784, -0.9784],\n",
            "         [ 7.4882,  5.9271,  5.2140,  ..., -0.9134, -0.9134, -0.9134],\n",
            "         [ 6.2142,  5.2880,  5.1763,  ..., -0.9261, -0.9261, -0.9261]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 62, 20108])\n",
            "tensor([[[ 2.0496,  5.2895,  3.9120,  ..., -1.0241, -1.0241, -1.0241],\n",
            "         [ 2.0229,  5.4138,  3.6912,  ..., -0.9912, -0.9912, -0.9912],\n",
            "         [ 2.5071,  5.6766,  3.9713,  ..., -1.0542, -1.0542, -1.0542],\n",
            "         ...,\n",
            "         [ 3.6240,  4.9638,  4.5808,  ..., -0.7602, -0.7602, -0.7602],\n",
            "         [ 2.8075,  5.3419,  4.7594,  ..., -0.7015, -0.7015, -0.7015],\n",
            "         [ 2.8297,  5.0538,  4.5122,  ..., -0.7142, -0.7142, -0.7142]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 4.4335,  6.8927,  6.6543,  ..., -1.0679, -1.0679, -1.0679],\n",
            "         [ 3.9801,  6.5773,  6.1929,  ..., -1.0406, -1.0406, -1.0406],\n",
            "         [ 3.1057,  6.4459,  5.6731,  ..., -1.0008, -1.0008, -1.0008],\n",
            "         ...,\n",
            "         [ 3.7225,  7.8337,  7.8468,  ..., -0.8475, -0.8475, -0.8475],\n",
            "         [ 4.0946,  8.1643,  7.5509,  ..., -0.8250, -0.8250, -0.8250],\n",
            "         [ 4.9684,  8.6369,  7.6606,  ..., -0.8871, -0.8871, -0.8871]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 72, 20108])\n",
            "tensor([[[ 3.1757,  4.3540,  3.5116,  ..., -1.0637, -1.0637, -1.0637],\n",
            "         [ 2.3919,  5.5965,  4.9727,  ..., -1.0981, -1.0981, -1.0981],\n",
            "         [ 1.1059,  4.2841,  3.0292,  ..., -0.9823, -0.9823, -0.9823],\n",
            "         ...,\n",
            "         [ 4.1307,  4.0984,  3.7955,  ..., -0.7278, -0.7278, -0.7278],\n",
            "         [ 4.0701,  4.0159,  3.7670,  ..., -0.6860, -0.6860, -0.6860],\n",
            "         [ 3.6308,  3.5981,  3.4649,  ..., -0.7021, -0.7021, -0.7021]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 93, 20108])\n",
            "tensor([[[ 2.6524,  7.2752,  6.7663,  ..., -1.0675, -1.0675, -1.0675],\n",
            "         [ 1.4315,  7.5809,  5.7545,  ..., -0.9148, -0.9148, -0.9148],\n",
            "         [ 1.6829,  8.0582,  6.4178,  ..., -0.9533, -0.9533, -0.9533],\n",
            "         ...,\n",
            "         [ 5.1941,  5.1582,  5.4385,  ..., -0.9846, -0.9846, -0.9846],\n",
            "         [ 4.9488,  5.1131,  5.1099,  ..., -0.9561, -0.9561, -0.9561],\n",
            "         [ 4.9376,  5.3916,  5.3806,  ..., -0.9378, -0.9378, -0.9378]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 39, 20108])\n",
            "tensor([[[ 3.8519,  6.5303,  4.9383,  ..., -1.0845, -1.0845, -1.0845],\n",
            "         [ 4.3825,  6.5944,  4.5464,  ..., -1.0873, -1.0873, -1.0873],\n",
            "         [ 3.6466,  6.3816,  5.1169,  ..., -1.0913, -1.0913, -1.0913],\n",
            "         ...,\n",
            "         [ 5.6970,  8.1777,  6.9238,  ..., -0.7957, -0.7957, -0.7957],\n",
            "         [ 5.0435,  7.6220,  6.3380,  ..., -0.7510, -0.7510, -0.7510],\n",
            "         [ 5.8129,  8.6532,  7.3984,  ..., -0.8438, -0.8438, -0.8438]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 219, 20108])\n",
            "tensor([[[ 4.1712,  5.6685,  4.1039,  ..., -1.0183, -1.0183, -1.0183],\n",
            "         [ 5.7581,  5.4292,  4.6172,  ..., -1.0314, -1.0314, -1.0314],\n",
            "         [ 6.6031,  6.1280,  5.3706,  ..., -1.1044, -1.1044, -1.1044],\n",
            "         ...,\n",
            "         [ 4.3880,  3.9270,  2.9987,  ..., -0.8266, -0.8266, -0.8266],\n",
            "         [ 4.1763,  4.2855,  3.8925,  ..., -0.8773, -0.8773, -0.8773],\n",
            "         [ 4.0802,  3.8535,  2.9579,  ..., -0.8268, -0.8268, -0.8268]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 131, 20108])\n",
            "tensor([[[ 3.1042,  4.5237,  4.3958,  ..., -0.9570, -0.9570, -0.9570],\n",
            "         [ 2.6025,  5.9940,  5.1815,  ..., -0.9518, -0.9518, -0.9518],\n",
            "         [ 3.5347,  5.8883,  5.0671,  ..., -0.8317, -0.8317, -0.8317],\n",
            "         ...,\n",
            "         [ 0.6922,  1.5768,  1.7725,  ..., -0.5795, -0.5795, -0.5795],\n",
            "         [ 0.1431,  1.4413,  1.7144,  ..., -0.5689, -0.5689, -0.5689],\n",
            "         [-0.7166,  1.5938,  1.0028,  ..., -0.5223, -0.5223, -0.5223]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 156, 20108])\n",
            "tensor([[[ 3.5415,  5.7835,  4.7013,  ..., -1.1105, -1.1105, -1.1105],\n",
            "         [ 2.0195,  5.1842,  3.6876,  ..., -1.0685, -1.0685, -1.0685],\n",
            "         [ 3.6987,  7.0063,  5.1460,  ..., -1.1569, -1.1569, -1.1569],\n",
            "         ...,\n",
            "         [ 2.9585,  4.5861,  4.3167,  ..., -0.8000, -0.8000, -0.8000],\n",
            "         [ 2.8584,  4.9335,  4.2142,  ..., -0.7547, -0.7547, -0.7547],\n",
            "         [ 2.9012,  4.4527,  4.1589,  ..., -0.8003, -0.8003, -0.8003]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 15, 20108])\n",
            "tensor([[[ 3.5685,  4.9615,  4.2618,  ..., -1.0218, -1.0218, -1.0218],\n",
            "         [ 4.9938,  6.7632,  5.7548,  ..., -1.1163, -1.1163, -1.1163],\n",
            "         [ 5.4205,  6.7853,  6.3987,  ..., -1.1586, -1.1586, -1.1586],\n",
            "         ...,\n",
            "         [ 4.6170,  5.2704,  5.4633,  ..., -0.7232, -0.7232, -0.7232],\n",
            "         [ 4.9765,  6.3842,  5.9551,  ..., -0.8013, -0.8013, -0.8013],\n",
            "         [ 4.7984,  6.3282,  6.0270,  ..., -0.7813, -0.7813, -0.7813]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 20, 20108])\n",
            "tensor([[[ 2.8503,  5.0701,  2.7486,  ..., -0.5171, -0.5171, -0.5171],\n",
            "         [ 3.1235,  4.2940,  2.4783,  ..., -0.4672, -0.4672, -0.4672],\n",
            "         [ 2.6960,  4.9398,  2.8655,  ..., -0.4685, -0.4685, -0.4685],\n",
            "         ...,\n",
            "         [ 6.3426,  2.8192,  1.2501,  ..., -0.3197, -0.3197, -0.3197],\n",
            "         [ 5.9040,  3.2039,  1.4611,  ..., -0.3680, -0.3680, -0.3680],\n",
            "         [ 6.2127,  3.8196,  2.0953,  ..., -0.3880, -0.3880, -0.3880]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 29, 20108])\n",
            "tensor([[[ 2.5062,  5.5843,  3.8921,  ..., -1.0059, -1.0059, -1.0059],\n",
            "         [ 4.3125,  6.9540,  6.2210,  ..., -1.1145, -1.1145, -1.1145],\n",
            "         [ 4.3803,  5.4858,  6.0196,  ..., -1.0263, -1.0263, -1.0263],\n",
            "         ...,\n",
            "         [ 6.2597,  6.2599,  6.6329,  ..., -1.0785, -1.0785, -1.0785],\n",
            "         [ 6.7395,  6.0811,  6.9150,  ..., -1.0141, -1.0141, -1.0141],\n",
            "         [ 6.0803,  5.7953,  6.5615,  ..., -0.9760, -0.9760, -0.9760]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 183, 20108])\n",
            "tensor([[[ 2.5060,  5.4141,  3.8636,  ..., -1.0018, -1.0018, -1.0018],\n",
            "         [ 3.4983,  4.9060,  3.8817,  ..., -1.0615, -1.0615, -1.0615],\n",
            "         [ 2.8571,  5.2213,  4.3417,  ..., -1.0379, -1.0379, -1.0379],\n",
            "         ...,\n",
            "         [ 1.5287,  3.1170,  3.0407,  ..., -0.6118, -0.6118, -0.6118],\n",
            "         [ 1.2568,  2.5336,  2.6906,  ..., -0.5488, -0.5488, -0.5488],\n",
            "         [ 2.8910,  4.7065,  4.3110,  ..., -0.6858, -0.6858, -0.6858]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 36, 20108])\n",
            "tensor([[[ 4.2294,  5.8175,  5.1394,  ..., -1.1379, -1.1379, -1.1379],\n",
            "         [ 4.2948,  4.9606,  4.4421,  ..., -1.0586, -1.0586, -1.0586],\n",
            "         [ 4.1585,  6.0523,  4.7119,  ..., -1.1134, -1.1134, -1.1134],\n",
            "         ...,\n",
            "         [ 5.0492,  8.3497,  6.3016,  ..., -0.8374, -0.8374, -0.8374],\n",
            "         [ 5.4396,  8.5505,  6.2750,  ..., -0.8815, -0.8815, -0.8815],\n",
            "         [ 5.4324,  8.1572,  5.8970,  ..., -0.8284, -0.8284, -0.8284]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 5.4119,  7.6292,  6.6990,  ..., -1.1070, -1.1070, -1.1070],\n",
            "         [ 5.0700,  6.5097,  6.3492,  ..., -1.0222, -1.0222, -1.0222],\n",
            "         [ 5.2448,  7.6284,  6.9310,  ..., -1.0435, -1.0435, -1.0435],\n",
            "         [ 5.5123,  7.2554,  6.6817,  ..., -1.0837, -1.0837, -1.0837],\n",
            "         [ 5.4279,  7.7719,  6.7969,  ..., -1.0661, -1.0661, -1.0661]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 29, 20108])\n",
            "tensor([[[ 4.7899,  6.6871,  5.0135,  ..., -0.9603, -0.9603, -0.9603],\n",
            "         [ 3.8357,  5.7817,  4.1701,  ..., -0.8463, -0.8463, -0.8463],\n",
            "         [ 4.3351,  6.9704,  4.9055,  ..., -0.8398, -0.8398, -0.8398],\n",
            "         ...,\n",
            "         [ 6.0370,  4.0382,  1.8513,  ..., -0.6509, -0.6509, -0.6509],\n",
            "         [ 6.4084,  4.1607,  1.8732,  ..., -0.6137, -0.6137, -0.6137],\n",
            "         [ 6.1602,  4.7112,  2.1705,  ..., -0.5954, -0.5954, -0.5954]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 5.7805,  6.1550,  3.8527,  ..., -0.4073, -0.4073, -0.4073],\n",
            "         [ 5.1112,  4.5993,  2.8295,  ..., -0.3880, -0.3880, -0.3880],\n",
            "         [ 5.5880,  4.1021,  1.8746,  ..., -0.3320, -0.3320, -0.3320],\n",
            "         ...,\n",
            "         [ 3.9208,  2.7832,  0.7544,  ..., -0.3793, -0.3793, -0.3793],\n",
            "         [ 4.5938,  2.7464,  0.5163,  ..., -0.3758, -0.3758, -0.3758],\n",
            "         [ 4.0981,  2.4460,  0.1374,  ..., -0.3116, -0.3116, -0.3116]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 39, 20108])\n",
            "tensor([[[ 6.7293,  8.6404,  7.9062,  ..., -1.0968, -1.0968, -1.0968],\n",
            "         [ 5.1493,  7.7468,  6.5558,  ..., -1.0813, -1.0813, -1.0813],\n",
            "         [ 5.4109,  7.8322,  6.0411,  ..., -0.9508, -0.9508, -0.9508],\n",
            "         ...,\n",
            "         [ 2.9873,  4.5844,  3.4646,  ..., -0.7654, -0.7654, -0.7654],\n",
            "         [ 3.3840,  4.7103,  3.5749,  ..., -0.8099, -0.8099, -0.8099],\n",
            "         [ 4.3061,  5.5159,  3.5534,  ..., -0.8754, -0.8754, -0.8754]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 74, 20108])\n",
            "tensor([[[ 5.8501,  7.0617,  6.7658,  ..., -1.1401, -1.1401, -1.1401],\n",
            "         [ 5.6858,  7.1729,  6.9618,  ..., -1.1466, -1.1466, -1.1466],\n",
            "         [ 4.8127,  7.3382,  6.8368,  ..., -1.0769, -1.0769, -1.0769],\n",
            "         ...,\n",
            "         [ 3.3043,  3.8761,  3.2782,  ..., -0.9299, -0.9299, -0.9299],\n",
            "         [ 2.9138,  3.3920,  3.1920,  ..., -0.8852, -0.8852, -0.8852],\n",
            "         [ 3.1176,  4.1844,  3.0204,  ..., -0.8348, -0.8348, -0.8348]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 146, 20108])\n",
            "tensor([[[ 3.4595,  6.3083,  4.9765,  ..., -1.0926, -1.0926, -1.0926],\n",
            "         [ 3.7910,  5.6612,  5.0971,  ..., -1.1171, -1.1171, -1.1171],\n",
            "         [ 5.2448,  6.7221,  6.2059,  ..., -1.0190, -1.0190, -1.0190],\n",
            "         ...,\n",
            "         [ 4.2862,  2.8591,  4.7322,  ..., -0.9617, -0.9617, -0.9617],\n",
            "         [ 5.6154,  3.9129,  4.8898,  ..., -1.0080, -1.0080, -1.0080],\n",
            "         [ 5.5778,  3.6375,  4.2842,  ..., -0.9842, -0.9842, -0.9842]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 16, 20108])\n",
            "tensor([[[ 3.8405,  6.1564,  5.6196,  ..., -1.0547, -1.0547, -1.0547],\n",
            "         [ 3.7351,  6.6701,  5.7625,  ..., -1.0340, -1.0340, -1.0340],\n",
            "         [ 3.4910,  7.6374,  6.1816,  ..., -0.9637, -0.9637, -0.9637],\n",
            "         ...,\n",
            "         [ 3.5339,  7.3281,  6.7951,  ..., -0.8407, -0.8407, -0.8407],\n",
            "         [ 3.5131,  6.6805,  6.1821,  ..., -0.7799, -0.7799, -0.7799],\n",
            "         [ 1.9393,  5.9398,  5.5021,  ..., -0.7819, -0.7819, -0.7819]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 40, 20108])\n",
            "tensor([[[ 2.6634,  5.7999,  4.3643,  ..., -1.0503, -1.0503, -1.0503],\n",
            "         [ 3.8593,  5.5427,  4.4443,  ..., -1.0704, -1.0704, -1.0704],\n",
            "         [ 3.5247,  5.0783,  4.0081,  ..., -1.0600, -1.0600, -1.0600],\n",
            "         ...,\n",
            "         [ 6.4153,  5.7358,  5.6242,  ..., -0.9894, -0.9894, -0.9894],\n",
            "         [ 6.2628,  5.7002,  5.4586,  ..., -0.9695, -0.9695, -0.9695],\n",
            "         [ 5.6929,  5.4294,  5.0590,  ..., -0.9790, -0.9790, -0.9790]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 90, 20108])\n",
            "tensor([[[ 0.7243,  4.7887,  3.0951,  ..., -0.7700, -0.7700, -0.7700],\n",
            "         [ 2.3686,  6.3350,  4.1922,  ..., -0.8972, -0.8972, -0.8972],\n",
            "         [ 1.5824,  7.7560,  5.0794,  ..., -0.7102, -0.7102, -0.7102],\n",
            "         ...,\n",
            "         [ 4.9083,  6.3215,  6.8164,  ..., -0.8734, -0.8734, -0.8734],\n",
            "         [ 5.6073,  6.1345,  6.8187,  ..., -0.8465, -0.8465, -0.8465],\n",
            "         [ 5.7043,  5.9500,  6.9098,  ..., -0.8766, -0.8766, -0.8766]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 32, 20108])\n",
            "tensor([[[ 3.7651,  5.6092,  3.6811,  ..., -0.9932, -0.9932, -0.9932],\n",
            "         [ 5.7553,  7.4503,  6.2955,  ..., -1.0913, -1.0913, -1.0913],\n",
            "         [ 4.0510,  5.4446,  4.7074,  ..., -0.8370, -0.8370, -0.8370],\n",
            "         ...,\n",
            "         [ 7.7022,  6.1595,  5.2121,  ..., -0.8982, -0.8982, -0.8982],\n",
            "         [ 7.7087,  5.9797,  4.8575,  ..., -0.8529, -0.8529, -0.8529],\n",
            "         [ 7.1618,  5.9474,  4.9707,  ..., -0.8692, -0.8692, -0.8692]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.8325,  6.0319,  6.0384,  ..., -0.9766, -0.9766, -0.9766],\n",
            "         [ 6.5394,  7.7212,  8.4090,  ..., -1.0333, -1.0333, -1.0333],\n",
            "         [ 6.8136,  7.8974,  8.8053,  ..., -1.0097, -1.0097, -1.0097],\n",
            "         ...,\n",
            "         [ 6.2092,  7.5443,  7.2827,  ..., -1.0525, -1.0525, -1.0525],\n",
            "         [ 6.2698,  7.2874,  6.7801,  ..., -1.0842, -1.0842, -1.0842],\n",
            "         [ 7.1459,  6.9354,  7.1090,  ..., -1.0555, -1.0555, -1.0555]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.6989,  4.7453,  4.1143,  ..., -1.1029, -1.1029, -1.1029],\n",
            "         [ 3.8751,  4.3534,  3.4501,  ..., -1.0662, -1.0662, -1.0662],\n",
            "         [ 3.2845,  3.8572,  3.5359,  ..., -1.0126, -1.0126, -1.0126],\n",
            "         ...,\n",
            "         [ 2.9905,  4.0556,  3.2083,  ..., -0.9901, -0.9901, -0.9901],\n",
            "         [ 3.7706,  4.5924,  3.6114,  ..., -1.0197, -1.0197, -1.0197],\n",
            "         [ 2.9536,  3.6548,  2.8205,  ..., -0.9102, -0.9102, -0.9102]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 44, 20108])\n",
            "tensor([[[ 3.3876,  4.9550,  2.4991,  ..., -0.4766, -0.4766, -0.4766],\n",
            "         [ 3.2896,  4.5877,  2.3226,  ..., -0.4543, -0.4543, -0.4543],\n",
            "         [ 3.2668,  4.7579,  2.4632,  ..., -0.4439, -0.4439, -0.4439],\n",
            "         ...,\n",
            "         [ 6.5322,  0.7927, -0.7297,  ..., -0.3302, -0.3302, -0.3302],\n",
            "         [ 6.3837,  0.1142, -0.8855,  ..., -0.3015, -0.3015, -0.3015],\n",
            "         [ 6.4919,  0.6977, -0.1441,  ..., -0.3602, -0.3602, -0.3602]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.3294,  5.5984,  4.8964,  ..., -1.0451, -1.0451, -1.0451],\n",
            "         [ 2.6734,  5.4207,  4.6906,  ..., -0.9958, -0.9958, -0.9958],\n",
            "         [ 3.7173,  8.2098,  6.7383,  ..., -0.9173, -0.9173, -0.9173],\n",
            "         ...,\n",
            "         [ 3.9538, 10.1146,  7.2396,  ..., -0.7913, -0.7913, -0.7913],\n",
            "         [ 4.3545,  9.7061,  7.1681,  ..., -0.8328, -0.8328, -0.8328],\n",
            "         [ 4.4089,  9.3286,  7.0568,  ..., -0.8157, -0.8157, -0.8157]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 3.2596,  4.4170,  2.0822,  ..., -0.6806, -0.6806, -0.6806],\n",
            "         [ 2.6203,  4.4125,  3.1000,  ..., -0.8729, -0.8729, -0.8729],\n",
            "         [ 2.1040,  4.7475,  3.1111,  ..., -0.7939, -0.7939, -0.7939],\n",
            "         ...,\n",
            "         [ 4.0702,  6.9416,  6.4404,  ..., -0.7995, -0.7995, -0.7995],\n",
            "         [ 4.5168,  6.3839,  6.1453,  ..., -0.8313, -0.8313, -0.8313],\n",
            "         [ 3.5084,  6.1343,  5.3886,  ..., -0.8870, -0.8870, -0.8870]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 71, 20108])\n",
            "tensor([[[ 4.7771,  7.1663,  5.5013,  ..., -1.0288, -1.0288, -1.0288],\n",
            "         [ 6.1505,  6.8404,  6.3282,  ..., -1.0537, -1.0537, -1.0537],\n",
            "         [ 4.8444,  6.1407,  5.7684,  ..., -0.9880, -0.9880, -0.9880],\n",
            "         ...,\n",
            "         [ 3.5076,  5.7014,  5.9938,  ..., -0.8157, -0.8157, -0.8157],\n",
            "         [ 4.8512,  6.9786,  7.0618,  ..., -0.8536, -0.8536, -0.8536],\n",
            "         [ 4.9111,  7.8149,  7.2927,  ..., -0.8683, -0.8683, -0.8683]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 22, 20108])\n",
            "tensor([[[ 5.2249,  7.4286,  5.7248,  ..., -0.8650, -0.8650, -0.8650],\n",
            "         [ 5.1556,  6.4611,  4.8674,  ..., -0.8599, -0.8599, -0.8599],\n",
            "         [ 3.9594,  7.2254,  6.1807,  ..., -1.0264, -1.0264, -1.0264],\n",
            "         ...,\n",
            "         [ 0.2919,  4.9830,  3.9974,  ..., -0.6294, -0.6294, -0.6294],\n",
            "         [ 0.0212,  5.6041,  4.0960,  ..., -0.6391, -0.6391, -0.6391],\n",
            "         [-0.1481,  5.6836,  4.3609,  ..., -0.6641, -0.6641, -0.6641]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 46, 20108])\n",
            "tensor([[[ 4.1715,  5.8783,  5.4165,  ..., -1.0433, -1.0433, -1.0433],\n",
            "         [ 4.3704,  6.1442,  6.0222,  ..., -1.0464, -1.0464, -1.0464],\n",
            "         [ 4.1973,  6.5905,  6.1915,  ..., -1.0642, -1.0642, -1.0642],\n",
            "         ...,\n",
            "         [ 6.8218,  7.0768,  7.0209,  ..., -1.0839, -1.0839, -1.0839],\n",
            "         [ 7.2373,  7.3939,  6.9824,  ..., -1.0769, -1.0769, -1.0769],\n",
            "         [ 7.2078,  6.9827,  6.3833,  ..., -1.0801, -1.0801, -1.0801]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 60, 20108])\n",
            "tensor([[[ 4.2251,  5.3851,  4.3863,  ..., -1.0210, -1.0210, -1.0210],\n",
            "         [ 5.0643,  7.6861,  5.6148,  ..., -1.0044, -1.0044, -1.0044],\n",
            "         [ 4.8804,  6.5193,  4.8006,  ..., -0.9491, -0.9491, -0.9491],\n",
            "         ...,\n",
            "         [ 7.1366,  4.9054,  3.3759,  ..., -0.7907, -0.7907, -0.7907],\n",
            "         [ 7.1642,  4.8581,  3.2701,  ..., -0.8241, -0.8241, -0.8241],\n",
            "         [ 6.9216,  4.2009,  3.1623,  ..., -0.7961, -0.7961, -0.7961]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 65, 20108])\n",
            "tensor([[[ 4.8536,  7.0039,  6.1926,  ..., -1.1628, -1.1628, -1.1628],\n",
            "         [ 5.5080,  6.7524,  6.3883,  ..., -1.1197, -1.1197, -1.1197],\n",
            "         [ 4.6348,  6.8107,  6.2980,  ..., -1.1049, -1.1049, -1.1049],\n",
            "         ...,\n",
            "         [ 5.9088,  6.9078,  6.9430,  ..., -0.9943, -0.9943, -0.9943],\n",
            "         [ 5.8571,  6.6973,  6.5421,  ..., -0.9745, -0.9745, -0.9745],\n",
            "         [ 5.2587,  6.1857,  6.2752,  ..., -0.9710, -0.9710, -0.9710]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 5.8214,  6.0569,  4.2341,  ..., -0.5125, -0.5125, -0.5125],\n",
            "         [ 6.1026,  4.5392,  2.6065,  ..., -0.5021, -0.5021, -0.5021],\n",
            "         [ 5.5399,  3.4982,  1.5232,  ..., -0.4836, -0.4836, -0.4836],\n",
            "         ...,\n",
            "         [ 5.5542,  4.0007,  1.4553,  ..., -0.5568, -0.5568, -0.5568],\n",
            "         [ 5.7668,  4.0599,  1.5432,  ..., -0.5756, -0.5756, -0.5756],\n",
            "         [ 5.7903,  4.2359,  1.7318,  ..., -0.5440, -0.5440, -0.5440]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 3.7964,  6.5191,  5.9328,  ..., -1.0295, -1.0295, -1.0295],\n",
            "         [ 3.5154,  6.1220,  4.6993,  ..., -0.9029, -0.9029, -0.9029],\n",
            "         [ 1.2164,  6.1834,  4.4700,  ..., -0.7870, -0.7870, -0.7870],\n",
            "         ...,\n",
            "         [ 2.5046,  8.1810,  7.3833,  ..., -0.8028, -0.8028, -0.8028],\n",
            "         [ 2.7276,  7.4896,  7.0370,  ..., -0.8722, -0.8722, -0.8722],\n",
            "         [ 3.2228,  7.8211,  7.0678,  ..., -0.9519, -0.9519, -0.9519]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 34, 20108])\n",
            "tensor([[[ 6.1085,  6.7465,  7.1308,  ..., -1.1062, -1.1062, -1.1062],\n",
            "         [ 6.5631,  6.5048,  6.4073,  ..., -1.0710, -1.0710, -1.0710],\n",
            "         [ 4.8691,  5.1352,  4.9056,  ..., -0.9913, -0.9913, -0.9913],\n",
            "         ...,\n",
            "         [ 3.0458,  5.5002,  4.3410,  ..., -0.8253, -0.8253, -0.8253],\n",
            "         [ 2.4040,  4.9553,  4.8220,  ..., -0.8315, -0.8315, -0.8315],\n",
            "         [ 2.2280,  5.3204,  5.7477,  ..., -0.7305, -0.7305, -0.7305]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 5.0870,  7.7273,  7.1663,  ..., -1.1442, -1.1442, -1.1442],\n",
            "         [ 5.1600,  7.3033,  6.5235,  ..., -1.0943, -1.0943, -1.0943],\n",
            "         [ 4.3285,  7.0352,  5.8643,  ..., -1.0964, -1.0964, -1.0964],\n",
            "         ...,\n",
            "         [ 7.1042,  8.5714,  8.0936,  ..., -0.9850, -0.9850, -0.9850],\n",
            "         [ 7.6527,  8.5966,  8.0754,  ..., -0.9748, -0.9748, -0.9748],\n",
            "         [ 7.9176,  8.9049,  8.5456,  ..., -0.9375, -0.9375, -0.9375]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 111, 20108])\n",
            "tensor([[[ 5.6934,  6.5947,  6.0761,  ..., -1.1145, -1.1145, -1.1145],\n",
            "         [ 5.6955,  6.8170,  6.7214,  ..., -1.1279, -1.1279, -1.1279],\n",
            "         [ 6.1179,  6.4095,  6.3288,  ..., -1.0758, -1.0758, -1.0758],\n",
            "         ...,\n",
            "         [ 7.3105,  5.9407,  6.8009,  ..., -1.0270, -1.0270, -1.0270],\n",
            "         [ 7.2122,  5.9278,  6.3938,  ..., -1.0166, -1.0166, -1.0166],\n",
            "         [ 7.1803,  6.1325,  6.6654,  ..., -1.0294, -1.0294, -1.0294]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 4.7538,  6.9585,  6.5063,  ..., -1.0951, -1.0951, -1.0951],\n",
            "         [ 4.1166,  7.2649,  6.4966,  ..., -1.0605, -1.0605, -1.0605],\n",
            "         [ 4.4568,  7.4726,  6.6778,  ..., -1.0120, -1.0120, -1.0120],\n",
            "         ...,\n",
            "         [ 5.4714,  7.9045,  6.8639,  ..., -1.1359, -1.1359, -1.1359],\n",
            "         [ 5.8744,  7.5241,  6.8729,  ..., -0.9988, -0.9988, -0.9988],\n",
            "         [ 4.4745,  7.2635,  7.4575,  ..., -0.9892, -0.9892, -0.9892]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 35, 20108])\n",
            "tensor([[[ 5.3675,  7.4770,  6.7989,  ..., -1.0919, -1.0919, -1.0919],\n",
            "         [ 4.6879,  7.1278,  6.2713,  ..., -1.0735, -1.0735, -1.0735],\n",
            "         [ 4.7482,  6.4996,  5.8886,  ..., -1.0922, -1.0922, -1.0922],\n",
            "         ...,\n",
            "         [ 5.9102,  9.9142,  8.7360,  ..., -0.9003, -0.9003, -0.9003],\n",
            "         [ 6.0098,  9.9746,  8.8284,  ..., -0.9274, -0.9274, -0.9274],\n",
            "         [ 5.9713, 10.1090,  9.0078,  ..., -0.9341, -0.9341, -0.9341]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 28, 20108])\n",
            "tensor([[[ 6.5869,  6.3784,  4.8250,  ..., -0.5272, -0.5272, -0.5272],\n",
            "         [ 5.6682,  5.3874,  3.2908,  ..., -0.4395, -0.4395, -0.4395],\n",
            "         [ 6.0596,  4.3812,  1.8459,  ..., -0.4079, -0.4079, -0.4079],\n",
            "         ...,\n",
            "         [ 6.4280,  2.8701,  0.6233,  ..., -0.4582, -0.4582, -0.4582],\n",
            "         [ 5.8310,  3.1773,  1.0919,  ..., -0.4121, -0.4121, -0.4121],\n",
            "         [ 7.6434,  3.4484,  1.3852,  ..., -0.5060, -0.5060, -0.5060]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 61, 20108])\n",
            "tensor([[[ 3.5972,  5.8027,  4.7609,  ..., -1.0266, -1.0266, -1.0266],\n",
            "         [ 2.1733,  5.6361,  3.9527,  ..., -0.9523, -0.9523, -0.9523],\n",
            "         [ 1.9345,  6.6182,  4.8147,  ..., -0.8330, -0.8330, -0.8330],\n",
            "         ...,\n",
            "         [ 0.6859,  4.7437,  3.8373,  ..., -0.6446, -0.6446, -0.6446],\n",
            "         [ 0.7083,  4.7005,  3.5025,  ..., -0.6128, -0.6128, -0.6128],\n",
            "         [ 0.0425,  4.6422,  3.5395,  ..., -0.6765, -0.6765, -0.6765]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 51, 20108])\n",
            "tensor([[[ 6.2652,  7.5922,  7.0083,  ..., -1.1070, -1.1070, -1.1070],\n",
            "         [ 5.7452,  7.7307,  6.9387,  ..., -1.1154, -1.1154, -1.1154],\n",
            "         [ 5.0568,  6.8658,  6.6994,  ..., -1.0503, -1.0503, -1.0503],\n",
            "         ...,\n",
            "         [ 4.8162,  5.1387,  5.0162,  ..., -1.0917, -1.0917, -1.0917],\n",
            "         [ 4.8257,  4.3035,  4.3591,  ..., -1.0890, -1.0890, -1.0890],\n",
            "         [ 4.8699,  4.9107,  4.8469,  ..., -1.1072, -1.1072, -1.1072]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 33, 20108])\n",
            "tensor([[[ 4.5560,  6.5351,  5.6340,  ..., -0.9973, -0.9973, -0.9973],\n",
            "         [ 5.4739,  6.9096,  6.8642,  ..., -1.0742, -1.0742, -1.0742],\n",
            "         [ 6.2572,  7.0925,  6.9942,  ..., -1.0447, -1.0447, -1.0447],\n",
            "         ...,\n",
            "         [ 2.9967,  4.7207,  5.1122,  ..., -0.9294, -0.9294, -0.9294],\n",
            "         [ 3.6454,  6.2453,  5.1985,  ..., -0.8925, -0.8925, -0.8925],\n",
            "         [ 3.5199,  5.8418,  5.9131,  ..., -0.9209, -0.9209, -0.9209]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 39, 20108])\n",
            "tensor([[[ 7.0349,  7.4053,  7.2832,  ..., -1.0635, -1.0635, -1.0635],\n",
            "         [ 5.1607,  6.2194,  6.1343,  ..., -1.0454, -1.0454, -1.0454],\n",
            "         [ 6.1257,  7.6860,  6.7791,  ..., -1.0742, -1.0742, -1.0742],\n",
            "         ...,\n",
            "         [ 4.6769,  5.3708,  6.7655,  ..., -0.9226, -0.9226, -0.9226],\n",
            "         [ 3.9960,  5.7273,  6.6514,  ..., -0.8824, -0.8824, -0.8824],\n",
            "         [ 5.6913,  5.3768,  6.4761,  ..., -0.9420, -0.9420, -0.9420]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 5.8621,  6.9308,  6.5489,  ..., -1.1689, -1.1689, -1.1689],\n",
            "         [ 5.8618,  7.1049,  6.5842,  ..., -1.1714, -1.1714, -1.1714],\n",
            "         [ 5.7436,  6.7126,  6.8059,  ..., -1.1030, -1.1030, -1.1030],\n",
            "         ...,\n",
            "         [ 3.6205,  6.7510,  7.7401,  ..., -0.9251, -0.9251, -0.9251],\n",
            "         [ 3.3607,  5.9907,  7.1606,  ..., -0.9143, -0.9143, -0.9143],\n",
            "         [ 2.9042,  7.2127,  7.0612,  ..., -0.8742, -0.8742, -0.8742]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 3.0516,  6.1024,  3.6370,  ..., -0.6282, -0.6282, -0.6282],\n",
            "         [ 3.2553,  4.5842,  2.4083,  ..., -0.4322, -0.4322, -0.4322],\n",
            "         [ 3.4827,  4.5064,  2.1147,  ..., -0.4009, -0.4009, -0.4009],\n",
            "         ...,\n",
            "         [ 4.4093,  3.4350,  2.3637,  ..., -0.3784, -0.3784, -0.3784],\n",
            "         [ 4.5437,  3.7199,  2.5203,  ..., -0.4249, -0.4249, -0.4249],\n",
            "         [ 3.9179,  3.3450,  1.9251,  ..., -0.2920, -0.2920, -0.2920]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 9, 20108])\n",
            "tensor([[[ 5.2716,  5.2589,  3.0576,  ..., -0.5911, -0.5911, -0.5911],\n",
            "         [ 4.7058,  5.1091,  3.1074,  ..., -0.5333, -0.5333, -0.5333],\n",
            "         [ 3.8016,  4.7810,  2.6896,  ..., -0.5030, -0.5030, -0.5030],\n",
            "         ...,\n",
            "         [ 4.2941,  3.6715,  1.7162,  ..., -0.3679, -0.3679, -0.3679],\n",
            "         [ 5.5048,  4.2239,  2.2070,  ..., -0.3242, -0.3242, -0.3242],\n",
            "         [ 5.0849,  3.6814,  1.8681,  ..., -0.3548, -0.3548, -0.3548]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 25, 20108])\n",
            "tensor([[[ 7.0810,  8.6456,  8.6737,  ..., -1.0686, -1.0686, -1.0686],\n",
            "         [ 6.5085,  8.1875,  9.0467,  ..., -1.0296, -1.0296, -1.0296],\n",
            "         [ 6.9395,  8.3382,  9.1614,  ..., -0.9907, -0.9907, -0.9907],\n",
            "         ...,\n",
            "         [ 6.4136, 10.5139,  8.8943,  ..., -0.8464, -0.8464, -0.8464],\n",
            "         [ 6.2659, 10.6772,  8.8611,  ..., -0.8527, -0.8527, -0.8527],\n",
            "         [ 6.3236, 10.3693,  8.5655,  ..., -0.8296, -0.8296, -0.8296]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 23, 20108])\n",
            "tensor([[[ 6.0565,  6.7393,  4.9271,  ..., -0.8147, -0.8147, -0.8147],\n",
            "         [ 5.0138,  5.4067,  4.0180,  ..., -0.7923, -0.7923, -0.7923],\n",
            "         [ 6.0369,  6.2876,  4.6770,  ..., -0.9020, -0.9020, -0.9020],\n",
            "         ...,\n",
            "         [ 7.0255,  3.0463,  1.8057,  ..., -0.6035, -0.6035, -0.6035],\n",
            "         [ 7.1134,  2.2576,  1.0624,  ..., -0.5473, -0.5473, -0.5473],\n",
            "         [ 6.9632,  2.5889,  1.0407,  ..., -0.6026, -0.6026, -0.6026]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 37, 20108])\n",
            "tensor([[[ 2.7312,  4.4169,  3.7753,  ..., -1.0276, -1.0276, -1.0276],\n",
            "         [ 3.1232,  4.9869,  3.9119,  ..., -0.9804, -0.9804, -0.9804],\n",
            "         [ 2.6441,  5.0411,  3.7842,  ..., -0.9012, -0.9012, -0.9012],\n",
            "         ...,\n",
            "         [ 4.3721,  9.1630,  6.2060,  ..., -0.6770, -0.6770, -0.6770],\n",
            "         [ 4.5390,  9.0100,  6.2209,  ..., -0.6691, -0.6691, -0.6691],\n",
            "         [ 4.9829,  9.0002,  6.3703,  ..., -0.6809, -0.6809, -0.6809]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 43, 20108])\n",
            "tensor([[[ 5.8913,  6.6093,  6.4738,  ..., -1.1186, -1.1186, -1.1186],\n",
            "         [ 5.6041,  8.4267,  7.6493,  ..., -1.0891, -1.0891, -1.0891],\n",
            "         [ 6.0372,  7.6355,  6.9881,  ..., -1.1040, -1.1040, -1.1040],\n",
            "         ...,\n",
            "         [ 6.9944,  6.3194,  6.8835,  ..., -1.1407, -1.1407, -1.1407],\n",
            "         [ 5.6775,  6.4790,  6.7831,  ..., -1.1381, -1.1381, -1.1381],\n",
            "         [ 6.1582,  7.5517,  7.4624,  ..., -1.1374, -1.1374, -1.1374]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 110, 20108])\n",
            "tensor([[[ 3.9037,  4.5991,  2.8957,  ..., -0.6299, -0.6299, -0.6299],\n",
            "         [ 4.2558,  4.6905,  2.5322,  ..., -0.5228, -0.5228, -0.5228],\n",
            "         [ 4.0118,  4.8476,  2.3059,  ..., -0.4337, -0.4337, -0.4337],\n",
            "         ...,\n",
            "         [ 4.3522,  2.1628,  0.0531,  ..., -0.3915, -0.3915, -0.3915],\n",
            "         [ 4.1840,  2.1037, -0.2743,  ..., -0.3758, -0.3758, -0.3758],\n",
            "         [ 4.7315,  2.1189,  0.1025,  ..., -0.3875, -0.3875, -0.3875]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 31, 20108])\n",
            "tensor([[[ 4.6879,  7.0979,  5.8854,  ..., -1.0303, -1.0303, -1.0303],\n",
            "         [ 4.3057,  8.1509,  7.9861,  ..., -0.9926, -0.9926, -0.9926],\n",
            "         [ 3.5058,  8.3043,  7.8244,  ..., -0.9243, -0.9243, -0.9243],\n",
            "         ...,\n",
            "         [ 0.6387,  4.5525,  3.1719,  ..., -0.5063, -0.5063, -0.5063],\n",
            "         [ 2.2190,  5.5548,  4.3408,  ..., -0.6920, -0.6920, -0.6920],\n",
            "         [ 2.8775,  5.6197,  4.9051,  ..., -0.7635, -0.7635, -0.7635]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 61, 20108])\n",
            "tensor([[[ 2.9518,  5.0308,  4.9915,  ..., -1.1030, -1.1030, -1.1030],\n",
            "         [ 3.0224,  6.0301,  5.2648,  ..., -0.9180, -0.9180, -0.9180],\n",
            "         [ 3.0101,  6.3679,  5.4955,  ..., -0.8318, -0.8318, -0.8318],\n",
            "         ...,\n",
            "         [ 7.0629,  8.6228,  8.0306,  ..., -0.9556, -0.9556, -0.9556],\n",
            "         [ 7.9401,  8.7108,  8.1187,  ..., -0.9533, -0.9533, -0.9533],\n",
            "         [ 7.6521,  8.6675,  8.3582,  ..., -0.9342, -0.9342, -0.9342]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 2.6186,  5.0267,  3.4325,  ..., -0.9966, -0.9966, -0.9966],\n",
            "         [ 3.3357,  5.1551,  3.3671,  ..., -1.0353, -1.0353, -1.0353],\n",
            "         [ 3.1636,  5.0669,  3.4027,  ..., -1.0729, -1.0729, -1.0729],\n",
            "         ...,\n",
            "         [ 4.0315, 10.6254,  7.2511,  ..., -0.9006, -0.9006, -0.9006],\n",
            "         [ 4.4639, 10.5209,  8.3651,  ..., -0.9034, -0.9034, -0.9034],\n",
            "         [ 4.4631, 10.7540,  8.0569,  ..., -0.8920, -0.8920, -0.8920]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 12, 20108])\n",
            "tensor([[[ 5.8807,  5.8825,  3.6999,  ..., -0.4530, -0.4530, -0.4530],\n",
            "         [ 5.1408,  5.2704,  3.3801,  ..., -0.4312, -0.4312, -0.4312],\n",
            "         [ 4.9382,  3.7631,  2.1829,  ..., -0.4257, -0.4257, -0.4257],\n",
            "         ...,\n",
            "         [ 4.1609,  1.7965,  0.1785,  ..., -0.3145, -0.3145, -0.3145],\n",
            "         [ 3.9447,  2.0150, -0.2130,  ..., -0.3309, -0.3309, -0.3309],\n",
            "         [ 4.1546,  2.7768,  0.6738,  ..., -0.4049, -0.4049, -0.4049]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 3.0148,  5.2541,  4.4502,  ..., -1.0660, -1.0660, -1.0660],\n",
            "         [ 2.8741,  5.7006,  4.6346,  ..., -1.0064, -1.0064, -1.0064],\n",
            "         [ 2.4670,  5.9686,  4.3182,  ..., -0.9634, -0.9634, -0.9634],\n",
            "         ...,\n",
            "         [ 0.2870,  5.4070,  4.3894,  ..., -0.7010, -0.7010, -0.7010],\n",
            "         [ 0.6959,  5.3840,  4.1991,  ..., -0.6816, -0.6816, -0.6816],\n",
            "         [-0.0151,  5.3568,  4.0518,  ..., -0.6386, -0.6386, -0.6386]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 93, 20108])\n",
            "tensor([[[ 7.4807,  7.2605,  6.1821,  ..., -1.0705, -1.0705, -1.0705],\n",
            "         [ 5.6822,  6.2310,  6.5427,  ..., -1.0472, -1.0472, -1.0472],\n",
            "         [ 6.0770,  6.8116,  7.1044,  ..., -1.0852, -1.0852, -1.0852],\n",
            "         ...,\n",
            "         [ 4.9911,  4.8789,  6.3418,  ..., -0.9388, -0.9388, -0.9388],\n",
            "         [ 4.8993,  5.6428,  5.9947,  ..., -0.8676, -0.8676, -0.8676],\n",
            "         [ 5.0054,  6.3991,  6.5495,  ..., -0.8196, -0.8196, -0.8196]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 6, 20108])\n",
            "tensor([[[ 5.5979,  6.6102,  4.7166,  ..., -0.5180, -0.5180, -0.5180],\n",
            "         [ 5.1665,  4.6119,  2.5340,  ..., -0.4626, -0.4626, -0.4626],\n",
            "         [ 5.0770,  3.2890,  1.3674,  ..., -0.4291, -0.4291, -0.4291],\n",
            "         [ 5.3535,  3.5088,  1.4997,  ..., -0.4166, -0.4166, -0.4166],\n",
            "         [ 4.6122,  3.3232,  1.3376,  ..., -0.3881, -0.3881, -0.3881],\n",
            "         [ 5.4342,  2.6910,  0.7647,  ..., -0.4019, -0.4019, -0.4019]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 93, 20108])\n",
            "tensor([[[ 4.6832,  7.0536,  5.8941,  ..., -1.0163, -1.0163, -1.0163],\n",
            "         [ 6.7978,  6.8175,  6.6435,  ..., -1.0420, -1.0420, -1.0420],\n",
            "         [ 4.9876,  5.9271,  6.3179,  ..., -1.0131, -1.0131, -1.0131],\n",
            "         ...,\n",
            "         [ 4.7743,  7.7131,  6.0355,  ..., -0.8520, -0.8520, -0.8520],\n",
            "         [ 4.5404,  7.1672,  5.6475,  ..., -0.8199, -0.8199, -0.8199],\n",
            "         [ 4.7569,  7.4920,  5.9303,  ..., -0.8383, -0.8383, -0.8383]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 45, 20108])\n",
            "tensor([[[ 5.3840,  5.9627,  4.3288,  ..., -0.4958, -0.4958, -0.4958],\n",
            "         [ 5.6393,  5.1940,  3.0941,  ..., -0.4791, -0.4791, -0.4791],\n",
            "         [ 5.7488,  4.9708,  3.0542,  ..., -0.4438, -0.4438, -0.4438],\n",
            "         ...,\n",
            "         [ 8.0516,  3.5402,  1.5542,  ..., -0.4666, -0.4666, -0.4666],\n",
            "         [ 9.1121,  3.6965,  2.3066,  ..., -0.5883, -0.5883, -0.5883],\n",
            "         [ 8.9594,  3.1423,  1.6626,  ..., -0.6193, -0.6193, -0.6193]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 17, 20108])\n",
            "tensor([[[ 6.2302,  7.5165,  7.6176,  ..., -1.0379, -1.0379, -1.0379],\n",
            "         [ 3.7296,  6.1168,  5.5805,  ..., -0.9284, -0.9284, -0.9284],\n",
            "         [ 4.2450,  5.6948,  5.0095,  ..., -0.8852, -0.8852, -0.8852],\n",
            "         ...,\n",
            "         [ 7.6179,  5.3060,  5.1023,  ..., -0.9306, -0.9306, -0.9306],\n",
            "         [ 7.5033,  5.9233,  5.7352,  ..., -0.8832, -0.8832, -0.8832],\n",
            "         [ 8.4389,  5.6027,  5.5692,  ..., -0.9127, -0.9127, -0.9127]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 5, 20108])\n",
            "tensor([[[ 4.6609,  5.9364,  3.3101,  ..., -0.5534, -0.5534, -0.5534],\n",
            "         [ 4.2707,  5.2400,  3.2043,  ..., -0.5793, -0.5793, -0.5793],\n",
            "         [ 5.4664,  5.4722,  3.1269,  ..., -0.4991, -0.4991, -0.4991],\n",
            "         [ 5.4680,  4.8911,  2.3246,  ..., -0.3411, -0.3411, -0.3411],\n",
            "         [ 5.5366,  5.1452,  2.4953,  ..., -0.3329, -0.3329, -0.3329]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.9845,  6.8999,  6.0464,  ..., -1.0514, -1.0514, -1.0514],\n",
            "         [ 4.9175,  5.9632,  6.3979,  ..., -0.9897, -0.9897, -0.9897],\n",
            "         [ 4.7143,  5.3272,  5.6605,  ..., -0.9348, -0.9348, -0.9348],\n",
            "         ...,\n",
            "         [ 4.1053,  4.5490,  5.4713,  ..., -0.8974, -0.8974, -0.8974],\n",
            "         [ 3.5918,  4.0950,  5.3456,  ..., -0.8200, -0.8200, -0.8200],\n",
            "         [ 5.1186,  5.6709,  5.7046,  ..., -0.8752, -0.8752, -0.8752]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 51, 20108])\n",
            "tensor([[[ 3.1834,  5.0621,  3.8726,  ..., -1.0435, -1.0435, -1.0435],\n",
            "         [ 3.2031,  5.5325,  4.0181,  ..., -0.8996, -0.8996, -0.8996],\n",
            "         [ 2.5243,  5.8562,  4.4320,  ..., -0.8840, -0.8840, -0.8840],\n",
            "         ...,\n",
            "         [ 2.9299,  5.6007,  5.7438,  ..., -0.7076, -0.7076, -0.7076],\n",
            "         [ 3.2094,  5.5846,  5.1720,  ..., -0.6207, -0.6207, -0.6207],\n",
            "         [ 3.5923,  6.9840,  6.3930,  ..., -0.7196, -0.7196, -0.7196]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 21, 20108])\n",
            "tensor([[[ 6.2970,  6.9118,  4.5202,  ..., -0.5213, -0.5213, -0.5213],\n",
            "         [ 5.6647,  4.5235,  2.6262,  ..., -0.4342, -0.4342, -0.4342],\n",
            "         [ 5.8951,  3.7520,  1.7198,  ..., -0.4125, -0.4125, -0.4125],\n",
            "         ...,\n",
            "         [ 7.4201,  3.3987,  1.2697,  ..., -0.3409, -0.3409, -0.3409],\n",
            "         [ 6.9079,  3.4694,  1.2353,  ..., -0.4160, -0.4160, -0.4160],\n",
            "         [ 6.6177,  3.9739,  1.6314,  ..., -0.4226, -0.4226, -0.4226]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 82, 20108])\n",
            "tensor([[[ 3.1021,  5.4667,  4.5240,  ..., -1.0189, -1.0189, -1.0189],\n",
            "         [ 2.7862,  5.8135,  4.8551,  ..., -1.0250, -1.0250, -1.0250],\n",
            "         [ 2.0441,  6.7313,  4.6899,  ..., -0.9266, -0.9266, -0.9266],\n",
            "         ...,\n",
            "         [ 5.4039,  6.5858,  6.2739,  ..., -0.9892, -0.9892, -0.9892],\n",
            "         [ 4.8243,  5.7604,  5.2026,  ..., -1.0078, -1.0078, -1.0078],\n",
            "         [ 4.6160,  5.0362,  4.6973,  ..., -0.9384, -0.9384, -0.9384]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 19, 20108])\n",
            "tensor([[[ 2.7327,  5.5351,  4.7639,  ..., -0.9974, -0.9974, -0.9974],\n",
            "         [ 2.2643,  5.5643,  4.3142,  ..., -0.9073, -0.9073, -0.9073],\n",
            "         [ 0.7845,  5.6964,  3.5819,  ..., -0.7782, -0.7782, -0.7782],\n",
            "         ...,\n",
            "         [ 3.7016,  8.7331,  7.6154,  ..., -0.8580, -0.8580, -0.8580],\n",
            "         [ 3.7405,  8.6869,  7.8269,  ..., -0.8605, -0.8605, -0.8605],\n",
            "         [ 3.3861,  9.2871,  7.7003,  ..., -0.8733, -0.8733, -0.8733]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 42, 20108])\n",
            "tensor([[[ 4.2712,  9.4223,  6.7319,  ..., -0.8238, -0.8238, -0.8238],\n",
            "         [ 5.5194,  8.8624,  7.0613,  ..., -0.9877, -0.9877, -0.9877],\n",
            "         [ 5.9170,  7.8678,  5.4233,  ..., -0.7379, -0.7379, -0.7379],\n",
            "         ...,\n",
            "         [ 8.8830,  5.1417,  3.8180,  ..., -0.8678, -0.8678, -0.8678],\n",
            "         [ 8.9520,  4.7877,  3.4355,  ..., -0.8373, -0.8373, -0.8373],\n",
            "         [ 8.8729,  4.8172,  3.5991,  ..., -0.8119, -0.8119, -0.8119]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 164, 20108])\n",
            "tensor([[[ 6.6286,  6.9420,  6.8569,  ..., -1.1491, -1.1491, -1.1491],\n",
            "         [ 5.3919,  6.1196,  6.3077,  ..., -1.0717, -1.0717, -1.0717],\n",
            "         [ 5.1914,  5.9142,  6.2119,  ..., -1.0281, -1.0281, -1.0281],\n",
            "         ...,\n",
            "         [ 7.7139,  3.6542,  3.3237,  ..., -0.6939, -0.6939, -0.6939],\n",
            "         [ 8.0716,  3.9272,  3.5961,  ..., -0.7241, -0.7241, -0.7241],\n",
            "         [ 7.6579,  4.0362,  3.5533,  ..., -0.6823, -0.6823, -0.6823]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 52, 20108])\n",
            "tensor([[[ 3.9593,  5.7162,  4.9886,  ..., -1.1016, -1.1016, -1.1016],\n",
            "         [ 3.2716,  4.4467,  3.6781,  ..., -1.0260, -1.0260, -1.0260],\n",
            "         [ 2.6774,  4.0848,  3.5582,  ..., -0.9591, -0.9591, -0.9591],\n",
            "         ...,\n",
            "         [ 4.4175,  7.6467,  6.9362,  ..., -0.8900, -0.8900, -0.8900],\n",
            "         [ 4.4798,  8.0932,  7.9618,  ..., -0.9840, -0.9840, -0.9840],\n",
            "         [ 4.6778,  8.7723,  8.2714,  ..., -0.9724, -0.9724, -0.9724]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 2.6894,  5.4410,  4.3233,  ..., -1.0683, -1.0683, -1.0683],\n",
            "         [ 2.4910,  5.1745,  4.1523,  ..., -1.0568, -1.0568, -1.0568],\n",
            "         [ 1.7750,  4.6991,  3.6350,  ..., -0.9920, -0.9920, -0.9920],\n",
            "         ...,\n",
            "         [ 1.7173,  5.2374,  3.3983,  ..., -0.9147, -0.9147, -0.9147],\n",
            "         [ 0.8211,  5.6047,  3.7283,  ..., -0.8234, -0.8234, -0.8234],\n",
            "         [ 1.6112,  5.1510,  3.3125,  ..., -0.7802, -0.7802, -0.7802]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 3.6878,  5.6896,  3.9753,  ..., -0.7366, -0.7366, -0.7366],\n",
            "         [ 3.6978,  4.5116,  2.7651,  ..., -0.5133, -0.5133, -0.5133],\n",
            "         [ 4.3721,  3.6435,  2.3254,  ..., -0.4626, -0.4626, -0.4626],\n",
            "         ...,\n",
            "         [ 6.0604,  2.2807,  1.2716,  ..., -0.3962, -0.3962, -0.3962],\n",
            "         [ 5.8955,  4.1369,  2.4295,  ..., -0.4271, -0.4271, -0.4271],\n",
            "         [ 5.9302,  3.4963,  2.1209,  ..., -0.3531, -0.3531, -0.3531]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 10, 20108])\n",
            "tensor([[[ 8.0346,  8.3535,  8.0428,  ..., -1.1327, -1.1327, -1.1327],\n",
            "         [ 8.3301,  9.2170,  8.8767,  ..., -1.0105, -1.0105, -1.0105],\n",
            "         [ 7.9011,  9.5799,  9.1018,  ..., -1.0251, -1.0251, -1.0251],\n",
            "         ...,\n",
            "         [ 5.5026,  8.0477,  7.2969,  ..., -1.0729, -1.0729, -1.0729],\n",
            "         [ 5.5275,  7.6151,  7.1545,  ..., -1.0605, -1.0605, -1.0605],\n",
            "         [ 5.8964,  8.4718,  7.4262,  ..., -1.0785, -1.0785, -1.0785]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 7, 20108])\n",
            "tensor([[[ 3.1929,  4.8254,  2.1703,  ..., -0.5507, -0.5507, -0.5507],\n",
            "         [ 3.4418,  5.1594,  3.0678,  ..., -0.5611, -0.5611, -0.5611],\n",
            "         [ 3.9647,  3.7169,  2.3554,  ..., -0.4469, -0.4469, -0.4469],\n",
            "         ...,\n",
            "         [ 5.5066,  3.6045,  1.5818,  ..., -0.3029, -0.3029, -0.3029],\n",
            "         [ 5.4560,  3.7977,  1.4669,  ..., -0.2904, -0.2904, -0.2904],\n",
            "         [ 5.4776,  4.8842,  2.1511,  ..., -0.3161, -0.3161, -0.3161]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 24, 20108])\n",
            "tensor([[[ 4.1800,  6.5133,  6.1184,  ..., -1.1037, -1.1037, -1.1037],\n",
            "         [ 4.1653,  6.8831,  7.1023,  ..., -1.0738, -1.0738, -1.0738],\n",
            "         [ 4.2814,  6.6642,  6.2419,  ..., -0.8889, -0.8889, -0.8889],\n",
            "         ...,\n",
            "         [ 5.5634,  7.5512,  8.8558,  ..., -1.0899, -1.0899, -1.0899],\n",
            "         [ 5.2473,  7.3355,  8.6271,  ..., -1.0834, -1.0834, -1.0834],\n",
            "         [ 4.9182,  6.0865,  7.9373,  ..., -0.9860, -0.9860, -0.9860]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 11, 20108])\n",
            "tensor([[[ 3.2583,  5.3899,  4.8468,  ..., -1.0193, -1.0193, -1.0193],\n",
            "         [ 2.1734,  7.4028,  4.9667,  ..., -0.8205, -0.8205, -0.8205],\n",
            "         [ 0.5571,  6.6983,  5.5061,  ..., -0.7968, -0.7968, -0.7968],\n",
            "         ...,\n",
            "         [ 0.8648,  7.9795,  5.2539,  ..., -0.7329, -0.7329, -0.7329],\n",
            "         [ 1.3405,  8.1640,  6.0088,  ..., -0.7174, -0.7174, -0.7174],\n",
            "         [ 1.5161,  8.5675,  6.7840,  ..., -0.7344, -0.7344, -0.7344]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 186, 20108])\n",
            "tensor([[[ 2.8776,  5.5323,  4.3603,  ..., -1.0355, -1.0355, -1.0355],\n",
            "         [ 2.2606,  5.8558,  3.4755,  ..., -1.0290, -1.0290, -1.0290],\n",
            "         [ 2.6708,  5.3376,  4.1041,  ..., -1.0543, -1.0543, -1.0543],\n",
            "         ...,\n",
            "         [ 4.2346,  4.1116,  4.2868,  ..., -0.8092, -0.8092, -0.8092],\n",
            "         [ 4.0359,  3.9819,  3.8506,  ..., -0.7998, -0.7998, -0.7998],\n",
            "         [ 4.6548,  5.0092,  5.2688,  ..., -0.8785, -0.8785, -0.8785]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 79, 20108])\n",
            "tensor([[[ 2.8211,  6.1419,  5.2380,  ..., -1.1554, -1.1554, -1.1554],\n",
            "         [ 1.5421,  5.3605,  4.0743,  ..., -0.9885, -0.9885, -0.9885],\n",
            "         [ 2.1624,  5.5663,  4.0450,  ..., -1.0287, -1.0287, -1.0287],\n",
            "         ...,\n",
            "         [ 2.9938,  2.8557,  2.7292,  ..., -0.9641, -0.9641, -0.9641],\n",
            "         [ 2.9976,  2.4328,  2.3476,  ..., -0.9613, -0.9613, -0.9613],\n",
            "         [ 3.2916,  3.0969,  2.9851,  ..., -0.9081, -0.9081, -0.9081]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 26, 20108])\n",
            "tensor([[[ 3.4399,  5.5489,  5.2748,  ..., -1.0590, -1.0590, -1.0590],\n",
            "         [ 3.8295,  4.9384,  4.8607,  ..., -1.0425, -1.0425, -1.0425],\n",
            "         [ 2.8563,  5.4222,  4.7717,  ..., -1.0663, -1.0663, -1.0663],\n",
            "         ...,\n",
            "         [ 3.9870,  8.1523,  6.9698,  ..., -0.8600, -0.8600, -0.8600],\n",
            "         [ 4.2793,  6.7089,  6.9941,  ..., -0.8644, -0.8644, -0.8644],\n",
            "         [ 4.2404,  6.3301,  6.3560,  ..., -0.8350, -0.8350, -0.8350]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 179, 20108])\n",
            "tensor([[[ 4.7478,  7.0527,  6.6635,  ..., -1.0978, -1.0978, -1.0978],\n",
            "         [ 5.5341,  7.9932,  7.5967,  ..., -1.0609, -1.0609, -1.0609],\n",
            "         [ 4.6844,  7.5819,  7.1120,  ..., -1.0694, -1.0694, -1.0694],\n",
            "         ...,\n",
            "         [ 3.5063,  4.4243,  4.1636,  ..., -0.9115, -0.9115, -0.9115],\n",
            "         [ 3.1102,  4.6082,  4.2854,  ..., -0.9513, -0.9513, -0.9513],\n",
            "         [ 3.2683,  4.7553,  4.5320,  ..., -0.9371, -0.9371, -0.9371]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 8, 20108])\n",
            "tensor([[[ 5.1069,  5.5286,  3.8727,  ..., -0.6981, -0.6981, -0.6981],\n",
            "         [ 5.8378,  4.5176,  3.6761,  ..., -0.6857, -0.6857, -0.6857],\n",
            "         [ 5.7684,  4.1443,  2.1865,  ..., -0.3828, -0.3828, -0.3828],\n",
            "         ...,\n",
            "         [ 5.0035,  2.6836,  1.2071,  ..., -0.2661, -0.2661, -0.2661],\n",
            "         [ 5.5950,  2.1259,  1.5824,  ..., -0.3491, -0.3491, -0.3491],\n",
            "         [ 5.1946,  2.2625,  1.7259,  ..., -0.3885, -0.3885, -0.3885]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 182, 20108])\n",
            "tensor([[[ 3.6678,  5.5185,  4.3831,  ..., -1.0958, -1.0958, -1.0958],\n",
            "         [ 5.0269,  6.5725,  5.7471,  ..., -1.0656, -1.0656, -1.0656],\n",
            "         [ 5.8295,  7.1686,  6.2737,  ..., -1.0950, -1.0950, -1.0950],\n",
            "         ...,\n",
            "         [ 3.7753,  3.2258,  2.6572,  ..., -0.7859, -0.7859, -0.7859],\n",
            "         [ 4.3055,  3.6527,  2.9244,  ..., -0.8173, -0.8173, -0.8173],\n",
            "         [ 3.6920,  3.0581,  2.4600,  ..., -0.7684, -0.7684, -0.7684]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 38, 20108])\n",
            "tensor([[[ 5.3988,  6.5979,  6.4072,  ..., -1.0806, -1.0806, -1.0806],\n",
            "         [ 4.9671,  7.1572,  6.6883,  ..., -1.1317, -1.1317, -1.1317],\n",
            "         [ 5.0644,  6.7621,  6.6424,  ..., -1.0740, -1.0740, -1.0740],\n",
            "         ...,\n",
            "         [ 6.6003,  6.2071,  5.8018,  ..., -1.0116, -1.0116, -1.0116],\n",
            "         [ 7.1148,  6.7941,  6.4000,  ..., -1.0376, -1.0376, -1.0376],\n",
            "         [ 6.5851,  5.8917,  5.4840,  ..., -0.9640, -0.9640, -0.9640]]],\n",
            "       device='cuda:0')\n",
            "decoder_output.shape\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 5.7150,  6.3053,  4.1450,  ..., -0.5213, -0.5213, -0.5213],\n",
            "         [ 5.4612,  4.7826,  3.0206,  ..., -0.4559, -0.4559, -0.4559],\n",
            "         [ 4.7381,  4.2456,  2.4699,  ..., -0.4552, -0.4552, -0.4552],\n",
            "         ...,\n",
            "         [ 4.6571,  2.2601,  0.1565,  ..., -0.3409, -0.3409, -0.3409],\n",
            "         [ 4.0678,  1.9682, -0.1425,  ..., -0.3015, -0.3015, -0.3015],\n",
            "         [ 4.4935,  1.6616, -0.5948,  ..., -0.3061, -0.3061, -0.3061]]],\n",
            "       device='cuda:0')\n",
            "torch.Size([1, 14, 20108])\n",
            "tensor([[[ 5.7150,  6.3053,  4.1450,  ..., -0.5213, -0.5213, -0.5213],\n",
            "         [ 5.4612,  4.7826,  3.0206,  ..., -0.4559, -0.4559, -0.4559],\n",
            "         [ 4.7381,  4.2456,  2.4699,  ..., -0.4552, -0.4552, -0.4552],\n",
            "         ...,\n",
            "         [ 4.6571,  2.2601,  0.1565,  ..., -0.3409, -0.3409, -0.3409],\n",
            "         [ 4.0678,  1.9682, -0.1425,  ..., -0.3015, -0.3015, -0.3015],\n",
            "         [ 4.4935,  1.6616, -0.5948,  ..., -0.3061, -0.3061, -0.3061]]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-902f3b6b9c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_to_ndcg_at_100_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFairness_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#print ('the shape ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print (decoder_output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-4947494c31e6>\u001b[0m in \u001b[0;36mFairness_evaluate\u001b[0;34m(model, criterion, reader, hyper_params, is_train_set)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMA_b8oeDBH",
        "colab_type": "text"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GrM_OcUShxI",
        "colab_type": "text"
      },
      "source": [
        "Fairnee evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i46rrI_wSjyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Fairness_evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['loss'] = 0.0\n",
        "    Ks = [10, 100]\n",
        "    for k in Ks: \n",
        "        metrics['NDCG@' + str(k)] = 0.0\n",
        "        metrics['Rec@' + str(k)] = 0.0\n",
        "        metrics['Prec@' + str(k)] = 0.0\n",
        "\n",
        "    batch = 0\n",
        "    total_users = 0.0\n",
        "    \n",
        "    # For plotting the results (seq length vs. NDCG@100)\n",
        "    len_to_ndcg_at_100_map = {}\n",
        "\n",
        "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
        "        batch += 1\n",
        "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
        "\n",
        "        decoder_output, z_mean, z_log_sigma = model(x)\n",
        "        \n",
        "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data\n",
        "        \n",
        "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
        "        decoder_output = decoder_output.data\n",
        "\n",
        "        print('decoder_output.shape')\n",
        "        print(decoder_output.shape)\n",
        "        print(decoder_output)\n",
        "\n",
        "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
        "        #print('x_scattered.shape')\n",
        "        #print(x_scattered.shape)\n",
        "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
        "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
        "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
        "        #print (decoder_output.shape)\n",
        "        #print ('last_predictions.shape')\n",
        "        #print (last_predictions.shape)\n",
        "        #print (last_predictions)\n",
        "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
        "            predicted_scores = last_predictions[batch_num]\n",
        "            #print ('predicted_scores.shape')\n",
        "            #print (predicted_scores.shape)\n",
        "            \n",
        "            actual_movies_watched = test_movies[batch_num]\n",
        "            actual_movies_ratings = test_movies_r[batch_num]\n",
        "         #   print (last_predictions.shape) \n",
        "          #  print (predicted_scores.shape)    \n",
        "            # Calculate NDCG\n",
        "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
        "            for k in Ks:\n",
        "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
        "                \n",
        "                rec_list = list(argsorted[:k].cpu().numpy())\n",
        "                for m in range(len(actual_movies_watched)):\n",
        "                    movie = actual_movies_watched[m]\n",
        "                    now_at += 1.0\n",
        "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
        "                    \n",
        "                    if movie not in rec_list: continue\n",
        "                    hits += 1.0\n",
        "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
        "                \n",
        "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
        "                metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
        "                metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
        "                \n",
        "    print(decoder_output.shape) \n",
        "    print(decoder_output)  \n",
        "    print(dcg.shape) \n",
        "    print(dcg)   \n",
        "\n",
        "    ufairs, ndcgs = Fairness_at_k_rounds(decoder_output, dcg)\n",
        "\n",
        "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
        "                #if k == 100:\n",
        "                 #   seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
        "                  #  if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
        "                   # len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
        "                \n",
        "            #total_users += 1.0\n",
        "    \n",
        "    #metrics['loss'] = float(metrics['loss']) / float(batch)\n",
        "    #metrics['loss'] = round(metrics['loss'], 4)\n",
        "\n",
        "    #print ('the size is') \n",
        "    #print (decoder_output.size)\n",
        "    #print ('the shape is') \n",
        "#    print (decoder_output.shape)\n",
        "    #for k in Ks:\n",
        "     #   metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
        "      #  metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
        "       # metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
        "\n",
        "    #print (last_predictions.shape)        \n",
        "    return metrics, len_to_ndcg_at_100_map, dcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7zGjnGSndb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Fairness_at_k_rounds(X_pred, dcg_gt):\n",
        "    debug = False\n",
        "    print(X_pred.shape)\n",
        "    ufair_all = []\n",
        "    ndcg_all = []\n",
        "    print('good')\n",
        "    for user in range(X_pred.shape[1]):\n",
        "        ufair, ndcg = 0.0, 0.0\n",
        "        for item in range(X_pred.shape[2]):\n",
        "            sum_a, sum_r = 0,0\n",
        "            item_ufair, item_ndcg = [], []\n",
        "            for iround in range(X_pred.shape[0]):\n",
        "                print('gggood')\n",
        "                att, rel = 0,0\n",
        "                #print(X_pred[iround,user,item])\n",
        "                if X_pred[iround,user,item] != -np.inf:\n",
        "                    #if debug: print(user,item,iround)\n",
        "                    print(user,item,iround)\n",
        "                    # NORMALIZE SCORES BETWEEN THE MINIMUN AND MAXIMUN VALUES\n",
        "                    #print(min(X_pred[iround,user,:]),max(X_pred[iround,user,:]))\n",
        "                    norm_scores = ((X_pred[iround,user,:] - min(X_pred[iround,user,:]))/(max(X_pred[iround,user,:])- min(X_pred[iround,user,:])))\n",
        "                    print(norm_scores)\n",
        "                    #norm_scores = (X_pred[iround,user,:]/max(X_pred[iround,user,:]))\n",
        "                    if debug: print(norm_scores)\n",
        "                    print('ok num scores')\n",
        "                    # INDEX OF ITEMS SORTED IN DESCENDING ORDER\n",
        "                   # if debug: print(np.argsort(norm_scores)[::-1]) \n",
        "                   \n",
        "                    print(np.argsort(norm_scores)[::-1]) \n",
        "                    #print(argsort)\n",
        "                    print('ok argsort')\n",
        "                    print('POSITION OF THE CURRENT ITEM') \n",
        "                    if debug: print(max(np.argsort(norm_scores)) - np.where(np.argsort(norm_scores) == item)[0][0])\n",
        "                    print('ahead') \n",
        "                    #max(np.argsort(norm_scores)).cpu()\n",
        "                    #print('x') \n",
        "                    #y = (np.where(np.argsort(norm_scores) == item)[0][0]).cpu()\n",
        "                    #print ('y')\n",
        "                    #att = y/x\n",
        "                    att = np.where(np.argsort(norm_scores) == item)[0][0]/max(np.argsort(norm_scores)).cpu()\n",
        "                    print('att') \n",
        "                    if debug: print('Attention: '+ str(att)) \n",
        "                    sum_a = sum_a + att\n",
        "                    rel = norm_scores[item]\n",
        "                    if debug: print('Relevance: '+str(rel))\n",
        "                    sum_r = sum_r + rel\n",
        "                    if debug: print('Unfairness: '+str(abs(att - rel)))\n",
        "                    if debug: print('DCG: '+str(dcg_single_ranking(X_pred[iround,user,:])))\n",
        "                    if debug: print('NDCG: '+str(dcg_single_ranking(X_pred[iround,user,:])/dcg_gt[user]))\n",
        "                    if debug: input()\n",
        "                    item_ufair.append(abs(att - rel)) \n",
        "                    item_ndcg.append(dcg_single_ranking(X_pred[iround,user,:])/dcg_gt[user])\n",
        "                else: \n",
        "                    print(\"ALERT\")    \n",
        "                    print(user,item,iround) \n",
        "            print ('plot_curve(item_ufair,item_ndcg')\n",
        "            # SUMS THE UNFAIRNESS OF CURRENT ITEM\n",
        "            ufair = ufair + (abs(sum_a - sum_r)/X_pred.shape[0])\n",
        "            ndcg = ndcg + (np.sum(item_ndcg)/X_pred.shape[0])\n",
        "            if debug: print('Unfairness of Item: '+str((abs(sum_a - sum_r)/X_pred.shape[0])))\n",
        "            if debug: print('Total Current Unfairness: '+str(ufair/(item+1)))\n",
        "            if debug: print('-----------------------------------')\n",
        "        if debug: print('Normalized Total Unfairness: '+str(ufair/X_pred.shape[2]))\n",
        "        if debug: print('Normalized Total NDCG: '+str(ndcg/X_pred.shape[2]))\n",
        "        # normalize by the number of items\n",
        "        ufair_all.append(ufair/X_pred.shape[2])\n",
        "        ndcg_all.append(ndcg/X_pred.shape[2])\n",
        "    return np.array(ufair_all), np.array(ndcg_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ac9t-VqX3qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_k_rounds = []\n",
        "num_users = 1000\n",
        "num_items = 100\n",
        "num_rounds = 100 \n",
        "batch_size_test = 2000 \n",
        "    for k in range(num_rounds):\n",
        "        preds = []\n",
        "        with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:\n",
        "        #with tf.Session() as sess:\n",
        "            saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
        "            for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
        "                end_idx = min(st_idx + batch_size_test, N_test)\n",
        "                X = test_data[idxlist_test[st_idx:end_idx]]\n",
        "            #    X = test_data\n",
        "                \n",
        "                if sparse.isspmatrix(X):\n",
        "                    X = X.toarray()\n",
        "                X = X.astype('float32')\n",
        "                \n",
        "                pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
        "                # exclude examples from training and validation (if any)\n",
        "                pred_val[X.nonzero()] = -np.inf\n",
        "                preds.extend(pred_val)\n",
        "        preds_k_rounds.append(preds)    \n",
        "    preds_k_rounds = np.array(preds_k_rounds)\n",
        "    print(preds_k_rounds.shape)\n",
        "    \n",
        "    preds_k_rounds_filter = np.zeros((num_rounds,num_users,num_items))\n",
        "    for user in range(num_users):\n",
        "        preds_k_rounds_filter[:,user,:] = preds_k_rounds[:,user,sorted(topkItens[user,:])]\n",
        "    \n",
        "    #preds_k_rounds = preds_k_rounds[:,:,sorted(topkItens)]\n",
        "    preds_k_rounds_filter = np.array(preds_k_rounds_filter)\n",
        "    print(preds_k_rounds_filter.shape)\n",
        "    \n",
        "    ufairs, ndcgs = Fairness_at_k_rounds(preds_k_rounds_filter, dcg_gt)\n",
        "    return ufairs,ndcgs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsCVX_X9jzPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps7vBNbsjzVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTgw1_6Js38J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4xutRbes4B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Z9G-Xs3_z",
        "colab_type": "code",
        "outputId": "8e0e63a9-765a-4ef7-d4ca-24737da4d30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
        "hyper_params['noise'] = 1\n",
        "test_reader, total_items = load_data(hyper_params)\n",
        "hyper_params['total_items'] = total_items\n",
        "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
        "criterion = VAELoss(hyper_params)\n",
        "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
        "print(len_to_ndcg_at_100_map)\n",
        "# # Plot sequence length vs NDCG@100 graph\n",
        "# plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
        "\n",
        "# string = \"\"\n",
        "# for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
        "\n",
        "# ss  = '=' * 89\n",
        "# ss += '\\n| End of training'\n",
        "# ss += string + \" (TEST)\"\n",
        "# ss += '\\n'\n",
        "# ss += '=' * 89\n",
        "# file_write(hyper_params['log_file'], ss)\n",
        "# print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started reading data file\n",
            "Data Files loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8538846/8538846 [00:15<00:00, 564806.22it/s]\n",
            "100%|██████████| 581927/581927 [00:01<00:00, 368602.87it/s]\n",
            "100%|██████████| 150474/150474 [00:00<00:00, 798345.59it/s]\n",
            "100%|██████████| 571057/571057 [00:00<00:00, 850410.03it/s]\n",
            "100%|██████████| 147726/147726 [00:00<00:00, 842081.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9d4dc985d1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noise'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_items'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testing_batch_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl0MGRs38WVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}